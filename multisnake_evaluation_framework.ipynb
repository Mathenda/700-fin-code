{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83219ebb-58ce-42e0-9e02-171abc5ea136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Standard libraries imported successfully\n",
      "pygame 2.6.1 (SDL 2.28.4, Python 3.11.9)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "‚úì snake_environment imported successfully\n",
      "‚úì astar_snake imported successfully\n",
      "Using device: cuda\n",
      "‚úì dqn_snake imported successfully\n",
      "‚úì gp_snake imported successfully\n",
      "\n",
      "üéØ All imports completed!\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Any, Tuple\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set matplotlib to inline for notebook display\n",
    "%matplotlib inline\n",
    "\n",
    "# Configure plot style\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(\"‚úì Standard libraries imported successfully\")\n",
    "\n",
    "# Import custom Snake game modules\n",
    "try:\n",
    "    from snake_environment import SnakeGame, Direction\n",
    "    print(\"‚úì snake_environment imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Warning: Could not import snake_environment: {e}\")\n",
    "    print(\"   Make sure snake_environment.py is in the same directory\")\n",
    "\n",
    "try:\n",
    "    from astar_snake import AStarSnakeAgent, run_astar_game\n",
    "    print(\"‚úì astar_snake imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Warning: Could not import astar_snake: {e}\")\n",
    "\n",
    "try:\n",
    "    from dqn_snake import DQNAgent, train_dqn_agent, test_dqn_agent\n",
    "    print(\"‚úì dqn_snake imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Warning: Could not import dqn_snake: {e}\")\n",
    "\n",
    "try:\n",
    "    from gp_snake import GeneticProgram, Node, train_gp_agent, test_gp_agent, save_gp_agent, load_gp_agent\n",
    "    print(\"‚úì gp_snake imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Warning: Could not import gp_snake: {e}\")\n",
    "\n",
    "print(\"\\nüéØ All imports completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94a1adf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéÆ SETTING UP GLOBAL CONFIGURATION PARAMETERS\n",
      "============================================================\n",
      "üèãÔ∏è Training Grid Size: 10x10\n",
      "üìä Test Grid Sizes: ['4x4', '5x5', '6x6', '7x7', '8x8', '9x9', '10x10']\n",
      "üéØ Test Episodes per Grid: 500\n",
      "ü§ñ DQN Training Episodes: 5000\n",
      "üß¨ GP Training Generations: 1000\n",
      "üîß Use Pre-trained Models: False\n",
      "üèÜ Use Best Models: False\n",
      "üèÜ Win Threshold: 80.0% of board filled\n",
      "‚è±Ô∏è Max Steps: 300 √ó 1.5 grid multiplier\n",
      "üìà GP Parameters: Pop=120, Mut=0.25, Cross=0.75\n",
      "üìã Statistical significance level: 0.05\n",
      "üíæ Results Directory: evaluation_results\n",
      "‚ö° Total Test Episodes: 7 grids √ó 3 agents √ó 500 episodes = 10500\n",
      "\n",
      "‚úÖ Global configuration completed!\n"
     ]
    }
   ],
   "source": [
    "# üéÆ GLOBAL CONFIGURATION PARAMETERS\n",
    "print(\"üéÆ SETTING UP GLOBAL CONFIGURATION PARAMETERS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# === GRID SIZE CONFIGURATION ===\n",
    "# Training grid size (agents will be trained on this size)\n",
    "TRAINING_GRID_SIZE = (10, 10)  # Medium grid for balanced training\n",
    "\n",
    "# Multiple grid configurations for testing the same trained agents\n",
    "TEST_GRID_SIZES = [\n",
    "    (4, 4),   # Small grid - simple scenarios\n",
    "    (5, 5),   # Medium-small grid\n",
    "    (6, 6),   # Medium-small grid\n",
    "    (7, 7),   # Medium grid\n",
    "    (8, 8),   # Medium grid\n",
    "    (9, 9),   # Medium-large grid\n",
    "    (10, 10)  # Large grid - complex scenarios (same as training)\n",
    "]\n",
    "\n",
    "# === EPISODE CONFIGURATION ===\n",
    "TEST_EPISODES = 500        # Episodes per grid for testing\n",
    "TRAINING_EPISODES_DQN = 5000  # Full training episodes for DQN\n",
    "TRAINING_GENERATIONS_GP = 1000  # Full training generations for GP\n",
    "\n",
    "# === STEP LIMITS AND THRESHOLDS ===\n",
    "# Step limit calculation parameters\n",
    "MAX_STEPS_BASE = 300  # Base maximum steps\n",
    "MAX_STEPS_GRID_MULTIPLIER = 1.5  # Grid size multiplier for max steps (larger grids = more steps)\n",
    "\n",
    "# Game evaluation parameters\n",
    "WIN_THRESHOLD = 0.8  # Consider game \"won\" if snake fills 80% of board\n",
    "\n",
    "# === GP ALGORITHM PARAMETERS ===\n",
    "GP_POPULATION_SIZE = 120  # Population size for GP\n",
    "GP_MAX_DEPTH = 8  # Maximum depth of GP trees\n",
    "GP_MUTATION_RATE = 0.25  # Mutation rate\n",
    "GP_CROSSOVER_RATE = 0.75  # Crossover rate\n",
    "GP_ELITE_SIZE = 12  # Number of elite individuals\n",
    "GP_DIVERSITY_THRESHOLD = 40  # Diversity threshold for GP population\n",
    "\n",
    "# === TRAINING/LOADING CONFIGURATION ===\n",
    "USE_PRETRAINED_MODELS = False  # Set to True to use best pre-trained models, False to train from scratch\n",
    "USE_BEST_MODELS = False  # If True, uses best_*.pth/json files; If False, uses evaluation_results/ models\n",
    "\n",
    "# === STATISTICAL ANALYSIS PARAMETERS ===\n",
    "SIGNIFICANCE_LEVEL = 0.05  # For statistical tests (p-value threshold)\n",
    "\n",
    "# === DIRECTORIES ===\n",
    "# Results directory\n",
    "RESULTS_DIR = Path(\"evaluation_results\")\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# === DISPLAY CONFIGURATION ===\n",
    "# Print configuration summary\n",
    "print(f\"üèãÔ∏è Training Grid Size: {TRAINING_GRID_SIZE[0]}x{TRAINING_GRID_SIZE[1]}\")\n",
    "print(f\"üìä Test Grid Sizes: {[f'{w}x{h}' for w, h in TEST_GRID_SIZES]}\")\n",
    "print(f\"üéØ Test Episodes per Grid: {TEST_EPISODES}\")\n",
    "print(f\"ü§ñ DQN Training Episodes: {TRAINING_EPISODES_DQN}\")\n",
    "print(f\"üß¨ GP Training Generations: {TRAINING_GENERATIONS_GP}\")\n",
    "print(f\"üîß Use Pre-trained Models: {USE_PRETRAINED_MODELS}\")\n",
    "print(f\"üèÜ Use Best Models: {USE_BEST_MODELS}\")\n",
    "print(f\"üèÜ Win Threshold: {WIN_THRESHOLD * 100}% of board filled\")\n",
    "print(f\"‚è±Ô∏è Max Steps: {MAX_STEPS_BASE} √ó {MAX_STEPS_GRID_MULTIPLIER} grid multiplier\")\n",
    "print(f\"üìà GP Parameters: Pop={GP_POPULATION_SIZE}, Mut={GP_MUTATION_RATE}, Cross={GP_CROSSOVER_RATE}\")\n",
    "print(f\"üìã Statistical significance level: {SIGNIFICANCE_LEVEL}\")\n",
    "print(f\"üíæ Results Directory: {RESULTS_DIR}\")\n",
    "print(f\"‚ö° Total Test Episodes: {len(TEST_GRID_SIZES)} grids √ó 3 agents √ó {TEST_EPISODES} episodes = {len(TEST_GRID_SIZES) * 3 * TEST_EPISODES}\")\n",
    "print(\"\\n‚úÖ Global configuration completed!\")\n",
    "\n",
    "# Global variables for results storage\n",
    "ALL_RESULTS = {}\n",
    "TRAINING_LOGS = {}\n",
    "MULTI_GRID_RESULTS = {}\n",
    "MULTI_GRID_EPISODE_DATA = {}\n",
    "TRAINED_AGENTS = {}  # Store trained agents for reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13419a34-1d55-43da-93ee-4a3bc2ef59b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéÆ CONFIGURING MULTI-GRID EVALUATION PARAMETERS\n",
      "============================================================\n",
      "üèãÔ∏è Training Grid Size: 10x10\n",
      "üìä Test Grid Sizes: ['4x4', '5x5', '6x6', '7x7', '8x8', '9x9', '10x10']\n",
      "üéØ Test Episodes per Grid: 200\n",
      "ü§ñ DQN Training Episodes: 5000\n",
      "üß¨ GP Training Generations: 1000\n",
      "üíæ Results Directory: evaluation_results\n",
      "üèÜ Win Threshold: 80.0% of board filled\n",
      "‚ö° Total Test Episodes: 7 grids √ó 3 agents √ó 200 episodes = 4200\n",
      "\n",
      "‚úÖ Multi-grid configuration completed!\n"
     ]
    }
   ],
   "source": [
    "# üéÆ EVALUATION CONFIGURATION\n",
    "print(\"üéÆ CONFIGURING MULTI-GRID EVALUATION PARAMETERS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Training grid size (agents will be trained on this size)\n",
    "TRAINING_GRID_SIZE = (10, 10)  # Medium grid for balanced training\n",
    "\n",
    "# Multiple grid configurations for testing the same trained agents\n",
    "TEST_GRID_SIZES = [\n",
    "    (4, 4),   # Small grid - simple scenarios\n",
    "    (5, 5),   # Medium-small grid\n",
    "    (6, 6),   # Medium-small grid\n",
    "    (7, 7),   # Medium grid\n",
    "    (8, 8),   # Medium grid\n",
    "    (9, 9),   # Medium-large grid\n",
    "    (10, 10)  # Large grid - complex scenarios (same as training)\n",
    "]\n",
    "\n",
    "\n",
    "# === EPISODE CONFIGURATION ===\n",
    "TEST_EPISODES = 200        # Episodes per grid for testing\n",
    "TRAINING_EPISODES_DQN = 5000  # Full training episodes for DQN\n",
    "TRAINING_GENERATIONS_GP = 1000  # Full training generations for GP\n",
    "\n",
    "# === TRAINING/LOADING CONFIGURATION ===\n",
    "USE_PRETRAINED_MODELS = False  # Set to True to use best pre-trained models, False to train from scratch\n",
    "USE_BEST_MODELS = False  # If True, uses best_*.pth/json files; If False, uses evaluation_results/ models\n",
    "\n",
    "# Statistical analysis parameters\n",
    "WIN_THRESHOLD = 0.8  # Consider game \"won\" if snake fills 80% of board\n",
    "SIGNIFICANCE_LEVEL = 0.05  # For statistical tests\n",
    "\n",
    "# Results directory\n",
    "RESULTS_DIR = Path(\"evaluation_results\")\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"üèãÔ∏è Training Grid Size: {TRAINING_GRID_SIZE[0]}x{TRAINING_GRID_SIZE[1]}\")\n",
    "print(f\"üìä Test Grid Sizes: {[f'{w}x{h}' for w, h in TEST_GRID_SIZES]}\")\n",
    "print(f\"üéØ Test Episodes per Grid: {TEST_EPISODES}\")\n",
    "print(f\"ü§ñ DQN Training Episodes: {TRAINING_EPISODES_DQN}\")\n",
    "print(f\"üß¨ GP Training Generations: {TRAINING_GENERATIONS_GP}\")\n",
    "print(f\"üíæ Results Directory: {RESULTS_DIR}\")\n",
    "print(f\"üèÜ Win Threshold: {WIN_THRESHOLD * 100}% of board filled\")\n",
    "print(f\"‚ö° Total Test Episodes: {len(TEST_GRID_SIZES)} grids √ó 3 agents √ó {TEST_EPISODES} episodes = {len(TEST_GRID_SIZES) * 3 * TEST_EPISODES}\")\n",
    "print(\"\\n‚úÖ Multi-grid configuration completed!\")\n",
    "\n",
    "# Global variables for results storage\n",
    "ALL_RESULTS = {}\n",
    "TRAINING_LOGS = {}\n",
    "MULTI_GRID_RESULTS = {}\n",
    "TRAINED_AGENTS = {}  # Store trained agents for reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a99ee498-5df9-48c9-a3c7-5da04c3fa2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèóÔ∏è MultiGridEvaluationFramework initialized:\n",
      "   Training grid: 10x10\n",
      "   Test grids: ['4x4', '5x5', '6x6', '7x7', '8x8', '9x9', '10x10']\n",
      "   Test episodes per grid: 200\n",
      "   DQN training: 5000 episodes\n",
      "   GP training: 1000 generations\n",
      "   Use pre-trained models: False\n",
      "   Use best models: False\n",
      "   Step limit: Base=300, Multiplier=1.5\n",
      "   Win threshold: 80.0% of board filled\n",
      "‚úÖ MultiGridEvaluationFramework class defined and initialized!\n"
     ]
    }
   ],
   "source": [
    "class MultiGridEvaluationFramework:\n",
    "    \"\"\"\n",
    "    Enhanced evaluation framework for comparing Snake game agents across multiple grid sizes\n",
    "    Trains agents once on a standard grid, then evaluates on multiple grid sizes\n",
    "    Uses global parameters for easy tuning and configuration\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, training_grid: Tuple[int, int] = TRAINING_GRID_SIZE, test_grids: List[Tuple[int, int]] = TEST_GRID_SIZES):\n",
    "        self.training_grid = training_grid\n",
    "        self.test_grids = test_grids\n",
    "        self.results_dir = RESULTS_DIR\n",
    "        \n",
    "        # Use global parameters\n",
    "        self.test_episodes = TEST_EPISODES\n",
    "        self.training_episodes_dqn = TRAINING_EPISODES_DQN\n",
    "        self.training_generations_gp = TRAINING_GENERATIONS_GP\n",
    "        self.win_threshold = WIN_THRESHOLD\n",
    "        \n",
    "        # Training/Loading configuration\n",
    "        self.use_pretrained_models = USE_PRETRAINED_MODELS\n",
    "        self.use_best_models = USE_BEST_MODELS\n",
    "        \n",
    "        # Step limit parameters\n",
    "        self.max_steps_base = MAX_STEPS_BASE\n",
    "        self.max_steps_grid_multiplier = MAX_STEPS_GRID_MULTIPLIER\n",
    "        \n",
    "        # GP parameters\n",
    "        self.gp_population_size = GP_POPULATION_SIZE\n",
    "        self.gp_max_depth = GP_MAX_DEPTH\n",
    "        self.gp_mutation_rate = GP_MUTATION_RATE\n",
    "        self.gp_crossover_rate = GP_CROSSOVER_RATE\n",
    "        self.gp_elite_size = GP_ELITE_SIZE\n",
    "        self.gp_diversity_threshold = GP_DIVERSITY_THRESHOLD\n",
    "        \n",
    "        \n",
    "        # Statistical parameters\n",
    "        self.significance_level = SIGNIFICANCE_LEVEL\n",
    "        \n",
    "        # Results storage\n",
    "        self.all_results = {}\n",
    "        self.training_logs = {}\n",
    "        self.multi_grid_results = {}\n",
    "        self.trained_agents = {}\n",
    "        \n",
    "        print(f\"üèóÔ∏è MultiGridEvaluationFramework initialized:\")\n",
    "        print(f\"   Training grid: {self.training_grid[0]}x{self.training_grid[1]}\")\n",
    "        print(f\"   Test grids: {[f'{w}x{h}' for w, h in self.test_grids]}\")\n",
    "        print(f\"   Test episodes per grid: {self.test_episodes}\")\n",
    "        print(f\"   DQN training: {self.training_episodes_dqn} episodes\")\n",
    "        print(f\"   GP training: {self.training_generations_gp} generations\")\n",
    "        print(f\"   Use pre-trained models: {USE_PRETRAINED_MODELS}\")\n",
    "        print(f\"   Use best models: {USE_BEST_MODELS}\")\n",
    "        print(f\"   Step limit: Base={self.max_steps_base}, Multiplier={self.max_steps_grid_multiplier}\")\n",
    "        print(f\"   Win threshold: {self.win_threshold * 100}% of board filled\")\n",
    "    \n",
    "    def calculate_research_paper_metrics(self, df: pd.DataFrame, width: int, height: int) -> Dict[str, Dict[str, float]]:\n",
    "        \"\"\"\n",
    "        Calculate metrics exactly as presented in the research paper for specific grid size:\n",
    "        - Mean Points Scored (pÃÑ) with standard deviation (œÉp)\n",
    "        - Mean Games Won (qÃÑ) with standard deviation (œÉq) \n",
    "        - Mean Moves Made (rÃÑ) with standard deviation (œÉr)\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        for agent in df['agent'].unique():\n",
    "            agent_data = df[df['agent'] == agent]\n",
    "            \n",
    "            # Points scored = score (food collected)\n",
    "            points_scored = agent_data['score'].values\n",
    "            \n",
    "            # Games won = episodes where snake achieved significant coverage\n",
    "            max_possible_score = (width * height) - 3  # Grid size minus initial snake\n",
    "            win_threshold_score = self.win_threshold * max_possible_score\n",
    "            games_won = (agent_data['score'] >= win_threshold_score).astype(int) * 100\n",
    "            \n",
    "            # Moves made = steps taken\n",
    "            moves_made = agent_data['steps'].values\n",
    "            \n",
    "            results[agent] = {\n",
    "                # Points metrics\n",
    "                'p_mean': float(np.mean(points_scored)),\n",
    "                'p_std': float(np.std(points_scored, ddof=1)),\n",
    "                \n",
    "                # Games won metrics (as percentage)\n",
    "                'q_mean': float(np.mean(games_won)),\n",
    "                'q_std': float(np.std(games_won, ddof=1)),\n",
    "                \n",
    "                # Moves made metrics\n",
    "                'r_mean': float(np.mean(moves_made)),\n",
    "                'r_std': float(np.std(moves_made, ddof=1)),\n",
    "                \n",
    "                # Additional metrics for multi-grid analysis\n",
    "                'max_score': int(np.max(points_scored)),\n",
    "                'success_rate': float(np.mean(points_scored > 0) * 100),\n",
    "                'efficiency_mean': float(np.mean(agent_data['efficiency'])),\n",
    "                'grid_size': f\"{width}x{height}\",\n",
    "                'grid_complexity': width * height,\n",
    "                'generalization_factor': (width * height) / (self.training_grid[0] * self.training_grid[1]),  # How different from training grid\n",
    "                \n",
    "                # Raw data for statistical tests\n",
    "                'points_data': points_scored,\n",
    "                'games_won_data': games_won,\n",
    "                'moves_data': moves_made\n",
    "            }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def calculate_statistical_significance(self, results: Dict[str, Dict[str, Any]]) -> Dict[str, Dict[str, float]]:\n",
    "        \"\"\"Calculate Mann-Whitney U test p-values between all agent pairs\"\"\"\n",
    "        agents = list(results.keys())\n",
    "        significance_results = {}\n",
    "        \n",
    "        for i, agent1 in enumerate(agents):\n",
    "            for j, agent2 in enumerate(agents):\n",
    "                if i < j:  # Avoid duplicate comparisons\n",
    "                    pair_key = f\"{agent1}_vs_{agent2}\"\n",
    "                    \n",
    "                    # Points comparison\n",
    "                    stat_p, pval_p = stats.mannwhitneyu(\n",
    "                        results[agent1]['points_data'],\n",
    "                        results[agent2]['points_data'],\n",
    "                        alternative='two-sided'\n",
    "                    )\n",
    "                    \n",
    "                    # Games won comparison\n",
    "                    stat_q, pval_q = stats.mannwhitneyu(\n",
    "                        results[agent1]['games_won_data'],\n",
    "                        results[agent2]['games_won_data'],\n",
    "                        alternative='two-sided'\n",
    "                    )\n",
    "                    \n",
    "                    # Moves comparison\n",
    "                    stat_r, pval_r = stats.mannwhitneyu(\n",
    "                        results[agent1]['moves_data'],\n",
    "                        results[agent2]['moves_data'],\n",
    "                        alternative='two-sided'\n",
    "                    )\n",
    "                    \n",
    "                    significance_results[pair_key] = {\n",
    "                        'points_pvalue': pval_p,\n",
    "                        'games_won_pvalue': pval_q,\n",
    "                        'moves_pvalue': pval_r\n",
    "                    }\n",
    "        \n",
    "        return significance_results\n",
    "    \n",
    "    def analyze_generalization_performance(self, multi_grid_data: Dict) -> pd.DataFrame:\n",
    "        \"\"\"Analyze how well agents generalize from training grid to different test grids\"\"\"\n",
    "        generalization_data = []\n",
    "        \n",
    "        training_complexity = self.training_grid[0] * self.training_grid[1]\n",
    "        \n",
    "        for grid_key, grid_results in multi_grid_data.items():\n",
    "            width, height = map(int, grid_key.split('x'))\n",
    "            test_complexity = width * height\n",
    "            complexity_ratio = test_complexity / training_complexity\n",
    "            is_training_grid = (width, height) == self.training_grid\n",
    "            \n",
    "            for agent, metrics in grid_results.items():\n",
    "                generalization_data.append({\n",
    "                    'grid_size': grid_key,\n",
    "                    'width': width,\n",
    "                    'height': height,\n",
    "                    'test_complexity': test_complexity,\n",
    "                    'training_complexity': training_complexity,\n",
    "                    'complexity_ratio': complexity_ratio,\n",
    "                    'is_training_grid': is_training_grid,\n",
    "                    'generalization_type': self._get_generalization_type(complexity_ratio),\n",
    "                    'agent': agent,\n",
    "                    'points_mean': metrics['p_mean'],\n",
    "                    'points_std': metrics['p_std'],\n",
    "                    'games_won_mean': metrics['q_mean'],\n",
    "                    'moves_mean': metrics['r_mean'],\n",
    "                    'max_score': metrics['max_score'],\n",
    "                    'success_rate': metrics['success_rate'],\n",
    "                    'efficiency_mean': metrics['efficiency_mean']\n",
    "                })\n",
    "        \n",
    "        return pd.DataFrame(generalization_data)\n",
    "    \n",
    "    def _get_generalization_type(self, complexity_ratio: float) -> str:\n",
    "        \"\"\"Categorize the type of generalization based on complexity ratio\"\"\"\n",
    "        if abs(complexity_ratio - 1.0) < 0.1:\n",
    "            return \"Same_Complexity\"\n",
    "        elif complexity_ratio < 1.0:\n",
    "            return \"Simpler_Grid\"\n",
    "        else:\n",
    "            return \"More_Complex_Grid\"\n",
    "\n",
    "# Initialize the multi-grid evaluation framework\n",
    "evaluator = MultiGridEvaluationFramework()\n",
    "print(\"‚úÖ MultiGridEvaluationFramework class defined and initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26b59585-7723-4296-9d0c-a3a5c9920d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Single training functions defined!\n"
     ]
    }
   ],
   "source": [
    "def train_gp_agent():\n",
    "    \"\"\"Train GP agent once on the training grid size using globally defined parameters\"\"\"\n",
    "    width, height = evaluator.training_grid\n",
    "    print(f\"üß¨ TRAINING GENETIC PROGRAMMING AGENT - {width}x{height} Training Grid\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Check if GP modules are available\n",
    "    try:\n",
    "        from gp_snake import GeneticProgram, Node, save_gp_agent\n",
    "    except ImportError as e:\n",
    "        print(f\"‚ùå GP modules not available: {e}\")\n",
    "        print(\"   Make sure gp_snake.py is in the same directory\")\n",
    "        return None\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Configure GP with global parameters for training grid\n",
    "    gp = GeneticProgram(\n",
    "        pop_size=evaluator.gp_population_size,\n",
    "        generations=evaluator.training_generations_gp,\n",
    "        max_depth=evaluator.gp_max_depth,\n",
    "        mutation_rate=evaluator.gp_mutation_rate,\n",
    "        crossover_rate=evaluator.gp_crossover_rate,\n",
    "        elite_size=evaluator.gp_elite_size,\n",
    "        diversity_threshold=evaluator.gp_diversity_threshold\n",
    "    )\n",
    "    \n",
    "    # Override evaluate method to use training grid size\n",
    "    def evaluate_on_training_grid(tree: Node, episodes: int = 5) -> float:\n",
    "        total_fitness = 0.0\n",
    "        for _ in range(episodes):\n",
    "            try:\n",
    "                game = SnakeGame(width=width, height=height, render=False)\n",
    "                state = game.get_state_vector()\n",
    "                steps_survived = 0\n",
    "                food_collected = 0\n",
    "                max_steps = (width * height) * 3  # Generous step limit\n",
    "                \n",
    "                while not game.game_over and steps_survived < max_steps:\n",
    "                    try:\n",
    "                        action = tree.evaluate(state)\n",
    "                        _, reward, done, info = game.step(action)\n",
    "                        \n",
    "                        steps_survived += 1\n",
    "                        if game.score > food_collected:\n",
    "                            food_collected = game.score\n",
    "                        \n",
    "                        state = game.get_state_vector()\n",
    "                    except Exception as e:\n",
    "                        # Handle any evaluation errors\n",
    "                        break\n",
    "                \n",
    "                # Fitness function optimized for generalization\n",
    "                episode_fitness = (\n",
    "                    food_collected * 1000 +      # Reward food collection\n",
    "                    steps_survived * 2 +         # Survival bonus\n",
    "                    (200 if food_collected > 0 else 0) +  # First food bonus\n",
    "                    (food_collected * 50 if food_collected > 1 else 0)  # Multiple food bonus\n",
    "                )\n",
    "                total_fitness += episode_fitness\n",
    "                game.close()\n",
    "            except Exception as e:\n",
    "                # Handle game creation errors\n",
    "                continue\n",
    "                \n",
    "        return total_fitness / episodes if episodes > 0 else 0.0\n",
    "    \n",
    "    gp.evaluate = evaluate_on_training_grid\n",
    "    \n",
    "    print(f\"Training GP: {gp.pop_size} individuals, {gp.generations} generations\")\n",
    "    print(f\"Training grid: {width}x{height}\")\n",
    "    \n",
    "    try:\n",
    "        best_tree = gp.run()\n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        # Save trained agent\n",
    "        model_path = evaluator.results_dir / f\"gp_trained_agent_{width}x{height}.json\"\n",
    "        save_gp_agent(best_tree, str(model_path))\n",
    "        \n",
    "        # Store training log\n",
    "        TRAINING_LOGS['GP'] = {\n",
    "            'training_time': training_time,\n",
    "            'generations': evaluator.training_generations_gp,\n",
    "            'population_size': gp.pop_size,\n",
    "            'training_grid': f\"{width}x{height}\",\n",
    "            'model_path': str(model_path)\n",
    "        }\n",
    "        \n",
    "        print(f\"‚úÖ GP training completed in {training_time:.2f} seconds\")\n",
    "        print(f\"üíæ Model saved to: {model_path}\")\n",
    "        \n",
    "        return best_tree\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå GP training failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def train_dqn_agent():\n",
    "    \"\"\"Train DQN agent once on the training grid size using global parameters\"\"\"\n",
    "    width, height = evaluator.training_grid\n",
    "    print(f\"\\nü§ñ TRAINING DEEP Q-NETWORK AGENT - {width}x{height} Training Grid\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Check if DQN modules are available\n",
    "    try:\n",
    "        from dqn_snake import DQNAgent, train_dqn_agent as train_dqn_func\n",
    "    except ImportError as e:\n",
    "        print(f\"‚ùå DQN modules not available: {e}\")\n",
    "        print(\"   Make sure dqn_snake.py is in the same directory\")\n",
    "        return None\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(f\"Training DQN: {evaluator.training_episodes_dqn} episodes\")\n",
    "    print(f\"Training grid: {width}x{height}\")\n",
    "    \n",
    "    try:\n",
    "        # Train agent using the imported function with global parameters\n",
    "        agent, training_results = train_dqn_func(\n",
    "            episodes=evaluator.training_episodes_dqn,\n",
    "            width=width,\n",
    "            height=height,\n",
    "            render=False,\n",
    "            save_model_path=str(evaluator.results_dir / f\"dqn_trained_agent_{width}x{height}.pth\"),\n",
    "            save_best=True,\n",
    "        )\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        # Store training log\n",
    "        TRAINING_LOGS['DQN'] = {\n",
    "            'training_time': training_time,\n",
    "            'episodes': evaluator.training_episodes_dqn,\n",
    "            'final_epsilon': agent.epsilon,\n",
    "            'training_grid': f\"{width}x{height}\",\n",
    "            'training_results': training_results,\n",
    "            'model_path': str(evaluator.results_dir / f\"dqn_trained_agent_{width}x{height}.pth\")\n",
    "        }\n",
    "        \n",
    "        print(f\"‚úÖ DQN training completed in {training_time:.2f} seconds\")\n",
    "        \n",
    "        return agent\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå DQN training failed: {e}\")\n",
    "        print(f\"   Error details: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def train_all_agents():\n",
    "    \"\"\"Train all agents once on the training grid\"\"\"\n",
    "    print(f\"\\nüéØ TRAINING ALL AGENTS ON {evaluator.training_grid[0]}x{evaluator.training_grid[1]} TRAINING GRID\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    agents = {}\n",
    "    \n",
    "    # A* agent doesn't need training\n",
    "    try:\n",
    "        agents['A*'] = AStarSnakeAgent()\n",
    "        print(f\"‚úÖ A* agent ready (no training required)\")\n",
    "        TRAINING_LOGS['A*'] = {\n",
    "            'training_time': 0.0,\n",
    "            'training_grid': f\"{evaluator.training_grid[0]}x{evaluator.training_grid[1]}\",\n",
    "            'note': 'A* is a heuristic algorithm that does not require training'\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to create A* agent: {e}\")\n",
    "    \n",
    "    # Train GP agent\n",
    "    gp_agent = train_gp_agent()\n",
    "    if gp_agent is not None:\n",
    "        agents['GP'] = gp_agent\n",
    "    \n",
    "    # Train DQN agent\n",
    "    dqn_agent = train_dqn_agent()\n",
    "    if dqn_agent is not None:\n",
    "        agents['DQN'] = dqn_agent\n",
    "    \n",
    "    print(f\"\\n‚úÖ Training completed - {len(agents)} agents ready for multi-grid evaluation\")\n",
    "    \n",
    "    # Store trained agents globally for reuse\n",
    "    global TRAINED_AGENTS\n",
    "    TRAINED_AGENTS = agents\n",
    "    \n",
    "    return agents\n",
    "\n",
    "print(\"‚úÖ Single training functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8eee569f-be34-4158-a25e-0dc6932bc05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Multi-grid testing functions defined!\n"
     ]
    }
   ],
   "source": [
    "def test_agent_on_grid(agent_name: str, agent, width: int, height: int) -> List[Dict]:\n",
    "    \"\"\"Test a pre-trained agent on a specific grid size\"\"\"\n",
    "    print(f\"\\nüéØ Testing {agent_name} on {width}x{height} grid for {evaluator.test_episodes} episodes...\")\n",
    "    \n",
    "    results = []\n",
    "    # Use global parameters for max steps calculation\n",
    "    max_steps = 20000000\n",
    "    training_grid = evaluator.training_grid\n",
    "    is_training_grid = (width, height) == training_grid\n",
    "    \n",
    "    for episode in range(evaluator.test_episodes):\n",
    "        print(f\"  Episode {episode + 1}/{evaluator.test_episodes}\", end=\"\\r\")\n",
    "        \n",
    "        try:\n",
    "            if agent_name == \"A*\":\n",
    "                # A* agent testing (adapts automatically to any grid size)\n",
    "                game = SnakeGame(width=width, height=height, render=False)\n",
    "                episode_start_time = time.time()\n",
    "                \n",
    "                total_reward = 0\n",
    "                steps = 0\n",
    "                \n",
    "                while not game.game_over  and steps < max_steps:\n",
    "                    action = agent.get_action(game)\n",
    "                    state, reward, done, info = game.step(action)\n",
    "                    \n",
    "                    total_reward += reward\n",
    "                    steps += 1\n",
    "                \n",
    "                episode_time = time.time() - episode_start_time\n",
    "                \n",
    "                result = {\n",
    "                    'episode': episode + 1,\n",
    "                    'score': game.score,\n",
    "                    'steps': steps,\n",
    "                    'total_reward': total_reward,\n",
    "                    'time': episode_time,\n",
    "                    'reason': info.get('reason', 'unknown') if 'info' in locals() else 'unknown',\n",
    "                    'efficiency': game.score / steps if steps > 0 else 0,\n",
    "                    'snake_length': len(game.snake_pos),\n",
    "                    'grid_width': width,\n",
    "                    'grid_height': height,\n",
    "                    'grid_size': f\"{width}x{height}\",\n",
    "                    'training_grid': f\"{training_grid[0]}x{training_grid[1]}\",\n",
    "                    'is_training_grid': is_training_grid,\n",
    "                    'complexity_ratio': (width * height) / (training_grid[0] * training_grid[1]),\n",
    "                    'max_possible_score': (width * height) - 3\n",
    "                }\n",
    "                \n",
    "                game.close()\n",
    "                \n",
    "            elif agent_name == \"DQN\":\n",
    "                # DQN agent testing (using trained network on different grid sizes)\n",
    "                if agent is None:\n",
    "                    continue\n",
    "                    \n",
    "                original_epsilon = agent.epsilon\n",
    "                agent.epsilon = 0.0  # No exploration during testing\n",
    "                \n",
    "                game = SnakeGame(width=width, height=height, render=False)\n",
    "                state = game.get_state_vector()\n",
    "                episode_start_time = time.time()\n",
    "                \n",
    "                total_reward = 0\n",
    "                steps = 0\n",
    "                \n",
    "                while not game.game_over  and steps < max_steps:\n",
    "                    try:\n",
    "                        action = agent.get_action(state, game)\n",
    "                        next_state_full, reward, done, info = game.step(action)\n",
    "                        next_state = game.get_state_vector()\n",
    "                        \n",
    "                        state = next_state\n",
    "                        total_reward += reward\n",
    "                        steps += 1\n",
    "                    except Exception as e:\n",
    "                        # Handle potential issues with different grid sizes\n",
    "                        print(f\"\\nDQN error on {width}x{height}: {e}\")\n",
    "                        break\n",
    "                \n",
    "                episode_time = time.time() - episode_start_time\n",
    "                agent.epsilon = original_epsilon\n",
    "                \n",
    "                result = {\n",
    "                    'episode': episode + 1,\n",
    "                    'score': game.score,\n",
    "                    'steps': steps,\n",
    "                    'total_reward': total_reward,\n",
    "                    'time': episode_time,\n",
    "                    'reason': info.get('reason', 'unknown'),\n",
    "                    'efficiency': game.score / steps if steps > 0 else 0,\n",
    "                    'snake_length': len(game.snake_pos),\n",
    "                    'grid_width': width,\n",
    "                    'grid_height': height,\n",
    "                    'grid_size': f\"{width}x{height}\",\n",
    "                    'training_grid': f\"{training_grid[0]}x{training_grid[1]}\",\n",
    "                    'is_training_grid': is_training_grid,\n",
    "                    'complexity_ratio': (width * height) / (training_grid[0] * training_grid[1]),\n",
    "                    'max_possible_score': (width * height) - 3\n",
    "                }\n",
    "                \n",
    "                game.close()\n",
    "                \n",
    "            elif agent_name == \"GP\":\n",
    "                # GP agent testing (using trained tree on different grid sizes)\n",
    "                if agent is None:\n",
    "                    continue\n",
    "                    \n",
    "                game = SnakeGame(width=width, height=height, render=False)\n",
    "                state = game.get_state_vector()\n",
    "                episode_start_time = time.time()\n",
    "                \n",
    "                total_reward = 0\n",
    "                steps = 0\n",
    "                \n",
    "                while not game.game_over and steps < max_steps:\n",
    "                    try:\n",
    "                        action = agent.evaluate(state)\n",
    "                        _, reward, done, info = game.step(action)\n",
    "                        state = game.get_state_vector()\n",
    "                        \n",
    "                        total_reward += reward\n",
    "                        steps += 1\n",
    "                    except Exception as e:\n",
    "                        # Handle evaluation errors (GP tree might not generalize well)\n",
    "                        break\n",
    "                \n",
    "                episode_time = time.time() - episode_start_time\n",
    "                \n",
    "                result = {\n",
    "                    'episode': episode + 1,\n",
    "                    'score': game.score,\n",
    "                    'steps': steps,\n",
    "                    'total_reward': total_reward,\n",
    "                    'time': episode_time,\n",
    "                    'reason': info.get('reason', 'unknown') if 'info' in locals() else 'unknown',\n",
    "                    'efficiency': game.score / steps if steps > 0 else 0,\n",
    "                    'snake_length': len(game.snake_pos),\n",
    "                    'grid_width': width,\n",
    "                    'grid_height': height,\n",
    "                    'grid_size': f\"{width}x{height}\",\n",
    "                    'training_grid': f\"{training_grid[0]}x{training_grid[1]}\",\n",
    "                    'is_training_grid': is_training_grid,\n",
    "                    'complexity_ratio': (width * height) / (training_grid[0] * training_grid[1]),\n",
    "                    'max_possible_score': (width * height) - 3\n",
    "                }\n",
    "                \n",
    "                game.close()\n",
    "            \n",
    "            results.append(result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Error in episode {episode + 1}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Calculate generalization performance\n",
    "    avg_score = np.mean([r['score'] for r in results]) if results else 0\n",
    "    success_rate = np.mean([r['score'] > 0 for r in results]) * 100 if results else 0\n",
    "    \n",
    "    grid_type = \"training\" if is_training_grid else \"test\"\n",
    "    complexity_factor = (width * height) / (training_grid[0] * training_grid[1])\n",
    "    \n",
    "    print(f\"\\n‚úÖ {agent_name} on {width}x{height} ({grid_type}) completed!\")\n",
    "    print(f\"   Episodes: {len(results)}, Avg Score: {avg_score:.2f}, Success: {success_rate:.1f}%\")\n",
    "    print(f\"   Complexity Factor: {complexity_factor:.2f}x training grid\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def test_all_agents_on_all_grids(trained_agents: Dict) -> Dict[str, Dict[str, List[Dict]]]:\n",
    "    \"\"\"Test all trained agents on all test grid sizes\"\"\"\n",
    "    print(f\"\\nüéØ TESTING ALL AGENTS ON ALL GRID SIZES\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    all_grid_results = {}\n",
    "    \n",
    "    for i, (width, height) in enumerate(evaluator.test_grids):\n",
    "        grid_key = f\"{width}x{height}\"\n",
    "        is_training_grid = (width, height) == evaluator.training_grid\n",
    "        grid_type = \"TRAINING\" if is_training_grid else \"TEST\"\n",
    "        \n",
    "        print(f\"\\nüéÆ GRID {i+1}/{len(evaluator.test_grids)}: {grid_key} ({grid_type} GRID)\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        grid_results = {}\n",
    "        \n",
    "        for agent_name, agent in trained_agents.items():\n",
    "            print(f\"\\nTesting {agent_name} agent on {grid_key}...\")\n",
    "            grid_results[agent_name] = test_agent_on_grid(agent_name, agent, width, height)\n",
    "        \n",
    "        all_grid_results[grid_key] = grid_results\n",
    "        \n",
    "        # Brief summary for this grid\n",
    "        print(f\"\\nüìä Brief summary for {grid_key}:\")\n",
    "        for agent_name, results in grid_results.items():\n",
    "            if results:\n",
    "                avg_score = np.mean([r['score'] for r in results])\n",
    "                success_rate = np.mean([r['score'] > 0 for r in results]) * 100\n",
    "                print(f\"   {agent_name}: {avg_score:.2f} avg score, {success_rate:.1f}% success\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ All agents tested on all {len(evaluator.test_grids)} grid sizes\")\n",
    "    return all_grid_results\n",
    "\n",
    "def create_astar_agent():\n",
    "    \"\"\"Create A* agent (no training needed)\"\"\"\n",
    "    try:\n",
    "        astar_agent = AStarSnakeAgent()\n",
    "        return astar_agent\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to create A* agent: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"‚úÖ Multi-grid testing functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15016779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Pre-trained model loading functions defined!\n"
     ]
    }
   ],
   "source": [
    "def load_pretrained_agents(use_best_models: bool = True) -> Dict:\n",
    "    \"\"\"\n",
    "    Load pre-trained agents from saved models instead of training from scratch\n",
    "    \n",
    "    Args:\n",
    "        use_best_models: If True, loads from best_*.pth/json files. If False, loads from evaluation_results/\n",
    "    \n",
    "    Returns:\n",
    "        Dict of loaded agents\n",
    "    \"\"\"\n",
    "    print(f\"\\nüîß LOADING PRE-TRAINED AGENTS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    agents = {}\n",
    "    \n",
    "    # A* agent doesn't need loading (no training required)\n",
    "    try:\n",
    "        agents['A*'] = AStarSnakeAgent()\n",
    "        print(f\"‚úÖ A* agent ready (no training required)\")\n",
    "        TRAINING_LOGS['A*'] = {\n",
    "            'training_time': 0.0,\n",
    "            'training_grid': f\"{evaluator.training_grid[0]}x{evaluator.training_grid[1]}\",\n",
    "            'note': 'A* is a heuristic algorithm that does not require training',\n",
    "            'loaded_from': 'algorithm'\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to create A* agent: {e}\")\n",
    "    \n",
    "    # Load GP agent\n",
    "    if use_best_models:\n",
    "        gp_model_path = Path(\"best_gp_agent.json\")\n",
    "    else:\n",
    "        training_grid = evaluator.training_grid\n",
    "        gp_model_path = evaluator.results_dir / f\"gp_trained_agent_{training_grid[0]}x{training_grid[1]}.json\"\n",
    "    \n",
    "    if gp_model_path.exists():\n",
    "        try:\n",
    "            from gp_snake import load_gp_agent\n",
    "            gp_agent = load_gp_agent(str(gp_model_path))\n",
    "            agents['GP'] = gp_agent\n",
    "            print(f\"‚úÖ GP agent loaded from: {gp_model_path}\")\n",
    "            TRAINING_LOGS['GP'] = {\n",
    "                'training_time': 0.0,  # No training time since loaded\n",
    "                'training_grid': f\"{evaluator.training_grid[0]}x{evaluator.training_grid[1]}\",\n",
    "                'model_path': str(gp_model_path),\n",
    "                'loaded_from': str(gp_model_path),\n",
    "                'note': 'Loaded from pre-trained model'\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to load GP agent from {gp_model_path}: {e}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è GP model not found at: {gp_model_path}\")\n",
    "    \n",
    "    # Load DQN agent\n",
    "    if use_best_models:\n",
    "        dqn_model_path = Path(\"best_dqn_agent.pth\")\n",
    "    else:\n",
    "        training_grid = evaluator.training_grid\n",
    "        dqn_model_path = evaluator.results_dir / f\"dqn_trained_agent_{training_grid[0]}x{training_grid[1]}.pth\"\n",
    "        new_model_path = Path(\"best_dqn_agent.pth\")\n",
    "    if dqn_model_path.exists():\n",
    "        try:\n",
    "            from dqn_snake import DQNAgent, load_dqn_agent_for_viewing\n",
    "            \n",
    "            dqn_agent = load_dqn_agent_for_viewing(str(new_model_path))\n",
    "            \n",
    "            agents['DQN'] = dqn_agent\n",
    "            print(f\"‚úÖ DQN agent loaded from: {dqn_model_path}\")\n",
    "            TRAINING_LOGS['DQN'] = {\n",
    "                'training_time': 0.0,  # No training time since loaded\n",
    "                'training_grid': f\"{training_grid[0]}x{training_grid[1]}\",\n",
    "                'model_path': str(dqn_model_path),\n",
    "                'loaded_from': str(dqn_model_path),\n",
    "                'note': 'Loaded from pre-trained model',\n",
    "                'final_epsilon': 0.0\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to load DQN agent from {dqn_model_path}: {e}\")\n",
    "            print(f\"   Error details: {str(e)}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è DQN model not found at: {dqn_model_path}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Loading completed - {len(agents)} agents ready for evaluation\")\n",
    "    \n",
    "    # Store loaded agents globally for reuse\n",
    "    global TRAINED_AGENTS\n",
    "    TRAINED_AGENTS = agents\n",
    "    \n",
    "    return agents\n",
    "\n",
    "def train_or_load_agents() -> Dict:\n",
    "    \"\"\"\n",
    "    Either train agents from scratch or load pre-trained models based on global configuration\n",
    "    \n",
    "    Returns:\n",
    "        Dict of agents ready for evaluation\n",
    "    \"\"\"\n",
    "    if USE_PRETRAINED_MODELS:\n",
    "        print(f\"üîß Using pre-trained models (best_models={USE_BEST_MODELS})\")\n",
    "        return load_pretrained_agents(use_best_models=USE_BEST_MODELS)\n",
    "    else:\n",
    "        print(f\"üèãÔ∏è Training agents from scratch\")\n",
    "        return train_all_agents()\n",
    "\n",
    "def list_available_models():\n",
    "    \"\"\"List all available pre-trained models\"\"\"\n",
    "    print(\"\\nüìÅ AVAILABLE PRE-TRAINED MODELS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Check for best models\n",
    "    print(\"üèÜ Best Models:\")\n",
    "    best_gp = Path(\"best_gp_agent.json\")\n",
    "    best_dqn = Path(\"best_dqn_agent.pth\")\n",
    "    \n",
    "    if best_gp.exists():\n",
    "        print(f\"  ‚úÖ GP: {best_gp} ({best_gp.stat().st_size / 1024:.1f} KB)\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå GP: {best_gp} (not found)\")\n",
    "    \n",
    "    if best_dqn.exists():\n",
    "        print(f\"  ‚úÖ DQN: {best_dqn} ({best_dqn.stat().st_size / 1024:.1f} KB)\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå DQN: {best_dqn} (not found)\")\n",
    "    \n",
    "    # Check for evaluation results models\n",
    "    print(f\"\\nüìä Evaluation Results Models:\")\n",
    "    eval_dir = Path(\"evaluation_results\")\n",
    "    if eval_dir.exists():\n",
    "        gp_models = list(eval_dir.glob(\"gp_trained_agent_*.json\"))\n",
    "        dqn_models = list(eval_dir.glob(\"dqn_trained_agent_*.pth\"))\n",
    "        \n",
    "        if gp_models:\n",
    "            for model in gp_models:\n",
    "                print(f\"  ‚úÖ GP: {model} ({model.stat().st_size / 1024:.1f} KB)\")\n",
    "        else:\n",
    "            print(\"  ‚ùå No GP models found in evaluation_results/\")\n",
    "        \n",
    "        if dqn_models:\n",
    "            for model in dqn_models:\n",
    "                print(f\"  ‚úÖ DQN: {model} ({model.stat().st_size / 1024:.1f} KB)\")\n",
    "        else:\n",
    "            print(\"  ‚ùå No DQN models found in evaluation_results/\")\n",
    "    else:\n",
    "        print(\"  ‚ùå evaluation_results/ directory not found\")\n",
    "    \n",
    "    print(f\"\\nüí° Configuration:\")\n",
    "    print(f\"  ‚Ä¢ USE_PRETRAINED_MODELS = {USE_PRETRAINED_MODELS}\")\n",
    "    print(f\"  ‚Ä¢ USE_BEST_MODELS = {USE_BEST_MODELS}\")\n",
    "    print(f\"\\nüîß To change configuration, modify the global parameters:\")\n",
    "    print(f\"  ‚Ä¢ Set USE_PRETRAINED_MODELS = True to use pre-trained models\")\n",
    "    print(f\"  ‚Ä¢ Set USE_PRETRAINED_MODELS = False to train from scratch\")\n",
    "    print(f\"  ‚Ä¢ Set USE_BEST_MODELS = True to use best_*.pth/json files\")\n",
    "    print(f\"  ‚Ä¢ Set USE_BEST_MODELS = False to use evaluation_results/ models\")\n",
    "\n",
    "print(\"‚úÖ Pre-trained model loading functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16ef4348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ QUICK EVALUATION USING PRE-TRAINED BEST AGENTS\n",
      "============================================================\n",
      "\n",
      "üìÅ AVAILABLE PRE-TRAINED MODELS\n",
      "==================================================\n",
      "üèÜ Best Models:\n",
      "  ‚ùå GP: best_gp_agent.json (not found)\n",
      "  ‚ùå DQN: best_dqn_agent.pth (not found)\n",
      "\n",
      "üìä Evaluation Results Models:\n",
      "  ‚ùå No GP models found in evaluation_results/\n",
      "  ‚ùå No DQN models found in evaluation_results/\n",
      "\n",
      "üí° Configuration:\n",
      "  ‚Ä¢ USE_PRETRAINED_MODELS = False\n",
      "  ‚Ä¢ USE_BEST_MODELS = False\n",
      "\n",
      "üîß To change configuration, modify the global parameters:\n",
      "  ‚Ä¢ Set USE_PRETRAINED_MODELS = True to use pre-trained models\n",
      "  ‚Ä¢ Set USE_PRETRAINED_MODELS = False to train from scratch\n",
      "  ‚Ä¢ Set USE_BEST_MODELS = True to use best_*.pth/json files\n",
      "  ‚Ä¢ Set USE_BEST_MODELS = False to use evaluation_results/ models\n",
      "\n",
      "üîß Current Configuration:\n",
      "   USE_PRETRAINED_MODELS = False\n",
      "   USE_BEST_MODELS = False\n",
      "\n",
      "üèãÔ∏è TRAINING MODE: Training agents from scratch\n",
      "   ‚è±Ô∏è  This will take longer but ensures fresh training\n",
      "   üéØ Use this for new training runs\n",
      "\n",
      "üí° To switch modes, change the global parameters:\n",
      "   ‚Ä¢ Set USE_PRETRAINED_MODELS = True for fast evaluation\n",
      "   ‚Ä¢ Set USE_PRETRAINED_MODELS = False for training from scratch\n",
      "\n",
      "‚úÖ Ready to run evaluation!\n",
      "üìã Execute the main evaluation cell to start the analysis\n"
     ]
    }
   ],
   "source": [
    "# üöÄ QUICK EVALUATION USING PRE-TRAINED BEST AGENTS\n",
    "print(\"üöÄ QUICK EVALUATION USING PRE-TRAINED BEST AGENTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# List available models first\n",
    "list_available_models()\n",
    "\n",
    "print(f\"\\nüîß Current Configuration:\")\n",
    "print(f\"   USE_PRETRAINED_MODELS = {USE_PRETRAINED_MODELS}\")\n",
    "print(f\"   USE_BEST_MODELS = {USE_BEST_MODELS}\")\n",
    "\n",
    "if USE_PRETRAINED_MODELS:\n",
    "    print(f\"\\nüèÉ FAST EVALUATION MODE: Using pre-trained models\")\n",
    "    print(\"   ‚è±Ô∏è  This will skip training and go directly to testing\")\n",
    "    print(\"   üéØ Perfect for quick comparisons and analysis\")\n",
    "else:\n",
    "    print(f\"\\nüèãÔ∏è TRAINING MODE: Training agents from scratch\")\n",
    "    print(\"   ‚è±Ô∏è  This will take longer but ensures fresh training\")\n",
    "    print(\"   üéØ Use this for new training runs\")\n",
    "\n",
    "print(f\"\\nüí° To switch modes, change the global parameters:\")\n",
    "print(f\"   ‚Ä¢ Set USE_PRETRAINED_MODELS = True for fast evaluation\")\n",
    "print(f\"   ‚Ä¢ Set USE_PRETRAINED_MODELS = False for training from scratch\")\n",
    "\n",
    "# Ready to run evaluation with the configured mode\n",
    "print(f\"\\n‚úÖ Ready to run evaluation!\")\n",
    "print(f\"üìã Execute the main evaluation cell to start the analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4397363b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # üöÄ MODIFIED EVALUATION CELL - RUN THIS INSTEAD OF THE ORIGINAL\n",
    "# print(\"üöÄ STARTING COMPREHENSIVE MULTI-GRID EVALUATION WITH STATISTICAL ANALYSIS\")\n",
    "# print(\"=\" * 90)\n",
    "# print(f\"Training Grid: {evaluator.training_grid[0]}x{evaluator.training_grid[1]}\")\n",
    "# print(f\"Test Grid Sizes: {[f'{w}x{h}' for w, h in evaluator.test_grids]}\")\n",
    "# print(f\"Test Episodes per Grid: {evaluator.test_episodes}\")\n",
    "# print(f\"Total Test Episodes: {len(evaluator.test_grids) * 3 * evaluator.test_episodes}\")\n",
    "# print(f\"Statistical Analysis: PSO-NN (GP) vs Simple Agents (A*, DQN)\")\n",
    "# print(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "# print(f\"Mode: {'Pre-trained Models' if USE_PRETRAINED_MODELS else 'Training from Scratch'}\")\n",
    "# print(\"=\" * 90)\n",
    "\n",
    "# # Initialize storage for multi-grid results\n",
    "# MULTI_GRID_RESULTS = {}\n",
    "# MULTI_GRID_EPISODE_DATA = {}\n",
    "\n",
    "# # Phase 1: Load pre-trained agents or train from scratch based on configuration\n",
    "# print(f\"\\n\" + \"üèãÔ∏è\" * 20)\n",
    "# if USE_PRETRAINED_MODELS:\n",
    "#     print(f\"üîß PHASE 1: LOADING PRE-TRAINED BEST AGENTS\")\n",
    "#     print(f\"üîß Using {'best models' if USE_BEST_MODELS else 'evaluation results models'}\")\n",
    "# else:\n",
    "#     print(f\"üèãÔ∏è PHASE 1: TRAINING ALL AGENTS ON {evaluator.training_grid[0]}x{evaluator.training_grid[1]} GRID\")\n",
    "# print(\"üèãÔ∏è\" * 20)\n",
    "\n",
    "# # Use the new train_or_load_agents function that respects global configuration\n",
    "# trained_agents = train_or_load_agents()\n",
    "\n",
    "# if not trained_agents:\n",
    "#     if USE_PRETRAINED_MODELS:\n",
    "#         print(\"‚ùå No agents were successfully loaded. Check if model files exist.\")\n",
    "#     else:\n",
    "#         print(\"‚ùå No agents were successfully trained. Stopping evaluation.\")\n",
    "# else:\n",
    "#     print(f\"\\n‚úÖ {'Loading' if USE_PRETRAINED_MODELS else 'Training'} phase completed! {len(trained_agents)} agents ready:\")\n",
    "#     for agent_name in trained_agents.keys():\n",
    "#         training_time = TRAINING_LOGS.get(agent_name, {}).get('training_time', 0)\n",
    "#         agent_category = 'PSO-NN' if agent_name == 'GP' else 'Simple Agent'\n",
    "#         loaded_from = TRAINING_LOGS.get(agent_name, {}).get('loaded_from', 'training')\n",
    "#         if USE_PRETRAINED_MODELS and training_time == 0:\n",
    "#             print(f\"   ‚Ä¢ {agent_name} ({agent_category}): Loaded from {loaded_from}\")\n",
    "#         else:\n",
    "#             print(f\"   ‚Ä¢ {agent_name} ({agent_category}): {training_time:.1f}s training time\")\n",
    "\n",
    "#     # Phase 2: Test all trained agents on all grid sizes\n",
    "#     print(f\"\\n\" + \"üéØ\" * 20)\n",
    "#     print(f\"üéØ PHASE 2: TESTING AGENTS ON ALL GRID SIZES\")\n",
    "#     print(\"üéØ\" * 20)\n",
    "    \n",
    "#     all_grid_test_results = test_all_agents_on_all_grids(trained_agents)\n",
    "    \n",
    "#     # Phase 3: Calculate metrics for each grid\n",
    "#     print(f\"\\n\" + \"üìä\" * 20)\n",
    "#     print(f\"üìä PHASE 3: CALCULATING METRICS AND STATISTICAL ANALYSIS\")\n",
    "#     print(\"üìä\" * 20)\n",
    "    \n",
    "#     for grid_key, grid_test_results in all_grid_test_results.items():\n",
    "#         width, height = map(int, grid_key.split('x'))\n",
    "        \n",
    "#         # Convert episode results to DataFrame for analysis\n",
    "#         grid_episodes = []\n",
    "#         for agent_name, episodes in grid_test_results.items():\n",
    "#             for episode in episodes:\n",
    "#                 episode_copy = episode.copy()\n",
    "#                 episode_copy['agent'] = agent_name\n",
    "#                 grid_episodes.append(episode_copy)\n",
    "        \n",
    "#         if grid_episodes:\n",
    "#             grid_df = pd.DataFrame(grid_episodes)\n",
    "#             grid_metrics = evaluator.calculate_research_paper_metrics(grid_df, width, height)\n",
    "#             MULTI_GRID_RESULTS[grid_key] = grid_metrics\n",
    "            \n",
    "#             print(f\"‚úÖ {grid_key} grid metrics calculated\")\n",
    "#         else:\n",
    "#             print(f\"‚ö†Ô∏è No valid episodes for {grid_key} grid\")\n",
    "    \n",
    "#     # Store episode data for detailed statistical analysis\n",
    "#     MULTI_GRID_EPISODE_DATA = all_grid_test_results\n",
    "\n",
    "# print(f\"\\n\" + \"=\" * 90)\n",
    "# print(\"üéä MULTI-GRID EVALUATION WITH STATISTICAL ANALYSIS COMPLETED!\")\n",
    "# print(\"=\" * 90)\n",
    "\n",
    "# if USE_PRETRAINED_MODELS:\n",
    "#     print(f\"‚ö° Fast evaluation mode completed using pre-trained models\")\n",
    "#     print(f\"üèÜ Used {'best models' if USE_BEST_MODELS else 'evaluation results models'}\")\n",
    "# else:\n",
    "#     print(f\"üèãÔ∏è Full training and evaluation completed\")\n",
    "\n",
    "# print(f\"üìä Ready for statistical analysis and visualization!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3bea72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Multi-grid generalization analysis functions defined!\n"
     ]
    }
   ],
   "source": [
    "def generate_multi_grid_research_tables(multi_grid_data: Dict[str, Dict]):\n",
    "    \"\"\"Generate research paper format tables for all grid sizes\"\"\"\n",
    "    print(\"\\nüìä GENERATING MULTI-GRID RESEARCH PAPER FORMAT TABLES\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    all_tables_data = []\n",
    "    training_grid = evaluator.training_grid\n",
    "    \n",
    "    for grid_key, grid_results in multi_grid_data.items():\n",
    "        width, height = map(int, grid_key.split('x'))\n",
    "        is_training_grid = (width, height) == training_grid\n",
    "        grid_type = \"Training\" if is_training_grid else \"Test\"\n",
    "        complexity_ratio = (width * height) / (training_grid[0] * training_grid[1])\n",
    "        \n",
    "        print(f\"\\nüìã TABLES FOR {grid_key} GRID ({grid_type} Grid, Complexity Ratio: {complexity_ratio:.2f})\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # Table II: Mean Points Scored\n",
    "        print(f\"\\nTABLE II: Mean Points Scored - {grid_key} Grid\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"{'Agent':<12} {'pÃÑ':<10} {'œÉp':<10} {'Max':<10} {'Generalization':<15}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for agent, data in grid_results.items():\n",
    "            generalization_desc = \"Same\" if is_training_grid else f\"{complexity_ratio:.1f}x\"\n",
    "            print(f\"{agent:<12} {data['p_mean']:<10.3f} {data['p_std']:<10.3f} {data['max_score']:<10} {generalization_desc:<15}\")\n",
    "            all_tables_data.append({\n",
    "                'Grid_Size': grid_key,\n",
    "                'Grid_Width': width,\n",
    "                'Grid_Height': height,\n",
    "                'Complexity': width * height,\n",
    "                'Training_Grid': f\"{training_grid[0]}x{training_grid[1]}\",\n",
    "                'Is_Training_Grid': is_training_grid,\n",
    "                'Complexity_Ratio': complexity_ratio,\n",
    "                'Agent': agent,\n",
    "                'Metric': 'Points',\n",
    "                'Mean': data['p_mean'],\n",
    "                'Std': data['p_std'],\n",
    "                'Max_Value': data['max_score'],\n",
    "                'Success_Rate': data['success_rate']\n",
    "            })\n",
    "        \n",
    "        # Table III: Mean Games Won\n",
    "        print(f\"\\nTABLE III: Mean Games Won - {grid_key} Grid\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"{'Agent':<12} {'qÃÑ':<10} {'œÉq':<10} {'Win %':<10} {'Generalization':<15}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for agent, data in grid_results.items():\n",
    "            generalization_desc = \"Same\" if is_training_grid else f\"{complexity_ratio:.1f}x\"\n",
    "            print(f\"{agent:<12} {data['q_mean']:<10.3f} {data['q_std']:<10.3f} {data['q_mean']:<10.1f}% {generalization_desc:<15}\")\n",
    "            all_tables_data.append({\n",
    "                'Grid_Size': grid_key,\n",
    "                'Grid_Width': width,\n",
    "                'Grid_Height': height,\n",
    "                'Complexity': width * height,\n",
    "                'Training_Grid': f\"{training_grid[0]}x{training_grid[1]}\",\n",
    "                'Is_Training_Grid': is_training_grid,\n",
    "                'Complexity_Ratio': complexity_ratio,\n",
    "                'Agent': agent,\n",
    "                'Metric': 'Games_Won',\n",
    "                'Mean': data['q_mean'],\n",
    "                'Std': data['q_std'],\n",
    "                'Max_Value': 100.0,\n",
    "                'Success_Rate': data['success_rate']\n",
    "            })\n",
    "        \n",
    "        # Table IV: Mean Moves Made\n",
    "        print(f\"\\nTABLE IV: Mean Moves Made - {grid_key} Grid\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"{'Agent':<12} {'rÃÑ':<10} {'œÉr':<10} {'Generalization':<15}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for agent, data in grid_results.items():\n",
    "            generalization_desc = \"Same\" if is_training_grid else f\"{complexity_ratio:.1f}x\"\n",
    "            print(f\"{agent:<12} {data['r_mean']:<10.3f} {data['r_std']:<10.3f} {generalization_desc:<15}\")\n",
    "            all_tables_data.append({\n",
    "                'Grid_Size': grid_key,\n",
    "                'Grid_Width': width,\n",
    "                'Grid_Height': height,\n",
    "                'Complexity': width * height,\n",
    "                'Training_Grid': f\"{training_grid[0]}x{training_grid[1]}\",\n",
    "                'Is_Training_Grid': is_training_grid,\n",
    "                'Complexity_Ratio': complexity_ratio,\n",
    "                'Agent': agent,\n",
    "                'Metric': 'Moves',\n",
    "                'Mean': data['r_mean'],\n",
    "                'Std': data['r_std'],\n",
    "                'Max_Value': np.nan,\n",
    "                'Success_Rate': data['success_rate']\n",
    "            })\n",
    "    \n",
    "    # Create comprehensive multi-grid DataFrame\n",
    "    multi_grid_df = pd.DataFrame(all_tables_data)\n",
    "    \n",
    "    # Generate generalization summary\n",
    "    print(f\"\\nüîÑ GENERALIZATION PERFORMANCE SUMMARY\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Training Grid: {training_grid[0]}x{training_grid[1]}\")\n",
    "    print(f\"{'Grid':<8} {'Type':<10} {'Complexity':<12} {'A* Score':<10} {'GP Score':<10} {'DQN Score':<10}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for grid_key, grid_results in multi_grid_data.items():\n",
    "        width, height = map(int, grid_key.split('x'))\n",
    "        is_training_grid = (width, height) == training_grid\n",
    "        grid_type = \"Training\" if is_training_grid else \"Test\"\n",
    "        complexity_ratio = (width * height) / (training_grid[0] * training_grid[1])\n",
    "        \n",
    "        scores = {}\n",
    "        for agent, data in grid_results.items():\n",
    "            scores[agent] = data['p_mean']\n",
    "        \n",
    "        print(f\"{grid_key:<8} {grid_type:<10} {complexity_ratio:<12.2f} \"\n",
    "              f\"{scores.get('A*', 0):<10.2f} {scores.get('GP', 0):<10.2f} {scores.get('DQN', 0):<10.2f}\")\n",
    "    \n",
    "    # Save comprehensive results\n",
    "    multi_grid_file = evaluator.results_dir / f\"multi_grid_research_tables_{timestamp}.csv\"\n",
    "    multi_grid_df.to_csv(multi_grid_file, index=False)\n",
    "    \n",
    "    print(f\"\\nüíæ Multi-grid research tables saved to: {multi_grid_file}\")\n",
    "    \n",
    "    return multi_grid_df\n",
    "\n",
    "def generate_generalization_analysis(generalization_df: pd.DataFrame):\n",
    "    \"\"\"Generate analysis of how well agents generalize across grid sizes\"\"\"\n",
    "    print(\"\\nÔøΩ GENERALIZATION PERFORMANCE ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    training_grid = evaluator.training_grid\n",
    "    training_complexity = training_grid[0] * training_grid[1]\n",
    "    \n",
    "    # Calculate generalization metrics\n",
    "    generalization_summary = []\n",
    "    \n",
    "    for agent in generalization_df['agent'].unique():\n",
    "        agent_data = generalization_df[generalization_df['agent'] == agent]\n",
    "        \n",
    "        # Performance on training grid\n",
    "        training_performance = agent_data[agent_data['is_training_grid']]['points_mean'].iloc[0] if any(agent_data['is_training_grid']) else 0\n",
    "        \n",
    "        # Performance on test grids\n",
    "        test_data = agent_data[~agent_data['is_training_grid']]\n",
    "        \n",
    "        if len(test_data) > 0:\n",
    "            avg_test_performance = test_data['points_mean'].mean()\n",
    "            min_test_performance = test_data['points_mean'].min()\n",
    "            max_test_performance = test_data['points_mean'].max()\n",
    "            performance_drop = training_performance - avg_test_performance\n",
    "            relative_drop = (performance_drop / training_performance * 100) if training_performance > 0 else 0\n",
    "            \n",
    "            # Generalization robustness (lower std = more robust)\n",
    "            performance_std = test_data['points_mean'].std()\n",
    "            \n",
    "            generalization_summary.append({\n",
    "                'Agent': agent,\n",
    "                'Training_Performance': training_performance,\n",
    "                'Avg_Test_Performance': avg_test_performance,\n",
    "                'Min_Test_Performance': min_test_performance,\n",
    "                'Max_Test_Performance': max_test_performance,\n",
    "                'Performance_Drop': performance_drop,\n",
    "                'Relative_Drop_Percent': relative_drop,\n",
    "                'Performance_Std': performance_std,\n",
    "                'Generalization_Score': max(0, 100 - relative_drop - performance_std * 10)  # Custom metric\n",
    "            })\n",
    "    \n",
    "    generalization_summary_df = pd.DataFrame(generalization_summary)\n",
    "    \n",
    "    # Print generalization analysis\n",
    "    print(\"\\nüéØ AGENT GENERALIZATION ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"{'Agent':<8} {'Training':<10} {'Avg Test':<10} {'Drop %':<8} {'Robust.':<8} {'Gen. Score':<10}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for _, row in generalization_summary_df.iterrows():\n",
    "        print(f\"{row['Agent']:<8} {row['Training_Performance']:<10.2f} {row['Avg_Test_Performance']:<10.2f} \"\n",
    "              f\"{row['Relative_Drop_Percent']:<8.1f} {row['Performance_Std']:<8.2f} {row['Generalization_Score']:<10.1f}\")\n",
    "    \n",
    "    # Complexity-specific analysis\n",
    "    print(f\"\\nüìà PERFORMANCE BY COMPLEXITY RATIO\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    complexity_analysis = generalization_df.groupby(['agent', 'generalization_type'])['points_mean'].agg(['mean', 'std']).round(3)\n",
    "    print(complexity_analysis)\n",
    "    \n",
    "    return generalization_summary_df\n",
    "\n",
    "def save_multi_grid_results(multi_grid_results: Dict, timestamp: str = None):\n",
    "    \"\"\"Save comprehensive multi-grid results with generalization metrics\"\"\"\n",
    "    if timestamp is None:\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    # Save comprehensive results as JSON\n",
    "    results_file = evaluator.results_dir / f\"multi_grid_results_{timestamp}.json\"\n",
    "    \n",
    "    # Prepare data for JSON serialization\n",
    "    json_data = {\n",
    "        'metadata': {\n",
    "            'timestamp': timestamp,\n",
    "            'training_grid': f\"{evaluator.training_grid[0]}x{evaluator.training_grid[1]}\",\n",
    "            'test_grids': [f\"{w}x{h}\" for w, h in evaluator.test_grids],\n",
    "            'test_episodes_per_grid': evaluator.test_episodes,\n",
    "            'total_episodes': len(evaluator.test_grids) * evaluator.test_episodes,\n",
    "            'training_logs': TRAINING_LOGS\n",
    "        },\n",
    "        'results_by_grid': {}\n",
    "    }\n",
    "    \n",
    "    # Convert results to JSON-serializable format\n",
    "    for grid_key, grid_data in multi_grid_results.items():\n",
    "        json_data['results_by_grid'][grid_key] = {}\n",
    "        for agent, agent_data in grid_data.items():\n",
    "            if isinstance(agent_data, list):  # Episode results\n",
    "                json_data['results_by_grid'][grid_key][agent] = agent_data\n",
    "            else:  # Metrics dict\n",
    "                json_data['results_by_grid'][grid_key][agent] = {\n",
    "                    k: v for k, v in agent_data.items() \n",
    "                    if not k.endswith('_data')  # Remove raw data arrays\n",
    "                }\n",
    "    \n",
    "    with open(results_file, 'w') as f:\n",
    "        json.dump(json_data, f, indent=2)\n",
    "    \n",
    "    # Save episode-level results as CSV\n",
    "    all_csv_data = []\n",
    "    for grid_key, grid_data in multi_grid_results.items():\n",
    "        for agent, results_list in grid_data.items():\n",
    "            if isinstance(results_list, list):  # Raw episode results\n",
    "                for result in results_list:\n",
    "                    row = result.copy()\n",
    "                    row['agent'] = agent\n",
    "                    all_csv_data.append(row)\n",
    "    \n",
    "    if all_csv_data:\n",
    "        df = pd.DataFrame(all_csv_data)\n",
    "        csv_file = evaluator.results_dir / f\"multi_grid_episodes_{timestamp}.csv\"\n",
    "        df.to_csv(csv_file, index=False)\n",
    "        \n",
    "        print(f\"üíæ Multi-grid results saved:\")\n",
    "        print(f\"   JSON: {results_file}\")\n",
    "        print(f\"   CSV: {csv_file}\")\n",
    "        \n",
    "        return df\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No episode results to save\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "print(\"‚úÖ Multi-grid generalization analysis functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a72c48c-9a96-46dd-ae22-ff9975e2ae9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Research paper statistical analysis functions defined!\n"
     ]
    }
   ],
   "source": [
    "def generate_research_paper_statistical_tables(multi_grid_data: Dict[str, Dict], detailed_episode_data: Dict[str, Dict]):\n",
    "    \"\"\"Generate statistical tables exactly matching the research paper format with p-values\"\"\"\n",
    "    print(\"\\nüìä GENERATING RESEARCH PAPER STATISTICAL TABLES WITH P-VALUES\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    statistical_results = {}\n",
    "    \n",
    "    # Define agent categories as per your specification\n",
    "    pso_nn_agent = 'GP'  # GP is your PSO-NN equivalent\n",
    "    simple_agents = ['A*', 'DQN']  # These are your baseline simple agents\n",
    "    \n",
    "    for grid_key, grid_metrics in multi_grid_data.items():\n",
    "        width, height = map(int, grid_key.split('x'))\n",
    "        print(f\"\\nüìã STATISTICAL TABLE FOR {grid_key} GRID\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Get raw episode data for statistical tests\n",
    "        grid_episode_data = detailed_episode_data.get(grid_key, {})\n",
    "        \n",
    "        # Extract PSO-NN (GP) data\n",
    "        if pso_nn_agent in grid_metrics and pso_nn_agent in grid_episode_data:\n",
    "            pso_episodes = grid_episode_data[pso_nn_agent]\n",
    "            pso_points = [ep['score'] for ep in pso_episodes]\n",
    "            pso_games_won = [(ep['score'] >= (width * height - 3) * 0.8) * 100 for ep in pso_episodes]  # Games won as percentage\n",
    "            pso_moves = [ep['steps'] for ep in pso_episodes]\n",
    "            \n",
    "            pso_stats = {\n",
    "                'points_mean': np.mean(pso_points),\n",
    "                'points_std': np.std(pso_points, ddof=1),\n",
    "                'games_won_mean': np.mean(pso_games_won),\n",
    "                'games_won_std': np.std(pso_games_won, ddof=1),\n",
    "                'moves_mean': np.mean(pso_moves),\n",
    "                'moves_std': np.std(pso_moves, ddof=1),\n",
    "                'points_data': pso_points,\n",
    "                'games_won_data': pso_games_won,\n",
    "                'moves_data': pso_moves\n",
    "            }\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Warning: PSO-NN (GP) data not found for {grid_key}\")\n",
    "            continue\n",
    "        \n",
    "        # Statistical comparison results\n",
    "        statistical_comparisons = {\n",
    "            'grid_size': grid_key,\n",
    "            'grid_width': width,\n",
    "            'grid_height': height,\n",
    "            'pso_nn_stats': pso_stats,\n",
    "            'simple_agents_stats': {},\n",
    "            'statistical_tests': {}\n",
    "        }\n",
    "        \n",
    "        # Compare against each simple agent\n",
    "        for agent in simple_agents:\n",
    "            if agent in grid_metrics and agent in grid_episode_data:\n",
    "                agent_episodes = grid_episode_data[agent]\n",
    "                agent_points = [ep['score'] for ep in agent_episodes]\n",
    "                agent_games_won = [(ep['score'] >= (width * height - 3) * 0.8) * 100 for ep in agent_episodes]\n",
    "                agent_moves = [ep['steps'] for ep in agent_episodes]\n",
    "                \n",
    "                agent_stats = {\n",
    "                    'points_mean': np.mean(agent_points),\n",
    "                    'points_std': np.std(agent_points, ddof=1),\n",
    "                    'games_won_mean': np.mean(agent_games_won),\n",
    "                    'games_won_std': np.std(agent_games_won, ddof=1),\n",
    "                    'moves_mean': np.mean(agent_moves),\n",
    "                    'moves_std': np.std(agent_moves, ddof=1),\n",
    "                    'points_data': agent_points,\n",
    "                    'games_won_data': agent_games_won,\n",
    "                    'moves_data': agent_moves\n",
    "                }\n",
    "                \n",
    "                statistical_comparisons['simple_agents_stats'][agent] = agent_stats\n",
    "                \n",
    "                # Perform Mann-Whitney U tests\n",
    "                try:\n",
    "                    # Points comparison\n",
    "                    stat_p, pval_p = stats.mannwhitneyu(\n",
    "                        pso_points, agent_points, alternative='two-sided'\n",
    "                    )\n",
    "                    \n",
    "                    # Games won comparison  \n",
    "                    stat_g, pval_g = stats.mannwhitneyu(\n",
    "                        pso_games_won, agent_games_won, alternative='two-sided'\n",
    "                    )\n",
    "                    \n",
    "                    # Moves comparison\n",
    "                    stat_m, pval_m = stats.mannwhitneyu(\n",
    "                        pso_moves, agent_moves, alternative='two-sided'\n",
    "                    )\n",
    "                    \n",
    "                    statistical_comparisons['statistical_tests'][agent] = {\n",
    "                        'points_pvalue': pval_p,\n",
    "                        'games_won_pvalue': pval_g, \n",
    "                        'moves_pvalue': pval_m,\n",
    "                        'points_significant': pval_p < evaluator.significance_level,\n",
    "                        'games_won_significant': pval_g < evaluator.significance_level,\n",
    "                        'moves_significant': pval_m < evaluator.significance_level\n",
    "                    }\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Statistical test failed for {agent} on {grid_key}: {e}\")\n",
    "                    statistical_comparisons['statistical_tests'][agent] = {\n",
    "                        'points_pvalue': 1.0,\n",
    "                        'games_won_pvalue': 1.0,\n",
    "                        'moves_pvalue': 1.0,\n",
    "                        'points_significant': False,\n",
    "                        'games_won_significant': False,\n",
    "                        'moves_significant': False\n",
    "                    }\n",
    "        \n",
    "        statistical_results[grid_key] = statistical_comparisons\n",
    "        \n",
    "        # Print TABLE II: Mean Points Scored (Research Paper Format)\n",
    "        print(f\"\\nTABLE II: Mean Points Scored - {grid_key} Grid\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"{'Grid':<8} | {'PSO-NN':<20} | {'Simple Agents':<40} | {'p-value':<15}\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"{'Size':<8} | {'pÃÑ':<8} {'œÉp':<8} | {'Agent':<8} {'pÃÑ':<8} {'œÉp':<8} | {'(vs PSO-NN)':<15}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        for i, agent in enumerate(simple_agents):\n",
    "            if agent in statistical_comparisons['simple_agents_stats']:\n",
    "                agent_stats = statistical_comparisons['simple_agents_stats'][agent]\n",
    "                test_results = statistical_comparisons['statistical_tests'][agent]\n",
    "                \n",
    "                pvalue_str = f\"{test_results['points_pvalue']:.3e}\"\n",
    "                if test_results['points_significant']:\n",
    "                    pvalue_str = f\"**{pvalue_str}**\"  # Bold for significant results\n",
    "                \n",
    "                if i == 0:  # First row shows PSO-NN stats\n",
    "                    print(f\"{grid_key:<8} | {pso_stats['points_mean']:<8.3f} {pso_stats['points_std']:<8.3f} | \"\n",
    "                          f\"{agent:<8} {agent_stats['points_mean']:<8.3f} {agent_stats['points_std']:<8.3f} | {pvalue_str:<15}\")\n",
    "                else:  # Subsequent rows only show simple agent stats\n",
    "                    print(f\"{'':8} | {'':8} {'':8} | \"\n",
    "                          f\"{agent:<8} {agent_stats['points_mean']:<8.3f} {agent_stats['points_std']:<8.3f} | {pvalue_str:<15}\")\n",
    "        \n",
    "        # Print TABLE III: Games Won\n",
    "        print(f\"\\nTABLE III: Games Won (%) - {grid_key} Grid\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"{'Grid':<8} | {'PSO-NN':<20} | {'Simple Agents':<40} | {'p-value':<15}\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"{'Size':<8} | {'qÃÑ':<8} {'œÉq':<8} | {'Agent':<8} {'qÃÑ':<8} {'œÉq':<8} | {'(vs PSO-NN)':<15}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        for i, agent in enumerate(simple_agents):\n",
    "            if agent in statistical_comparisons['simple_agents_stats']:\n",
    "                agent_stats = statistical_comparisons['simple_agents_stats'][agent]\n",
    "                test_results = statistical_comparisons['statistical_tests'][agent]\n",
    "                \n",
    "                pvalue_str = f\"{test_results['games_won_pvalue']:.3e}\"\n",
    "                if test_results['games_won_significant']:\n",
    "                    pvalue_str = f\"**{pvalue_str}**\"\n",
    "                \n",
    "                if i == 0:\n",
    "                    print(f\"{grid_key:<8} | {pso_stats['games_won_mean']:<8.3f} {pso_stats['games_won_std']:<8.3f} | \"\n",
    "                          f\"{agent:<8} {agent_stats['games_won_mean']:<8.3f} {agent_stats['games_won_std']:<8.3f} | {pvalue_str:<15}\")\n",
    "                else:\n",
    "                    print(f\"{'':8} | {'':8} {'':8} | \"\n",
    "                          f\"{agent:<8} {agent_stats['games_won_mean']:<8.3f} {agent_stats['games_won_std']:<8.3f} | {pvalue_str:<15}\")\n",
    "        \n",
    "        # Print TABLE IV: Mean Moves Made\n",
    "        print(f\"\\nTABLE IV: Mean Moves Made - {grid_key} Grid\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"{'Grid':<8} | {'PSO-NN':<20} | {'Simple Agents':<40} | {'p-value':<15}\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"{'Size':<8} | {'rÃÑ':<8} {'œÉr':<8} | {'Agent':<8} {'rÃÑ':<8} {'œÉr':<8} | {'(vs PSO-NN)':<15}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        for i, agent in enumerate(simple_agents):\n",
    "            if agent in statistical_comparisons['simple_agents_stats']:\n",
    "                agent_stats = statistical_comparisons['simple_agents_stats'][agent]\n",
    "                test_results = statistical_comparisons['statistical_tests'][agent]\n",
    "                \n",
    "                pvalue_str = f\"{test_results['moves_pvalue']:.3e}\"\n",
    "                if test_results['moves_significant']:\n",
    "                    pvalue_str = f\"**{pvalue_str}**\"\n",
    "                \n",
    "                if i == 0:\n",
    "                    print(f\"{grid_key:<8} | {pso_stats['moves_mean']:<8.3f} {pso_stats['moves_std']:<8.3f} | \"\n",
    "                          f\"{agent:<8} {agent_stats['moves_mean']:<8.3f} {agent_stats['moves_std']:<8.3f} | {pvalue_str:<15}\")\n",
    "                else:\n",
    "                    print(f\"{'':8} | {'':8} {'':8} | \"\n",
    "                          f\"{agent:<8} {agent_stats['moves_mean']:<8.3f} {agent_stats['moves_std']:<8.3f} | {pvalue_str:<15}\")\n",
    "    \n",
    "    # Save statistical results to files\n",
    "    save_statistical_tables_to_files(statistical_results, timestamp)\n",
    "    \n",
    "    return statistical_results\n",
    "\n",
    "def save_statistical_tables_to_files(statistical_results: Dict, timestamp: str):\n",
    "    \"\"\"Save statistical tables in multiple formats (CSV, JSON, LaTeX)\"\"\"\n",
    "    print(f\"\\nüíæ SAVING STATISTICAL TABLES TO FILES\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Create a custom JSON encoder to handle numpy types and other non-standard types\n",
    "    class NumpyEncoder(json.JSONEncoder):\n",
    "        def default(self, obj):\n",
    "            if isinstance(obj, (np.bool_, bool)):\n",
    "                return bool(obj)  # Convert numpy boolean to Python boolean\n",
    "            elif isinstance(obj, (np.integer, np.floating)):\n",
    "                return obj.item()  # Convert numpy number to Python number\n",
    "            elif isinstance(obj, np.ndarray):\n",
    "                return obj.tolist()  # Convert numpy array to list\n",
    "            return super(NumpyEncoder, self).default(obj)\n",
    "    \n",
    "    # Save detailed statistical results as JSON\n",
    "    json_file = evaluator.results_dir / f\"statistical_analysis_{timestamp}.json\"\n",
    "    with open(json_file, 'w') as f:\n",
    "        # Convert numpy arrays to lists for JSON serialization\n",
    "        json_data = {}\n",
    "        for grid_key, grid_stats in statistical_results.items():\n",
    "            json_data[grid_key] = {\n",
    "                'grid_size': grid_stats['grid_size'],\n",
    "                'grid_width': grid_stats['grid_width'],\n",
    "                'grid_height': grid_stats['grid_height'],\n",
    "                'pso_nn_stats': {\n",
    "                    k: v for k, v in grid_stats['pso_nn_stats'].items() \n",
    "                    if not k.endswith('_data')  # Exclude raw data arrays\n",
    "                },\n",
    "                'simple_agents_stats': {\n",
    "                    agent: {k: v for k, v in stats.items() if not k.endswith('_data')}\n",
    "                    for agent, stats in grid_stats['simple_agents_stats'].items()\n",
    "                },\n",
    "                'statistical_tests': grid_stats['statistical_tests']\n",
    "            }\n",
    "        # Use the custom encoder to properly handle numpy types\n",
    "        json.dump(json_data, f, indent=2, cls=NumpyEncoder)\n",
    "    \n",
    "    # Save as CSV for easy analysis\n",
    "    csv_data = []\n",
    "    for grid_key, grid_stats in statistical_results.items():\n",
    "        pso_stats = grid_stats['pso_nn_stats']\n",
    "        \n",
    "        for agent, agent_stats in grid_stats['simple_agents_stats'].items():\n",
    "            test_results = grid_stats['statistical_tests'][agent]\n",
    "            \n",
    "            csv_data.append({\n",
    "                'Grid_Size': grid_key,\n",
    "                'PSO_NN_Agent': 'GP',\n",
    "                'Simple_Agent': agent,\n",
    "                \n",
    "                # Points metrics\n",
    "                'PSO_NN_Points_Mean': pso_stats['points_mean'],\n",
    "                'PSO_NN_Points_Std': pso_stats['points_std'],\n",
    "                'Simple_Agent_Points_Mean': agent_stats['points_mean'],\n",
    "                'Simple_Agent_Points_Std': agent_stats['points_std'],\n",
    "                'Points_P_Value': test_results['points_pvalue'],\n",
    "                'Points_Significant': test_results['points_significant'],\n",
    "                \n",
    "                # Games won metrics\n",
    "                'PSO_NN_Games_Won_Mean': pso_stats['games_won_mean'],\n",
    "                'PSO_NN_Games_Won_Std': pso_stats['games_won_std'],\n",
    "                'Simple_Agent_Games_Won_Mean': agent_stats['games_won_mean'],\n",
    "                'Simple_Agent_Games_Won_Std': agent_stats['games_won_std'],\n",
    "                'Games_Won_P_Value': test_results['games_won_pvalue'],\n",
    "                'Games_Won_Significant': test_results['games_won_significant'],\n",
    "                \n",
    "                # Moves metrics\n",
    "                'PSO_NN_Moves_Mean': pso_stats['moves_mean'],\n",
    "                'PSO_NN_Moves_Std': pso_stats['moves_std'],\n",
    "                'Simple_Agent_Moves_Mean': agent_stats['moves_mean'],\n",
    "                'Simple_Agent_Moves_Std': agent_stats['moves_std'],\n",
    "                'Moves_P_Value': test_results['moves_pvalue'],\n",
    "                'Moves_Significant': test_results['moves_significant']\n",
    "            })\n",
    "    \n",
    "    csv_file = evaluator.results_dir / f\"statistical_comparison_{timestamp}.csv\"\n",
    "    pd.DataFrame(csv_data).to_csv(csv_file, index=False)\n",
    "    \n",
    "    # Generate LaTeX table format\n",
    "    latex_file = evaluator.results_dir / f\"statistical_tables_{timestamp}.tex\"\n",
    "    generate_latex_tables(statistical_results, latex_file)\n",
    "    \n",
    "    print(f\"‚úÖ Statistical results saved:\")\n",
    "    print(f\"   JSON: {json_file}\")\n",
    "    print(f\"   CSV: {csv_file}\")\n",
    "    print(f\"   LaTeX: {latex_file}\")\n",
    "\n",
    "def generate_latex_tables(statistical_results: Dict, output_file: Path):\n",
    "    \"\"\"Generate LaTeX format tables matching the research paper exactly\"\"\"\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(\"% Statistical Analysis Tables - Snake Game Agents\\n\")\n",
    "        f.write(\"% Generated automatically from multi-grid evaluation\\n\\n\")\n",
    "        \n",
    "        for table_type in ['points', 'games_won', 'moves']:\n",
    "            if table_type == 'points':\n",
    "                f.write(\"% TABLE II: Mean Points Scored\\n\")\n",
    "                f.write(\"\\\\begin{table}[h]\\n\")\n",
    "                f.write(\"\\\\begin{center}\\n\")\n",
    "                f.write(\"\\\\captionsetup{labelformat=empty}\\n\")\n",
    "                f.write(\"\\\\caption{TABLE II\\\\\\\\\\n\")\n",
    "                f.write(\"Comparison of Mean Points Scored by the Techniques}\\n\")\n",
    "                metric_symbol = 'p'\n",
    "                title = \"Points Scored\"\n",
    "            elif table_type == 'games_won':\n",
    "                f.write(\"% TABLE III: Games Won\\n\")\n",
    "                f.write(\"\\\\begin{table}[h]\\n\")\n",
    "                f.write(\"\\\\begin{center}\\n\")\n",
    "                f.write(\"\\\\captionsetup{labelformat=empty}\\n\")\n",
    "                f.write(\"\\\\caption{TABLE III\\\\\\\\\\n\")\n",
    "                f.write(\"Comparison of Games Won by the Techniques}\\n\")\n",
    "                metric_symbol = 'q'\n",
    "                title = \"Games Won (%)\"\n",
    "            else:  # moves\n",
    "                f.write(\"% TABLE IV: Mean Moves Made\\n\")\n",
    "                f.write(\"\\\\begin{table}[h]\\n\")\n",
    "                f.write(\"\\\\begin{center}\\n\")\n",
    "                f.write(\"\\\\captionsetup{labelformat=empty}\\n\")\n",
    "                f.write(\"\\\\caption{TABLE IV\\\\\\\\\\n\")\n",
    "                f.write(\"Comparison of Mean Moves Made by the Techniques}\\n\")\n",
    "                metric_symbol = 'r'\n",
    "                title = \"Moves Made\"\n",
    "            \n",
    "            # Table header\n",
    "            f.write(\"\\\\begin{tabular}{|l|l|l|l|l|l|l|}\\n\")\n",
    "            f.write(\"\\\\hline\\n\")\n",
    "            f.write(\"\\\\multirow{2}{*}{Grid} & \\\\multicolumn{2}{|c|}{PSO-NN} & \\\\multicolumn{3}{|c|}{Simple Agents} & \\\\multirow{2}{*}{$p$-value} \\\\\\\\\\n\")\n",
    "            f.write(\"\\\\hline\\n\")\n",
    "            f.write(f\" & $\\\\overline{{\\\\boldsymbol{{{metric_symbol}}}}}$ & $\\\\sigma_{{{metric_symbol}}}$ & Agent & $\\\\bar{{{metric_symbol}}}$ & $\\\\sigma_{{{metric_symbol}}}$ &  \\\\\\\\\\n\")\n",
    "            f.write(\"\\\\hline\\n\")\n",
    "            \n",
    "            # Table data\n",
    "            for grid_key in sorted(statistical_results.keys()):\n",
    "                grid_stats = statistical_results[grid_key]\n",
    "                pso_stats = grid_stats['pso_nn_stats']\n",
    "                simple_agents = list(grid_stats['simple_agents_stats'].keys())\n",
    "                \n",
    "                # Get the appropriate metric\n",
    "                if table_type == 'points':\n",
    "                    pso_mean = pso_stats['points_mean']\n",
    "                    pso_std = pso_stats['points_std']\n",
    "                    metric_key = 'points'\n",
    "                elif table_type == 'games_won':\n",
    "                    pso_mean = pso_stats['games_won_mean']\n",
    "                    pso_std = pso_stats['games_won_std']\n",
    "                    metric_key = 'games_won'\n",
    "                else:  # moves\n",
    "                    pso_mean = pso_stats['moves_mean']\n",
    "                    pso_std = pso_stats['moves_std']\n",
    "                    metric_key = 'moves'\n",
    "                \n",
    "                # First row with PSO-NN data\n",
    "                \n",
    "                # Simple agents data\n",
    "                agent_strings = []\n",
    "                mean_strings = []\n",
    "                std_strings = []\n",
    "                pval_strings = []\n",
    "                \n",
    "                for agent in simple_agents:\n",
    "                    agent_stats = grid_stats['simple_agents_stats'][agent]\n",
    "                    test_results = grid_stats['statistical_tests'][agent]\n",
    "                    \n",
    "                    agent_strings.append(f\"$A_{{{agent}}}$\")\n",
    "                    \n",
    "                    if table_type == 'points':\n",
    "                        mean_strings.append(f\"{agent_stats['points_mean']:.3f}\")\n",
    "                        std_strings.append(f\"{agent_stats['points_std']:.3f}\")\n",
    "                        pval = test_results['points_pvalue']\n",
    "                    elif table_type == 'games_won':\n",
    "                        mean_strings.append(f\"{agent_stats['games_won_mean']:.3f}\")\n",
    "                        std_strings.append(f\"{agent_stats['games_won_std']:.3f}\")\n",
    "                        pval = test_results['games_won_pvalue']\n",
    "                    else:  # moves\n",
    "                        mean_strings.append(f\"{agent_stats['moves_mean']:.3f}\")\n",
    "                        std_strings.append(f\"{agent_stats['moves_std']:.3f}\")\n",
    "                        pval = test_results['moves_pvalue']\n",
    "                    \n",
    "                    # Format p-value in scientific notation\n",
    "                    pval_str = f\"${pval:.3e}$\"\n",
    "                    if test_results[f'{metric_key}_significant']:\n",
    "                        pval_str = f\"$\\\\mathbf{{{pval:.3e}}}$\"  # Bold for significant\n",
    "                    pval_strings.append(pval_str)\n",
    "                \n",
    "                # Write the agent data in nested tabular format\n",
    "                f.write(\"\\\\begin{tabular}{l}\\n\")\n",
    "                for agent_str in agent_strings:\n",
    "                    f.write(f\"{agent_str} \\\\\\\\\\n\")\n",
    "                f.write(\"\\\\end{tabular} & \\\\begin{tabular}{l}\\n\")\n",
    "                for mean_str in mean_strings:\n",
    "                    f.write(f\"{mean_str} \\\\\\\\\\n\")\n",
    "                f.write(\"\\\\end{tabular} & \\\\begin{tabular}{l}\\n\")\n",
    "                for std_str in std_strings:\n",
    "                    f.write(f\"{std_str} \\\\\\\\\\n\")\n",
    "                f.write(\"\\\\end{tabular} & \\\\begin{tabular}{l}\\n\")\n",
    "                for pval_str in pval_strings:\n",
    "                    f.write(f\"{pval_str} \\\\\\\\\\n\")\n",
    "                f.write(\"\\\\end{tabular} \\\\\\\\\\n\")\n",
    "                f.write(\"\\\\hline\\n\")\n",
    "            \n",
    "            f.write(\"\\\\end{tabular}\\n\")\n",
    "            f.write(\"\\\\end{center}\\n\")\n",
    "            f.write(\"\\\\end{table}\\n\\n\")\n",
    "\n",
    "def save_detailed_episode_statistics(multi_grid_episode_data: Dict, timestamp: str):\n",
    "    \"\"\"Save detailed episode-by-episode statistics for further analysis\"\"\"\n",
    "    print(f\"\\nüìà SAVING DETAILED EPISODE STATISTICS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    all_episodes = []\n",
    "    \n",
    "    for grid_key, grid_data in multi_grid_episode_data.items():\n",
    "        width, height = map(int, grid_key.split('x'))\n",
    "        max_possible_score = (width * height) - 3\n",
    "        \n",
    "        for agent, episodes in grid_data.items():\n",
    "            for episode in episodes:\n",
    "                # Calculate additional metrics\n",
    "                episode_data = {\n",
    "                    'timestamp': timestamp,\n",
    "                    'grid_size': grid_key,\n",
    "                    'grid_width': width,\n",
    "                    'grid_height': height,\n",
    "                    'max_possible_score': max_possible_score,\n",
    "                    'agent': agent,\n",
    "                    'agent_category': 'PSO-NN' if agent == 'GP' else 'Simple_Agent',\n",
    "                    'episode': episode['episode'],\n",
    "                    \n",
    "                    # Primary metrics (matching research paper)\n",
    "                    'points_scored': episode['score'],  # p metric\n",
    "                    'game_won': 1 if episode['score'] >= max_possible_score * 0.8 else 0,  # q metric (binary)\n",
    "                    'game_won_percentage': 100 if episode['score'] >= max_possible_score * 0.8 else 0,  # q metric (%)\n",
    "                    'moves_made': episode['steps'],  # r metric\n",
    "                    \n",
    "                    # Additional performance metrics\n",
    "                    'total_reward': episode['total_reward'],\n",
    "                    'efficiency': episode['efficiency'],\n",
    "                    'snake_length': episode['snake_length'],\n",
    "                    'survival_time': episode['time'],\n",
    "                    'termination_reason': episode['reason'],\n",
    "                    \n",
    "                    # Normalized metrics for comparison\n",
    "                    'score_percentage': (episode['score'] / max_possible_score) * 100,\n",
    "                    'board_coverage': (episode['snake_length'] / (width * height)) * 100,\n",
    "                    'moves_per_food': episode['steps'] / episode['score'] if episode['score'] > 0 else episode['steps'],\n",
    "                    \n",
    "                    # Grid complexity metrics\n",
    "                    'complexity_ratio': episode.get('complexity_ratio', 1.0),\n",
    "                    'is_training_grid': episode.get('is_training_grid', False),\n",
    "                    \n",
    "                    # Success metrics\n",
    "                    'successful_episode': 1 if episode['score'] > 0 else 0,\n",
    "                    'high_performance': 1 if episode['score'] >= max_possible_score * 0.5 else 0\n",
    "                }\n",
    "                \n",
    "                all_episodes.append(episode_data)\n",
    "    \n",
    "    # Save detailed episode data\n",
    "    episodes_df = pd.DataFrame(all_episodes)\n",
    "    \n",
    "    # Save comprehensive episode data\n",
    "    detailed_file = evaluator.results_dir / f\"detailed_episodes_{timestamp}.csv\"\n",
    "    episodes_df.to_csv(detailed_file, index=False)\n",
    "    \n",
    "    # Save summary statistics by agent and grid\n",
    "    summary_stats = episodes_df.groupby(['grid_size', 'agent', 'agent_category']).agg({\n",
    "        'points_scored': ['count', 'mean', 'std', 'min', 'max', 'median'],\n",
    "        'game_won_percentage': ['mean', 'std'],\n",
    "        'moves_made': ['mean', 'std', 'min', 'max'],\n",
    "        'efficiency': ['mean', 'std'],\n",
    "        'survival_time': ['mean', 'std', 'sum'],\n",
    "        'successful_episode': ['sum', 'mean'],  # Total successes and success rate\n",
    "        'high_performance': ['sum', 'mean']     # High performance episodes\n",
    "    }).round(4)\n",
    "    \n",
    "    summary_file = evaluator.results_dir / f\"summary_statistics_{timestamp}.csv\"\n",
    "    summary_stats.to_csv(summary_file)\n",
    "    \n",
    "    # Generate agent comparison summary\n",
    "    agent_comparison = episodes_df.groupby(['agent', 'agent_category']).agg({\n",
    "        'points_scored': ['count', 'mean', 'std'],\n",
    "        'game_won_percentage': ['mean', 'std'],\n",
    "        'moves_made': ['mean', 'std'],\n",
    "        'successful_episode': 'mean',\n",
    "        'high_performance': 'mean'\n",
    "    }).round(4)\n",
    "    \n",
    "    comparison_file = evaluator.results_dir / f\"agent_comparison_{timestamp}.csv\"\n",
    "    agent_comparison.to_csv(comparison_file)\n",
    "    \n",
    "    print(f\"‚úÖ Detailed episode statistics saved:\")\n",
    "    print(f\"   Episodes: {detailed_file}\")\n",
    "    print(f\"   Summary: {summary_file}\")\n",
    "    print(f\"   Comparison: {comparison_file}\")\n",
    "    print(f\"   Total episodes analyzed: {len(episodes_df)}\")\n",
    "    \n",
    "    return episodes_df, summary_stats, agent_comparison\n",
    "\n",
    "print(\"‚úÖ Research paper statistical analysis functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b4864cf-9d11-4db4-9138-2d924299df3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Multi-grid generalization visualization functions defined!\n"
     ]
    }
   ],
   "source": [
    "def generate_multi_grid_summary_statistics(multi_grid_df: pd.DataFrame):\n",
    "    \"\"\"Generate comprehensive summary statistics across all grid sizes with generalization focus\"\"\"\n",
    "    print(\"\\nüìà GENERATING MULTI-GRID SUMMARY STATISTICS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    training_grid = evaluator.training_grid\n",
    "    \n",
    "    # Overall summary by agent across all grids\n",
    "    overall_summary = multi_grid_df.groupby('agent').agg({\n",
    "        'score': ['mean', 'std', 'min', 'max', 'median'],\n",
    "        'steps': ['mean', 'std', 'min', 'max'],\n",
    "        'total_reward': ['mean', 'std'],\n",
    "        'efficiency': ['mean', 'std', 'max'],\n",
    "        'complexity_ratio': ['min', 'max']  # Range of complexity ratios tested\n",
    "    }).round(3)\n",
    "    \n",
    "    # Grid-specific summary\n",
    "    grid_summary = multi_grid_df.groupby(['grid_size', 'agent']).agg({\n",
    "        'score': ['mean', 'std', 'max'],\n",
    "        'steps': ['mean', 'std'],\n",
    "        'efficiency': ['mean', 'std'],\n",
    "        'time': ['mean', 'sum']\n",
    "    }).round(3)\n",
    "    \n",
    "    # Print formatted summaries\n",
    "    print(\"\\nüéØ OVERALL AGENT PERFORMANCE ACROSS ALL GRIDS\")\n",
    "    print(\"=\" * 90)\n",
    "    \n",
    "    for agent in multi_grid_df['agent'].unique():\n",
    "        agent_data = multi_grid_df[multi_grid_df['agent'] == agent]\n",
    "        grids_tested = agent_data['grid_size'].unique()\n",
    "        \n",
    "        # Training vs test performance\n",
    "        training_data = agent_data[agent_data['is_training_grid']]\n",
    "        test_data = agent_data[~agent_data['is_training_grid']]\n",
    "        \n",
    "        training_score = training_data['score'].mean() if len(training_data) > 0 else 0\n",
    "        test_score = test_data['score'].mean() if len(test_data) > 0 else 0\n",
    "        generalization_gap = training_score - test_score\n",
    "        \n",
    "        print(f\"\\n{agent} AGENT (Tested on {len(grids_tested)} grids: {', '.join(grids_tested)}):\")\n",
    "        print(f\"  Training Grid Performance: {training_score:.2f}\")\n",
    "        print(f\"  Average Test Performance:  {test_score:.2f}\")\n",
    "        print(f\"  Generalization Gap:        {generalization_gap:.2f}\")\n",
    "        print(f\"  Overall Average Score:     {agent_data['score'].mean():.2f} ¬± {agent_data['score'].std():.2f}\")\n",
    "        print(f\"  Best Score:                {agent_data['score'].max()} (on {agent_data.loc[agent_data['score'].idxmax(), 'grid_size']} grid)\")\n",
    "        print(f\"  Average Steps:             {agent_data['steps'].mean():.0f} ¬± {agent_data['steps'].std():.0f}\")\n",
    "        print(f\"  Average Efficiency:        {agent_data['efficiency'].mean():.4f} ¬± {agent_data['efficiency'].std():.4f}\")\n",
    "        print(f\"  Total Test Time:           {agent_data['time'].sum():.2f}s\")\n",
    "        \n",
    "        # Success rate by grid type\n",
    "        training_success = (training_data['score'] > 0).mean() * 100 if len(training_data) > 0 else 0\n",
    "        test_success = (test_data['score'] > 0).mean() * 100 if len(test_data) > 0 else 0\n",
    "        print(f\"  Training Success Rate:     {training_success:.1f}%\")\n",
    "        print(f\"  Test Success Rate:         {test_success:.1f}%\")\n",
    "    \n",
    "    print(f\"\\nüìä GRID-SPECIFIC PERFORMANCE BREAKDOWN\")\n",
    "    print(\"=\" * 100)\n",
    "    print(f\"Training Grid: {training_grid[0]}x{training_grid[1]}\")\n",
    "    \n",
    "    for grid_size in sorted(multi_grid_df['grid_size'].unique(), key=lambda x: int(x.split('x')[0])):\n",
    "        grid_data = multi_grid_df[multi_grid_df['grid_size'] == grid_size]\n",
    "        width, height = map(int, grid_size.split('x'))\n",
    "        max_possible = (width * height) - 3\n",
    "        is_training_grid = (width, height) == training_grid\n",
    "        grid_type = \"TRAINING\" if is_training_grid else \"TEST\"\n",
    "        complexity_ratio = (width * height) / (training_grid[0] * training_grid[1])\n",
    "        \n",
    "        print(f\"\\n{grid_size} GRID ({grid_type}, Complexity: {complexity_ratio:.2f}x, Max Score: {max_possible}):\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        for agent in grid_data['agent'].unique():\n",
    "            agent_grid_data = grid_data[grid_data['agent'] == agent]\n",
    "            success_rate = (agent_grid_data['score'] > 0).mean() * 100\n",
    "            \n",
    "            print(f\"  {agent:<6}: Score {agent_grid_data['score'].mean():.1f}¬±{agent_grid_data['score'].std():.1f}, \"\n",
    "                  f\"Success {success_rate:.1f}%, Efficiency {agent_grid_data['efficiency'].mean():.4f}\")\n",
    "    \n",
    "    return overall_summary, grid_summary\n",
    "\n",
    "def generate_multi_grid_comparison_plots(multi_grid_df: pd.DataFrame):\n",
    "    \"\"\"Generate comprehensive comparison plots for multi-grid evaluation with generalization focus\"\"\"\n",
    "    print(\"\\nüìä GENERATING MULTI-GRID VISUALIZATION PLOTS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Set style for better plots\n",
    "    plt.style.use('default')\n",
    "    sns.set_palette(\"husl\")\n",
    "    \n",
    "    # Create comprehensive figure\n",
    "    fig = plt.figure(figsize=(20, 18))\n",
    "    \n",
    "    # Define grid layout\n",
    "    gs = fig.add_gridspec(4, 4, height_ratios=[1, 1, 1, 1.2], width_ratios=[1, 1, 1, 1])\n",
    "    \n",
    "    training_grid = evaluator.training_grid\n",
    "    fig.suptitle(f'Multi-Grid Snake Agent Generalization Analysis\\n(Trained on {training_grid[0]}x{training_grid[1]}, Tested on Multiple Grids)', \n",
    "                 fontsize=16, fontweight='bold', y=0.96)\n",
    "    \n",
    "    # 1. Score by Grid Size with Training/Test distinction (Top Left)\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    # Create a color map for training vs test grids\n",
    "    multi_grid_df['grid_type'] = multi_grid_df['is_training_grid'].map({True: 'Training Grid', False: 'Test Grid'})\n",
    "    sns.boxplot(data=multi_grid_df, x='grid_size', y='score', hue='agent', ax=ax1)\n",
    "    ax1.set_title('Score Distribution by Grid Size', fontweight='bold')\n",
    "    ax1.set_xlabel('Grid Size')\n",
    "    ax1.set_ylabel('Score')\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Mark training grid\n",
    "    training_grid_pos = list(multi_grid_df['grid_size'].unique()).index(f\"{training_grid[0]}x{training_grid[1]}\")\n",
    "    ax1.axvline(x=training_grid_pos, color='red', linestyle='--', alpha=0.5, label='Training Grid')\n",
    "    ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    # 2. Generalization Performance (Top Middle-Left)\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    generalization_data = multi_grid_df.groupby(['agent', 'complexity_ratio']).agg({\n",
    "        'score': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    for agent in generalization_data['agent'].unique():\n",
    "        agent_data = generalization_data[generalization_data['agent'] == agent]\n",
    "        ax2.plot(agent_data['complexity_ratio'], agent_data['score'], 'o-', label=agent, linewidth=2, markersize=8)\n",
    "    \n",
    "    ax2.axvline(x=1.0, color='red', linestyle='--', alpha=0.5, label='Training Complexity')\n",
    "    ax2.set_title('Performance vs Grid Complexity', fontweight='bold')\n",
    "    ax2.set_xlabel('Complexity Ratio (vs Training Grid)')\n",
    "    ax2.set_ylabel('Average Score')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Success Rate by Grid Size (Top Middle-Right)\n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    success_rates = multi_grid_df.groupby(['grid_size', 'agent']).apply(\n",
    "        lambda x: (x['score'] > 0).mean() * 100\n",
    "    ).reset_index(name='success_rate')\n",
    "    \n",
    "    sns.barplot(data=success_rates, x='grid_size', y='success_rate', hue='agent', ax=ax3)\n",
    "    ax3.set_title('Success Rate by Grid Size', fontweight='bold')\n",
    "    ax3.set_xlabel('Grid Size')\n",
    "    ax3.set_ylabel('Success Rate (%)')\n",
    "    ax3.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Mark training grid\n",
    "    ax3.axvline(x=training_grid_pos, color='red', linestyle='--', alpha=0.5)\n",
    "    ax3.legend().remove()\n",
    "    \n",
    "    # 4. Training vs Test Performance (Top Right)\n",
    "    ax4 = fig.add_subplot(gs[0, 3])\n",
    "    train_test_data = []\n",
    "    for agent in multi_grid_df['agent'].unique():\n",
    "        agent_data = multi_grid_df[multi_grid_df['agent'] == agent]\n",
    "        training_score = agent_data[agent_data['is_training_grid']]['score'].mean()\n",
    "        test_score = agent_data[~agent_data['is_training_grid']]['score'].mean()\n",
    "        \n",
    "        train_test_data.append({'Agent': agent, 'Performance': training_score, 'Type': 'Training'})\n",
    "        train_test_data.append({'Agent': agent, 'Performance': test_score, 'Type': 'Test'})\n",
    "    \n",
    "    train_test_df = pd.DataFrame(train_test_data)\n",
    "    sns.barplot(data=train_test_df, x='Agent', y='Performance', hue='Type', ax=ax4)\n",
    "    ax4.set_title('Training vs Test Performance', fontweight='bold')\n",
    "    ax4.set_ylabel('Average Score')\n",
    "    \n",
    "    # 5. Efficiency by Complexity (Middle Left)\n",
    "    ax5 = fig.add_subplot(gs[1, 0])\n",
    "    for agent in multi_grid_df['agent'].unique():\n",
    "        agent_data = multi_grid_df[multi_grid_df['agent'] == agent]\n",
    "        complexity_efficiency = agent_data.groupby('complexity_ratio')['efficiency'].mean()\n",
    "        ax5.plot(complexity_efficiency.index, complexity_efficiency.values, 'o-', label=agent, linewidth=2, markersize=8)\n",
    "    \n",
    "    ax5.axvline(x=1.0, color='red', linestyle='--', alpha=0.5, label='Training Complexity')\n",
    "    ax5.set_title('Efficiency vs Grid Complexity', fontweight='bold')\n",
    "    ax5.set_xlabel('Complexity Ratio')\n",
    "    ax5.set_ylabel('Average Efficiency')\n",
    "    ax5.legend()\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. Steps vs Complexity (Middle Middle-Left)\n",
    "    ax6 = fig.add_subplot(gs[1, 1])\n",
    "    for agent in multi_grid_df['agent'].unique():\n",
    "        agent_data = multi_grid_df[multi_grid_df['agent'] == agent]\n",
    "        complexity_steps = agent_data.groupby('complexity_ratio')['steps'].mean()\n",
    "        ax6.plot(complexity_steps.index, complexity_steps.values, 'o-', label=agent, linewidth=2, markersize=8)\n",
    "    \n",
    "    ax6.axvline(x=1.0, color='red', linestyle='--', alpha=0.5)\n",
    "    ax6.set_title('Steps vs Grid Complexity', fontweight='bold')\n",
    "    ax6.set_xlabel('Complexity Ratio')\n",
    "    ax6.set_ylabel('Average Steps')\n",
    "    ax6.legend()\n",
    "    ax6.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 7. Performance Heatmap (Middle Middle-Right)\n",
    "    ax7 = fig.add_subplot(gs[1, 2])\n",
    "    heatmap_data = multi_grid_df.groupby(['agent', 'grid_size'])['score'].mean().unstack()\n",
    "    sns.heatmap(heatmap_data, annot=True, fmt='.1f', cmap='YlOrRd', ax=ax7)\n",
    "    ax7.set_title('Score Heatmap', fontweight='bold')\n",
    "    ax7.set_xlabel('Grid Size')\n",
    "    ax7.set_ylabel('Agent')\n",
    "    \n",
    "    # 8. Generalization Gap Analysis (Middle Right)\n",
    "    ax8 = fig.add_subplot(gs[1, 3])\n",
    "    generalization_gaps = []\n",
    "    for agent in multi_grid_df['agent'].unique():\n",
    "        agent_data = multi_grid_df[multi_grid_df['agent'] == agent]\n",
    "        training_score = agent_data[agent_data['is_training_grid']]['score'].mean()\n",
    "        \n",
    "        for complexity_ratio in sorted(agent_data['complexity_ratio'].unique()):\n",
    "            if complexity_ratio != 1.0:  # Exclude training grid\n",
    "                test_score = agent_data[agent_data['complexity_ratio'] == complexity_ratio]['score'].mean()\n",
    "                gap = training_score - test_score\n",
    "                generalization_gaps.append({\n",
    "                    'Agent': agent,\n",
    "                    'Complexity_Ratio': complexity_ratio,\n",
    "                    'Generalization_Gap': gap\n",
    "                })\n",
    "    \n",
    "    if generalization_gaps:\n",
    "        gap_df = pd.DataFrame(generalization_gaps)\n",
    "        for agent in gap_df['Agent'].unique():\n",
    "            agent_gaps = gap_df[gap_df['Agent'] == agent]\n",
    "            ax8.plot(agent_gaps['Complexity_Ratio'], agent_gaps['Generalization_Gap'], 'o-', \n",
    "                    label=agent, linewidth=2, markersize=8)\n",
    "        \n",
    "        ax8.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "        ax8.set_title('Generalization Gap', fontweight='bold')\n",
    "        ax8.set_xlabel('Complexity Ratio')\n",
    "        ax8.set_ylabel('Training Score - Test Score')\n",
    "        ax8.legend()\n",
    "        ax8.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 9. Time Analysis by Grid (Third Row Left)\n",
    "    ax9 = fig.add_subplot(gs[2, 0])\n",
    "    time_by_grid = multi_grid_df.groupby(['grid_size', 'agent'])['time'].mean().reset_index()\n",
    "    sns.barplot(data=time_by_grid, x='grid_size', y='time', hue='agent', ax=ax9)\n",
    "    ax9.set_title('Average Time per Episode', fontweight='bold')\n",
    "    ax9.set_xlabel('Grid Size')\n",
    "    ax9.set_ylabel('Time (seconds)')\n",
    "    ax9.tick_params(axis='x', rotation=45)\n",
    "    ax9.legend().remove()\n",
    "    \n",
    "    # 10. Episode-by-Episode Performance (Third Row Middle-Left)\n",
    "    ax10 = fig.add_subplot(gs[2, 1])\n",
    "    # Show performance trend for training grid\n",
    "    training_grid_key = f\"{training_grid[0]}x{training_grid[1]}\"\n",
    "    training_data = multi_grid_df[multi_grid_df['grid_size'] == training_grid_key]\n",
    "    \n",
    "    for agent in training_data['agent'].unique():\n",
    "        agent_episodes = training_data[training_data['agent'] == agent].sort_values('episode')\n",
    "        ax10.plot(agent_episodes['episode'], agent_episodes['score'], alpha=0.7, label=f'{agent}')\n",
    "    \n",
    "    ax10.set_title(f'Episode Performance on Training Grid ({training_grid_key})', fontweight='bold')\n",
    "    ax10.set_xlabel('Episode')\n",
    "    ax10.set_ylabel('Score')\n",
    "    ax10.legend()\n",
    "    ax10.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 11. Success Rate vs Complexity (Third Row Middle-Right)\n",
    "    ax11 = fig.add_subplot(gs[2, 2])\n",
    "    for agent in multi_grid_df['agent'].unique():\n",
    "        agent_data = multi_grid_df[multi_grid_df['agent'] == agent]\n",
    "        complexity_success = agent_data.groupby('complexity_ratio').apply(lambda x: (x['score'] > 0).mean() * 100)\n",
    "        ax11.plot(complexity_success.index, complexity_success.values, 'o-', label=agent, linewidth=2, markersize=8)\n",
    "    \n",
    "    ax11.axvline(x=1.0, color='red', linestyle='--', alpha=0.5)\n",
    "    ax11.set_title('Success Rate vs Complexity', fontweight='bold')\n",
    "    ax11.set_xlabel('Complexity Ratio')\n",
    "    ax11.set_ylabel('Success Rate (%)')\n",
    "    ax11.legend()\n",
    "    ax11.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 12. Score Distribution (Third Row Right)\n",
    "    ax12 = fig.add_subplot(gs[2, 3])\n",
    "    sns.violinplot(data=multi_grid_df, x='agent', y='score', hue='is_training_grid', ax=ax12)\n",
    "    ax12.set_title('Score Distribution: Training vs Test', fontweight='bold')\n",
    "    ax12.set_xlabel('Agent')\n",
    "    ax12.set_ylabel('Score')\n",
    "    \n",
    "    # 13. Comprehensive Summary Table (Bottom, spanning all columns)\n",
    "    ax13 = fig.add_subplot(gs[3, :])\n",
    "    ax13.axis('off')\n",
    "    \n",
    "    # Create generalization summary table\n",
    "    table_data = []\n",
    "    for agent in multi_grid_df['agent'].unique():\n",
    "        agent_data = multi_grid_df[multi_grid_df['agent'] == agent]\n",
    "        \n",
    "        # Calculate generalization metrics\n",
    "        training_data = agent_data[agent_data['is_training_grid']]\n",
    "        test_data = agent_data[~agent_data['is_training_grid']]\n",
    "        \n",
    "        training_score = training_data['score'].mean() if len(training_data) > 0 else 0\n",
    "        test_score = test_data['score'].mean() if len(test_data) > 0 else 0\n",
    "        generalization_gap = training_score - test_score\n",
    "        \n",
    "        overall_success = (agent_data['score'] > 0).mean() * 100\n",
    "        max_score = agent_data['score'].max()\n",
    "        avg_efficiency = agent_data['efficiency'].mean()\n",
    "        total_time = agent_data['time'].sum()\n",
    "        \n",
    "        # Get training time\n",
    "        training_time = TRAINING_LOGS.get(agent, {}).get('training_time', 0)\n",
    "        \n",
    "        table_data.append([\n",
    "            agent,\n",
    "            f\"{training_score:.2f}\",\n",
    "            f\"{test_score:.2f}\",\n",
    "            f\"{generalization_gap:.2f}\",\n",
    "            f\"{max_score}\",\n",
    "            f\"{overall_success:.1f}%\",\n",
    "            f\"{avg_efficiency:.4f}\",\n",
    "            f\"{total_time:.1f}s\",\n",
    "            f\"{training_time:.1f}s\" if training_time > 0 else \"N/A\"\n",
    "        ])\n",
    "    \n",
    "    # Create table\n",
    "    table = ax13.table(\n",
    "        cellText=table_data,\n",
    "        colLabels=['Agent', 'Training Score', 'Test Score', 'Gen. Gap', 'Max Score', 'Success Rate', 'Avg Efficiency', 'Test Time', 'Train Time'],\n",
    "        cellLoc='center',\n",
    "        loc='center',\n",
    "        bbox=[0, 0.3, 1, 0.4]\n",
    "    )\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1.2, 2)\n",
    "    \n",
    "    # Style the table\n",
    "    for i in range(len(table_data) + 1):\n",
    "        for j in range(9):\n",
    "            cell = table[(i, j)]\n",
    "            if i == 0:  # Header\n",
    "                cell.set_facecolor('#40466e')\n",
    "                cell.set_text_props(weight='bold', color='white')\n",
    "            else:\n",
    "                cell.set_facecolor('#f5f5f5' if i % 2 == 0 else 'white')\n",
    "    \n",
    "    ax13.text(0.5, 0.8, f'GENERALIZATION PERFORMANCE SUMMARY\\nTrained on {training_grid[0]}x{training_grid[1]}, Tested on {len(evaluator.test_grids)} Grid Sizes', \n",
    "             ha='center', va='center', fontsize=14, fontweight='bold', transform=ax13.transAxes)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    plot_file = evaluator.results_dir / f\"multi_grid_generalization_{timestamp}.png\"\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    print(f\"üíæ Multi-grid generalization plots saved to: {plot_file}\")\n",
    "    plt.show()\n",
    "\n",
    "def generate_agent_ranking_analysis(multi_grid_df: pd.DataFrame):\n",
    "    \"\"\"Generate agent ranking analysis with generalization focus\"\"\"\n",
    "    print(\"\\nüèÜ AGENT RANKING ANALYSIS WITH GENERALIZATION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    rankings = {}\n",
    "    training_grid = evaluator.training_grid\n",
    "    \n",
    "    # Calculate rankings for each grid size\n",
    "    for grid_size in multi_grid_df['grid_size'].unique():\n",
    "        grid_data = multi_grid_df[multi_grid_df['grid_size'] == grid_size]\n",
    "        grid_rankings = grid_data.groupby('agent')['score'].mean().sort_values(ascending=False)\n",
    "        rankings[grid_size] = {agent: rank + 1 for rank, agent in enumerate(grid_rankings.index)}\n",
    "    \n",
    "    # Create ranking DataFrame\n",
    "    ranking_df = pd.DataFrame(rankings).fillna(0)\n",
    "    \n",
    "    # Separate training and test rankings\n",
    "    training_grid_key = f\"{training_grid[0]}x{training_grid[1]}\"\n",
    "    test_grid_keys = [col for col in ranking_df.columns if col != training_grid_key]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    ranking_df['Training_Rank'] = ranking_df.get(training_grid_key, np.nan)\n",
    "    ranking_df['Avg_Test_Rank'] = ranking_df[test_grid_keys].mean(axis=1) if test_grid_keys else np.nan\n",
    "    ranking_df['Overall_Avg_Rank'] = ranking_df.mean(axis=1)\n",
    "    ranking_df['Best_Rank'] = ranking_df.min(axis=1)\n",
    "    ranking_df['Worst_Rank'] = ranking_df.max(axis=1)\n",
    "    ranking_df['Rank_Consistency'] = ranking_df[test_grid_keys].std(axis=1) if test_grid_keys else np.nan\n",
    "    ranking_df['Generalization_Stability'] = abs(ranking_df['Training_Rank'] - ranking_df['Avg_Test_Rank'])\n",
    "    \n",
    "    # Sort by overall average rank\n",
    "    ranking_df = ranking_df.sort_values('Overall_Avg_Rank')\n",
    "    \n",
    "    print(\"\\nüìä AGENT RANKINGS BY GRID SIZE\")\n",
    "    print(\"=\" * 80)\n",
    "    print(ranking_df.round(2))\n",
    "    \n",
    "    # Print detailed ranking analysis\n",
    "    print(f\"\\nüéØ GENERALIZATION RANKING ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for agent in ranking_df.index:\n",
    "        training_rank = ranking_df.loc[agent, 'Training_Rank']\n",
    "        avg_test_rank = ranking_df.loc[agent, 'Avg_Test_Rank']\n",
    "        overall_rank = ranking_df.loc[agent, 'Overall_Avg_Rank']\n",
    "        consistency = ranking_df.loc[agent, 'Rank_Consistency']\n",
    "        stability = ranking_df.loc[agent, 'Generalization_Stability']\n",
    "        \n",
    "        print(f\"{agent}:\")\n",
    "        print(f\"  Training Grid Rank: {training_rank:.0f}\")\n",
    "        print(f\"  Average Test Rank: {avg_test_rank:.2f}\")\n",
    "        print(f\"  Overall Average Rank: {overall_rank:.2f}\")\n",
    "        print(f\"  Test Consistency: {consistency:.2f} (lower = more consistent)\")\n",
    "        print(f\"  Generalization Stability: {stability:.2f} (lower = more stable)\")\n",
    "        print()\n",
    "    \n",
    "    return ranking_df\n",
    "\n",
    "print(\"‚úÖ Multi-grid generalization visualization functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad365da-d81f-4df9-b378-7897bc7cd7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ STARTING COMPREHENSIVE MULTI-GRID EVALUATION WITH STATISTICAL ANALYSIS\n",
      "==========================================================================================\n",
      "Training Grid: 10x10\n",
      "Test Grid Sizes: ['4x4', '5x5', '6x6', '7x7', '8x8', '9x9', '10x10']\n",
      "Test Episodes per Grid: 200\n",
      "Total Test Episodes: 4200\n",
      "Statistical Analysis: PSO-NN (GP) vs Simple Agents (A*, DQN)\n",
      "Timestamp: 2025-10-15 16:47:55\n",
      "==========================================================================================\n",
      "\n",
      "üèãÔ∏èüèãÔ∏èüèãÔ∏èüèãÔ∏èüèãÔ∏èüèãÔ∏èüèãÔ∏èüèãÔ∏èüèãÔ∏èüèãÔ∏èüèãÔ∏èüèãÔ∏èüèãÔ∏èüèãÔ∏èüèãÔ∏èüèãÔ∏èüèãÔ∏èüèãÔ∏èüèãÔ∏èüèãÔ∏è\n",
      "üèãÔ∏è PHASE 1: TRAINING ALL AGENTS ON 10x10 GRID\n",
      "üèãÔ∏èüèãÔ∏èüèãÔ∏èüèãÔ∏èüèãÔ∏èüèãÔ∏èüèãÔ∏èüèãÔ∏èüèãÔ∏èüèãÔ∏èüèãÔ∏èüèãÔ∏èüèãÔ∏èüèãÔ∏èüèãÔ∏èüèãÔ∏èüèãÔ∏èüèãÔ∏èüèãÔ∏èüèãÔ∏è\n",
      "üèãÔ∏è Training agents from scratch\n",
      "\n",
      "üéØ TRAINING ALL AGENTS ON 10x10 TRAINING GRID\n",
      "================================================================================\n",
      "‚úÖ A* agent ready (no training required)\n",
      "üß¨ TRAINING GENETIC PROGRAMMING AGENT - 10x10 Training Grid\n",
      "============================================================\n",
      "Training GP: 120 individuals, 1000 generations\n",
      "Training grid: 10x10\n",
      "Generation 1/1000 - Best fitness: 502.00 - Avg: 73.52\n",
      "Generation 2/1000 - Best fitness: 713.60 - Avg: 92.60\n",
      "Generation 3/1000 - Best fitness: 1163.20 - Avg: 120.98\n",
      "Generation 4/1000 - Best fitness: 1316.00 - Avg: 134.54\n",
      "Generation 5/1000 - Best fitness: 1414.80 - Avg: 170.45\n",
      "Generation 6/1000 - Best fitness: 1414.80 - Avg: 162.72\n",
      "Generation 7/1000 - Best fitness: 1595.20 - Avg: 186.43\n",
      "Generation 8/1000 - Best fitness: 1595.20 - Avg: 166.15\n",
      "Generation 9/1000 - Best fitness: 2040.00 - Avg: 203.65\n",
      "Generation 10/1000 - Best fitness: 2040.00 - Avg: 190.27\n",
      "Generation 11/1000 - Best fitness: 2040.00 - Avg: 187.47\n",
      "Generation 12/1000 - Best fitness: 8547.20 - Avg: 207.98\n",
      "Generation 13/1000 - Best fitness: 8547.20 - Avg: 227.15\n",
      "Generation 14/1000 - Best fitness: 8547.20 - Avg: 185.95\n",
      "Generation 15/1000 - Best fitness: 10153.60 - Avg: 397.02\n",
      "Generation 16/1000 - Best fitness: 10774.40 - Avg: 410.02\n",
      "Generation 17/1000 - Best fitness: 10774.40 - Avg: 405.19\n",
      "Generation 18/1000 - Best fitness: 10774.40 - Avg: 351.59\n",
      "Generation 19/1000 - Best fitness: 10774.40 - Avg: 399.30\n",
      "Generation 20/1000 - Best fitness: 10774.40 - Avg: 387.76\n",
      "Generation 21/1000 - Best fitness: 10774.40 - Avg: 417.50\n",
      "Generation 22/1000 - Best fitness: 11372.40 - Avg: 733.95\n",
      "Generation 23/1000 - Best fitness: 13134.00 - Avg: 793.78\n",
      "Generation 24/1000 - Best fitness: 13134.00 - Avg: 787.17\n",
      "Generation 25/1000 - Best fitness: 14656.00 - Avg: 1143.70\n",
      "Generation 26/1000 - Best fitness: 14656.00 - Avg: 1325.36\n",
      "Generation 27/1000 - Best fitness: 14656.00 - Avg: 1611.08\n",
      "Generation 28/1000 - Best fitness: 14656.00 - Avg: 1258.90\n",
      "Generation 29/1000 - Best fitness: 14656.00 - Avg: 1346.62\n",
      "Generation 30/1000 - Best fitness: 14656.00 - Avg: 1325.15\n",
      "Generation 31/1000 - Best fitness: 14656.00 - Avg: 1242.76\n",
      "Generation 32/1000 - Best fitness: 14656.00 - Avg: 1511.04\n",
      "Generation 33/1000 - Best fitness: 14656.00 - Avg: 1438.87\n",
      "Generation 34/1000 - Best fitness: 16119.60 - Avg: 1485.99\n",
      "Generation 35/1000 - Best fitness: 16119.60 - Avg: 1628.58\n",
      "Generation 36/1000 - Best fitness: 16119.60 - Avg: 1372.38\n",
      "Generation 37/1000 - Best fitness: 16119.60 - Avg: 1447.70\n",
      "Generation 38/1000 - Best fitness: 16119.60 - Avg: 1580.51\n",
      "Generation 39/1000 - Best fitness: 16119.60 - Avg: 1523.94\n",
      "Generation 40/1000 - Best fitness: 16119.60 - Avg: 1542.76\n",
      "Generation 41/1000 - Best fitness: 16119.60 - Avg: 1551.43\n",
      "Generation 42/1000 - Best fitness: 16119.60 - Avg: 1470.82\n",
      "Generation 43/1000 - Best fitness: 16119.60 - Avg: 1709.21\n",
      "Generation 44/1000 - Best fitness: 16119.60 - Avg: 1482.84\n",
      "Generation 45/1000 - Best fitness: 16119.60 - Avg: 1597.08\n",
      "Generation 46/1000 - Best fitness: 16119.60 - Avg: 1599.17\n",
      "Generation 47/1000 - Best fitness: 16119.60 - Avg: 1621.94\n",
      "Generation 48/1000 - Best fitness: 16119.60 - Avg: 1554.43\n",
      "Generation 49/1000 - Best fitness: 16119.60 - Avg: 1709.50\n",
      "Generation 50/1000 - Best fitness: 16119.60 - Avg: 1591.35\n",
      "Generation 51/1000 - Best fitness: 16119.60 - Avg: 1654.30\n",
      "Generation 52/1000 - Best fitness: 16119.60 - Avg: 1379.11\n",
      "Generation 53/1000 - Best fitness: 16119.60 - Avg: 1899.79\n",
      "Generation 54/1000 - Best fitness: 16119.60 - Avg: 1892.16\n",
      "Generation 55/1000 - Best fitness: 16119.60 - Avg: 1706.03\n",
      "Generation 56/1000 - Best fitness: 16119.60 - Avg: 1670.46\n",
      "Generation 57/1000 - Best fitness: 16119.60 - Avg: 1588.02\n",
      "Generation 58/1000 - Best fitness: 16119.60 - Avg: 1405.42\n",
      "Generation 59/1000 - Best fitness: 16119.60 - Avg: 1766.21\n",
      "Generation 60/1000 - Best fitness: 16119.60 - Avg: 1900.30\n",
      "Generation 61/1000 - Best fitness: 16119.60 - Avg: 1552.01\n",
      "Generation 62/1000 - Best fitness: 16119.60 - Avg: 2114.56\n",
      "Generation 63/1000 - Best fitness: 16119.60 - Avg: 1980.01\n",
      "Generation 64/1000 - Best fitness: 16119.60 - Avg: 1434.78\n",
      "Generation 65/1000 - Best fitness: 16119.60 - Avg: 1650.50\n",
      "Generation 66/1000 - Best fitness: 16119.60 - Avg: 1520.89\n",
      "Generation 67/1000 - Best fitness: 16119.60 - Avg: 1549.07\n",
      "Generation 68/1000 - Best fitness: 16119.60 - Avg: 1597.50\n",
      "Generation 69/1000 - Best fitness: 16119.60 - Avg: 1741.96\n",
      "Generation 70/1000 - Best fitness: 16119.60 - Avg: 1655.03\n",
      "Generation 71/1000 - Best fitness: 16119.60 - Avg: 1744.39\n",
      "Generation 72/1000 - Best fitness: 16119.60 - Avg: 1709.58\n",
      "Generation 73/1000 - Best fitness: 16119.60 - Avg: 1493.12\n",
      "Generation 74/1000 - Best fitness: 16119.60 - Avg: 1959.29\n",
      "Injecting diversity at generation 74\n",
      "Generation 75/1000 - Best fitness: 16119.60 - Avg: 1632.21\n",
      "Generation 76/1000 - Best fitness: 16119.60 - Avg: 1384.52\n",
      "Generation 77/1000 - Best fitness: 16119.60 - Avg: 1462.62\n",
      "Generation 78/1000 - Best fitness: 16119.60 - Avg: 1506.99\n",
      "Generation 79/1000 - Best fitness: 16119.60 - Avg: 1429.11\n",
      "Generation 80/1000 - Best fitness: 16119.60 - Avg: 1647.33\n",
      "Generation 81/1000 - Best fitness: 16119.60 - Avg: 1492.46\n",
      "Generation 82/1000 - Best fitness: 16119.60 - Avg: 1693.52\n",
      "Generation 83/1000 - Best fitness: 16119.60 - Avg: 1649.99\n",
      "Generation 84/1000 - Best fitness: 16119.60 - Avg: 1730.56\n",
      "Generation 85/1000 - Best fitness: 16119.60 - Avg: 1681.50\n",
      "Generation 86/1000 - Best fitness: 16119.60 - Avg: 1963.25\n",
      "Generation 87/1000 - Best fitness: 16119.60 - Avg: 1484.20\n",
      "Generation 88/1000 - Best fitness: 16119.60 - Avg: 1887.77\n",
      "Generation 89/1000 - Best fitness: 16119.60 - Avg: 1493.22\n",
      "Generation 90/1000 - Best fitness: 16130.00 - Avg: 1565.68\n",
      "Generation 91/1000 - Best fitness: 16130.00 - Avg: 1609.46\n",
      "Generation 92/1000 - Best fitness: 16130.00 - Avg: 1413.26\n",
      "Generation 93/1000 - Best fitness: 16130.00 - Avg: 1611.12\n",
      "Generation 94/1000 - Best fitness: 16130.00 - Avg: 2085.32\n",
      "Generation 95/1000 - Best fitness: 16130.00 - Avg: 1892.38\n",
      "Generation 96/1000 - Best fitness: 16130.00 - Avg: 1550.61\n",
      "Generation 97/1000 - Best fitness: 16130.00 - Avg: 1541.61\n",
      "Generation 98/1000 - Best fitness: 16130.00 - Avg: 1393.16\n",
      "Generation 99/1000 - Best fitness: 16130.00 - Avg: 1412.42\n",
      "Generation 100/1000 - Best fitness: 16130.00 - Avg: 1453.17\n",
      "Generation 101/1000 - Best fitness: 16130.00 - Avg: 1765.08\n",
      "Generation 102/1000 - Best fitness: 16130.00 - Avg: 1688.06\n",
      "Generation 103/1000 - Best fitness: 16130.00 - Avg: 1608.06\n",
      "Generation 104/1000 - Best fitness: 16130.00 - Avg: 1739.86\n",
      "Generation 105/1000 - Best fitness: 16130.00 - Avg: 1744.93\n",
      "Generation 106/1000 - Best fitness: 16130.00 - Avg: 1902.59\n",
      "Generation 107/1000 - Best fitness: 16130.00 - Avg: 2161.75\n",
      "Generation 108/1000 - Best fitness: 16130.00 - Avg: 1735.28\n",
      "Generation 109/1000 - Best fitness: 16130.00 - Avg: 1725.01\n",
      "Generation 110/1000 - Best fitness: 16130.00 - Avg: 1684.32\n",
      "Generation 111/1000 - Best fitness: 16130.00 - Avg: 1786.88\n",
      "Generation 112/1000 - Best fitness: 16130.00 - Avg: 1646.94\n",
      "Generation 113/1000 - Best fitness: 16130.00 - Avg: 1690.91\n",
      "Generation 114/1000 - Best fitness: 16130.00 - Avg: 1839.76\n",
      "Generation 115/1000 - Best fitness: 16130.00 - Avg: 1468.45\n",
      "Generation 116/1000 - Best fitness: 16130.00 - Avg: 1701.24\n",
      "Generation 117/1000 - Best fitness: 16130.00 - Avg: 1743.45\n",
      "Generation 118/1000 - Best fitness: 16130.00 - Avg: 1975.99\n",
      "Generation 119/1000 - Best fitness: 16130.00 - Avg: 1904.96\n",
      "Generation 120/1000 - Best fitness: 16130.00 - Avg: 1704.80\n",
      "Generation 121/1000 - Best fitness: 16130.00 - Avg: 1903.42\n",
      "Generation 122/1000 - Best fitness: 16130.00 - Avg: 1761.26\n",
      "Generation 123/1000 - Best fitness: 16130.00 - Avg: 1779.22\n",
      "Generation 124/1000 - Best fitness: 17390.00 - Avg: 1891.51\n",
      "Generation 125/1000 - Best fitness: 17390.00 - Avg: 1809.89\n",
      "Generation 126/1000 - Best fitness: 17390.00 - Avg: 1548.77\n",
      "Generation 127/1000 - Best fitness: 17390.00 - Avg: 1699.71\n",
      "Generation 128/1000 - Best fitness: 18599.20 - Avg: 1739.62\n",
      "Generation 129/1000 - Best fitness: 18599.20 - Avg: 1784.08\n",
      "Generation 130/1000 - Best fitness: 18599.20 - Avg: 1464.99\n",
      "Generation 131/1000 - Best fitness: 18599.20 - Avg: 1516.67\n",
      "Generation 132/1000 - Best fitness: 18599.20 - Avg: 1868.22\n",
      "Generation 133/1000 - Best fitness: 18599.20 - Avg: 1705.20\n",
      "Generation 134/1000 - Best fitness: 18599.20 - Avg: 1793.47\n",
      "Generation 135/1000 - Best fitness: 18599.20 - Avg: 1670.83\n",
      "Generation 136/1000 - Best fitness: 18599.20 - Avg: 1550.63\n",
      "Generation 137/1000 - Best fitness: 18599.20 - Avg: 1536.62\n",
      "Generation 138/1000 - Best fitness: 18599.20 - Avg: 1663.82\n",
      "Generation 139/1000 - Best fitness: 18599.20 - Avg: 1839.55\n",
      "Generation 140/1000 - Best fitness: 18599.20 - Avg: 1926.77\n",
      "Generation 141/1000 - Best fitness: 18599.20 - Avg: 1683.43\n",
      "Generation 142/1000 - Best fitness: 18599.20 - Avg: 1861.06\n",
      "Generation 143/1000 - Best fitness: 18599.20 - Avg: 1707.97\n",
      "Generation 144/1000 - Best fitness: 18599.20 - Avg: 1487.79\n",
      "Generation 145/1000 - Best fitness: 18599.20 - Avg: 1696.77\n",
      "Generation 146/1000 - Best fitness: 18599.20 - Avg: 1984.23\n",
      "Generation 147/1000 - Best fitness: 18599.20 - Avg: 2040.73\n",
      "Generation 148/1000 - Best fitness: 18599.20 - Avg: 2115.46\n",
      "Generation 149/1000 - Best fitness: 18599.20 - Avg: 2401.40\n",
      "Generation 150/1000 - Best fitness: 18599.20 - Avg: 1914.94\n",
      "Generation 151/1000 - Best fitness: 18599.20 - Avg: 1589.67\n",
      "Generation 152/1000 - Best fitness: 18599.20 - Avg: 1883.93\n",
      "Generation 153/1000 - Best fitness: 18599.20 - Avg: 1604.73\n",
      "Generation 154/1000 - Best fitness: 19467.60 - Avg: 2103.95\n",
      "Generation 155/1000 - Best fitness: 19700.00 - Avg: 2072.47\n",
      "Generation 156/1000 - Best fitness: 19700.00 - Avg: 2177.95\n",
      "Generation 157/1000 - Best fitness: 19700.00 - Avg: 1786.45\n",
      "Generation 158/1000 - Best fitness: 19700.00 - Avg: 1916.33\n",
      "Generation 159/1000 - Best fitness: 19700.00 - Avg: 1605.96\n",
      "Generation 160/1000 - Best fitness: 19700.00 - Avg: 1694.17\n",
      "Generation 161/1000 - Best fitness: 19700.00 - Avg: 1580.70\n",
      "Generation 162/1000 - Best fitness: 19700.00 - Avg: 1635.35\n",
      "Generation 163/1000 - Best fitness: 19700.00 - Avg: 1656.49\n",
      "Generation 164/1000 - Best fitness: 19700.00 - Avg: 2262.25\n",
      "Generation 165/1000 - Best fitness: 19700.00 - Avg: 1931.47\n",
      "Generation 166/1000 - Best fitness: 19700.00 - Avg: 1963.06\n",
      "Generation 167/1000 - Best fitness: 19700.00 - Avg: 2072.15\n",
      "Generation 168/1000 - Best fitness: 19700.00 - Avg: 1857.84\n",
      "Generation 169/1000 - Best fitness: 19700.00 - Avg: 2096.46\n",
      "Generation 170/1000 - Best fitness: 19700.00 - Avg: 1785.62\n",
      "Generation 171/1000 - Best fitness: 19700.00 - Avg: 2026.10\n",
      "Generation 172/1000 - Best fitness: 19700.00 - Avg: 2097.95\n",
      "Generation 173/1000 - Best fitness: 19700.00 - Avg: 2257.38\n",
      "Generation 174/1000 - Best fitness: 19700.00 - Avg: 2280.42\n",
      "Generation 175/1000 - Best fitness: 19700.00 - Avg: 1814.97\n",
      "Generation 176/1000 - Best fitness: 19700.00 - Avg: 2166.22\n",
      "Generation 177/1000 - Best fitness: 19700.00 - Avg: 2113.79\n",
      "Generation 178/1000 - Best fitness: 19700.00 - Avg: 1825.86\n",
      "Generation 179/1000 - Best fitness: 19700.00 - Avg: 2070.91\n",
      "Generation 180/1000 - Best fitness: 19700.00 - Avg: 2110.68\n",
      "Generation 181/1000 - Best fitness: 19700.00 - Avg: 2093.74\n",
      "Generation 182/1000 - Best fitness: 19700.00 - Avg: 1881.26\n",
      "Generation 183/1000 - Best fitness: 19700.00 - Avg: 1725.46\n",
      "Generation 184/1000 - Best fitness: 19700.00 - Avg: 2001.98\n",
      "Generation 185/1000 - Best fitness: 19700.00 - Avg: 2147.06\n",
      "Generation 186/1000 - Best fitness: 19700.00 - Avg: 1713.40\n",
      "Generation 187/1000 - Best fitness: 19700.00 - Avg: 2224.97\n",
      "Generation 188/1000 - Best fitness: 19700.00 - Avg: 2046.21\n",
      "Generation 189/1000 - Best fitness: 19700.00 - Avg: 2140.24\n",
      "Generation 190/1000 - Best fitness: 19700.00 - Avg: 2357.29\n",
      "Generation 191/1000 - Best fitness: 19700.00 - Avg: 1807.61\n",
      "Generation 192/1000 - Best fitness: 19700.00 - Avg: 2056.73\n",
      "Generation 193/1000 - Best fitness: 19700.00 - Avg: 1940.18\n",
      "Generation 194/1000 - Best fitness: 19700.00 - Avg: 2320.84\n",
      "Generation 195/1000 - Best fitness: 19700.00 - Avg: 1855.01\n",
      "Injecting diversity at generation 195\n",
      "Generation 196/1000 - Best fitness: 19700.00 - Avg: 2460.97\n",
      "Generation 197/1000 - Best fitness: 19700.00 - Avg: 2274.74\n",
      "Generation 198/1000 - Best fitness: 19700.00 - Avg: 2348.44\n",
      "Generation 199/1000 - Best fitness: 19700.00 - Avg: 2328.51\n",
      "Generation 200/1000 - Best fitness: 19700.00 - Avg: 2143.65\n",
      "Generation 201/1000 - Best fitness: 19700.00 - Avg: 2143.91\n",
      "Generation 202/1000 - Best fitness: 19700.00 - Avg: 1863.41\n",
      "Generation 203/1000 - Best fitness: 19700.00 - Avg: 2016.86\n",
      "Generation 204/1000 - Best fitness: 19700.00 - Avg: 2305.52\n",
      "Generation 205/1000 - Best fitness: 19700.00 - Avg: 1957.21\n",
      "Generation 206/1000 - Best fitness: 19700.00 - Avg: 1957.38\n",
      "Generation 207/1000 - Best fitness: 19700.00 - Avg: 1748.72\n",
      "Generation 208/1000 - Best fitness: 19700.00 - Avg: 1926.76\n",
      "Generation 209/1000 - Best fitness: 19700.00 - Avg: 1961.73\n",
      "Generation 210/1000 - Best fitness: 19700.00 - Avg: 2143.69\n",
      "Generation 211/1000 - Best fitness: 19700.00 - Avg: 1806.23\n",
      "Generation 212/1000 - Best fitness: 19700.00 - Avg: 1941.90\n",
      "Generation 213/1000 - Best fitness: 19700.00 - Avg: 1717.65\n",
      "Generation 214/1000 - Best fitness: 19700.00 - Avg: 1698.93\n",
      "Generation 215/1000 - Best fitness: 19700.00 - Avg: 1836.83\n",
      "Generation 216/1000 - Best fitness: 19700.00 - Avg: 2120.05\n",
      "Generation 217/1000 - Best fitness: 19700.00 - Avg: 1815.32\n",
      "Generation 218/1000 - Best fitness: 19700.00 - Avg: 1669.04\n",
      "Generation 219/1000 - Best fitness: 19700.00 - Avg: 2147.27\n",
      "Generation 220/1000 - Best fitness: 19700.00 - Avg: 1815.35\n",
      "Generation 221/1000 - Best fitness: 19700.00 - Avg: 1788.23\n",
      "Generation 222/1000 - Best fitness: 19700.00 - Avg: 2269.82\n",
      "Generation 223/1000 - Best fitness: 19700.00 - Avg: 2383.14\n",
      "Generation 224/1000 - Best fitness: 19700.00 - Avg: 2223.04\n",
      "Generation 225/1000 - Best fitness: 19700.00 - Avg: 2053.33\n",
      "Generation 226/1000 - Best fitness: 19700.00 - Avg: 2188.10\n",
      "Generation 227/1000 - Best fitness: 19700.00 - Avg: 2140.26\n",
      "Generation 228/1000 - Best fitness: 19700.00 - Avg: 2142.66\n",
      "Generation 229/1000 - Best fitness: 19700.00 - Avg: 2106.44\n",
      "Generation 230/1000 - Best fitness: 19700.00 - Avg: 1765.86\n",
      "Generation 231/1000 - Best fitness: 19700.00 - Avg: 1886.01\n",
      "Generation 232/1000 - Best fitness: 19700.00 - Avg: 2147.92\n",
      "Generation 233/1000 - Best fitness: 19700.00 - Avg: 1947.06\n",
      "Generation 234/1000 - Best fitness: 19700.00 - Avg: 1846.22\n",
      "Generation 235/1000 - Best fitness: 19700.00 - Avg: 1966.25\n",
      "Injecting diversity at generation 235\n",
      "Generation 236/1000 - Best fitness: 19700.00 - Avg: 1971.58\n",
      "Generation 237/1000 - Best fitness: 19700.00 - Avg: 2038.42\n",
      "Generation 238/1000 - Best fitness: 19700.00 - Avg: 1929.91\n",
      "Generation 239/1000 - Best fitness: 19700.00 - Avg: 2423.07\n",
      "Generation 240/1000 - Best fitness: 19700.00 - Avg: 2258.81\n",
      "Generation 241/1000 - Best fitness: 19700.00 - Avg: 2724.17\n",
      "Generation 242/1000 - Best fitness: 19700.00 - Avg: 2072.16\n",
      "Generation 243/1000 - Best fitness: 19700.00 - Avg: 2133.51\n",
      "Generation 244/1000 - Best fitness: 19700.00 - Avg: 2135.42\n",
      "Generation 245/1000 - Best fitness: 19700.00 - Avg: 2075.77\n",
      "Generation 246/1000 - Best fitness: 20330.00 - Avg: 1908.02\n",
      "Generation 247/1000 - Best fitness: 20330.00 - Avg: 1844.00\n",
      "Generation 248/1000 - Best fitness: 20330.00 - Avg: 1935.46\n",
      "Generation 249/1000 - Best fitness: 20330.00 - Avg: 1951.07\n",
      "Generation 250/1000 - Best fitness: 20330.00 - Avg: 2230.59\n",
      "Generation 251/1000 - Best fitness: 20330.00 - Avg: 1932.25\n",
      "Generation 252/1000 - Best fitness: 20330.00 - Avg: 1770.61\n",
      "Generation 253/1000 - Best fitness: 20330.00 - Avg: 2094.02\n",
      "Generation 254/1000 - Best fitness: 20330.00 - Avg: 1965.87\n",
      "Generation 255/1000 - Best fitness: 20330.00 - Avg: 2293.25\n",
      "Generation 256/1000 - Best fitness: 20330.00 - Avg: 2147.95\n",
      "Generation 257/1000 - Best fitness: 20330.00 - Avg: 1846.24\n",
      "Generation 258/1000 - Best fitness: 20330.00 - Avg: 1749.44\n",
      "Generation 259/1000 - Best fitness: 20330.00 - Avg: 1996.11\n",
      "Generation 260/1000 - Best fitness: 20330.00 - Avg: 1921.68\n",
      "Generation 261/1000 - Best fitness: 20330.00 - Avg: 1822.77\n",
      "Generation 262/1000 - Best fitness: 20330.00 - Avg: 1744.41\n",
      "Generation 263/1000 - Best fitness: 20330.00 - Avg: 1877.37\n",
      "Generation 264/1000 - Best fitness: 20330.00 - Avg: 2039.15\n",
      "Generation 265/1000 - Best fitness: 20330.00 - Avg: 1748.76\n",
      "Generation 266/1000 - Best fitness: 20330.00 - Avg: 2118.07\n",
      "Generation 267/1000 - Best fitness: 20330.00 - Avg: 2532.46\n",
      "Generation 268/1000 - Best fitness: 20330.00 - Avg: 2332.23\n",
      "Generation 269/1000 - Best fitness: 20330.00 - Avg: 2325.68\n",
      "Generation 270/1000 - Best fitness: 20330.00 - Avg: 2291.31\n",
      "Generation 271/1000 - Best fitness: 20330.00 - Avg: 2235.13\n",
      "Generation 272/1000 - Best fitness: 20330.00 - Avg: 1810.67\n",
      "Generation 273/1000 - Best fitness: 20330.00 - Avg: 2022.71\n",
      "Generation 274/1000 - Best fitness: 20330.00 - Avg: 2373.40\n",
      "Generation 275/1000 - Best fitness: 20330.00 - Avg: 1968.95\n",
      "Generation 276/1000 - Best fitness: 20330.00 - Avg: 1954.31\n",
      "Generation 277/1000 - Best fitness: 20330.00 - Avg: 2153.75\n",
      "Generation 278/1000 - Best fitness: 20330.00 - Avg: 1936.31\n",
      "Generation 279/1000 - Best fitness: 20330.00 - Avg: 1780.18\n",
      "Generation 280/1000 - Best fitness: 20330.00 - Avg: 1870.45\n",
      "Generation 281/1000 - Best fitness: 20330.00 - Avg: 1727.55\n",
      "Generation 282/1000 - Best fitness: 20330.00 - Avg: 2262.40\n",
      "Generation 283/1000 - Best fitness: 20330.00 - Avg: 2021.45\n",
      "Generation 284/1000 - Best fitness: 20330.00 - Avg: 2212.12\n",
      "Generation 285/1000 - Best fitness: 20330.00 - Avg: 2191.24\n",
      "Generation 286/1000 - Best fitness: 20330.00 - Avg: 1812.90\n",
      "Injecting diversity at generation 286\n",
      "Generation 287/1000 - Best fitness: 20330.00 - Avg: 2235.01\n",
      "Generation 288/1000 - Best fitness: 20330.00 - Avg: 1869.29\n",
      "Generation 289/1000 - Best fitness: 20330.00 - Avg: 1757.29\n",
      "Generation 290/1000 - Best fitness: 20330.00 - Avg: 1917.04\n",
      "Generation 291/1000 - Best fitness: 20330.00 - Avg: 2429.77\n",
      "Generation 292/1000 - Best fitness: 20330.00 - Avg: 2106.00\n",
      "Generation 293/1000 - Best fitness: 20330.00 - Avg: 2512.37\n",
      "Generation 294/1000 - Best fitness: 20330.00 - Avg: 2063.90\n",
      "Generation 295/1000 - Best fitness: 20330.00 - Avg: 2489.94\n",
      "Generation 296/1000 - Best fitness: 20960.00 - Avg: 2148.34\n",
      "Generation 297/1000 - Best fitness: 20960.00 - Avg: 1856.07\n",
      "Generation 298/1000 - Best fitness: 20960.00 - Avg: 1856.03\n",
      "Generation 299/1000 - Best fitness: 20960.00 - Avg: 1917.19\n",
      "Generation 300/1000 - Best fitness: 20960.00 - Avg: 1800.31\n",
      "Generation 301/1000 - Best fitness: 20960.00 - Avg: 2088.07\n",
      "Generation 302/1000 - Best fitness: 20960.00 - Avg: 2325.82\n",
      "Generation 303/1000 - Best fitness: 20960.00 - Avg: 1963.06\n",
      "Generation 304/1000 - Best fitness: 20960.00 - Avg: 1958.32\n",
      "Generation 305/1000 - Best fitness: 20960.00 - Avg: 2516.61\n",
      "Generation 306/1000 - Best fitness: 20960.00 - Avg: 2297.17\n",
      "Generation 307/1000 - Best fitness: 20960.00 - Avg: 2009.98\n",
      "Generation 308/1000 - Best fitness: 20960.00 - Avg: 1989.18\n",
      "Generation 309/1000 - Best fitness: 20960.00 - Avg: 1932.46\n",
      "Generation 310/1000 - Best fitness: 20960.00 - Avg: 2110.09\n",
      "Generation 311/1000 - Best fitness: 20960.00 - Avg: 2047.01\n",
      "Generation 312/1000 - Best fitness: 20960.00 - Avg: 1952.59\n",
      "Generation 313/1000 - Best fitness: 20960.00 - Avg: 2305.17\n",
      "Generation 314/1000 - Best fitness: 20960.00 - Avg: 2046.83\n",
      "Generation 315/1000 - Best fitness: 20960.00 - Avg: 2052.53\n",
      "Generation 316/1000 - Best fitness: 20960.00 - Avg: 1985.88\n",
      "Generation 317/1000 - Best fitness: 20960.00 - Avg: 2165.80\n",
      "Generation 318/1000 - Best fitness: 20960.00 - Avg: 1993.20\n",
      "Generation 319/1000 - Best fitness: 20960.00 - Avg: 2062.70\n",
      "Generation 320/1000 - Best fitness: 20960.00 - Avg: 1881.58\n",
      "Generation 321/1000 - Best fitness: 20960.00 - Avg: 1979.89\n",
      "Generation 322/1000 - Best fitness: 20960.00 - Avg: 2158.30\n",
      "Generation 323/1000 - Best fitness: 20960.00 - Avg: 1921.54\n",
      "Generation 324/1000 - Best fitness: 20960.00 - Avg: 1788.48\n",
      "Generation 325/1000 - Best fitness: 20960.00 - Avg: 1918.13\n",
      "Generation 326/1000 - Best fitness: 20960.00 - Avg: 1776.16\n",
      "Generation 327/1000 - Best fitness: 20960.00 - Avg: 2317.81\n",
      "Generation 328/1000 - Best fitness: 20960.00 - Avg: 2045.81\n",
      "Generation 329/1000 - Best fitness: 20960.00 - Avg: 2069.67\n",
      "Generation 330/1000 - Best fitness: 20960.00 - Avg: 1921.89\n",
      "Generation 331/1000 - Best fitness: 20960.00 - Avg: 2030.46\n",
      "Generation 332/1000 - Best fitness: 20960.00 - Avg: 1748.20\n",
      "Generation 333/1000 - Best fitness: 20960.00 - Avg: 2024.71\n",
      "Generation 334/1000 - Best fitness: 20960.00 - Avg: 2176.01\n",
      "Generation 335/1000 - Best fitness: 20960.00 - Avg: 1815.01\n",
      "Generation 336/1000 - Best fitness: 20960.00 - Avg: 1858.66\n",
      "Injecting diversity at generation 336\n",
      "Generation 337/1000 - Best fitness: 20960.00 - Avg: 2232.48\n",
      "Generation 338/1000 - Best fitness: 20960.00 - Avg: 2714.79\n",
      "Generation 339/1000 - Best fitness: 20960.00 - Avg: 1933.90\n",
      "Generation 340/1000 - Best fitness: 20960.00 - Avg: 1731.99\n",
      "Generation 341/1000 - Best fitness: 20960.00 - Avg: 2337.59\n",
      "Generation 342/1000 - Best fitness: 20960.00 - Avg: 2046.28\n",
      "Generation 343/1000 - Best fitness: 20960.00 - Avg: 2461.19\n",
      "Generation 344/1000 - Best fitness: 20960.00 - Avg: 2144.27\n",
      "Generation 345/1000 - Best fitness: 20960.00 - Avg: 2346.14\n",
      "Generation 346/1000 - Best fitness: 20960.00 - Avg: 1889.78\n",
      "Generation 347/1000 - Best fitness: 20960.00 - Avg: 2275.18\n",
      "Generation 348/1000 - Best fitness: 20960.00 - Avg: 2117.04\n",
      "Generation 349/1000 - Best fitness: 20960.00 - Avg: 1799.56\n",
      "Generation 350/1000 - Best fitness: 20960.00 - Avg: 2142.97\n",
      "Generation 351/1000 - Best fitness: 20960.00 - Avg: 2018.15\n",
      "Generation 352/1000 - Best fitness: 20960.00 - Avg: 2011.58\n",
      "Generation 353/1000 - Best fitness: 20960.00 - Avg: 1904.79\n",
      "Generation 354/1000 - Best fitness: 20960.00 - Avg: 2132.22\n",
      "Generation 355/1000 - Best fitness: 20960.00 - Avg: 1924.23\n",
      "Generation 356/1000 - Best fitness: 20960.00 - Avg: 1954.97\n",
      "Generation 357/1000 - Best fitness: 20960.00 - Avg: 1990.75\n",
      "Generation 358/1000 - Best fitness: 20960.00 - Avg: 2180.97\n",
      "Generation 359/1000 - Best fitness: 20960.00 - Avg: 1788.63\n",
      "Generation 360/1000 - Best fitness: 20960.00 - Avg: 2170.27\n",
      "Generation 361/1000 - Best fitness: 20960.00 - Avg: 2438.51\n",
      "Generation 362/1000 - Best fitness: 20960.00 - Avg: 2161.07\n",
      "Generation 363/1000 - Best fitness: 20960.00 - Avg: 1762.74\n",
      "Generation 364/1000 - Best fitness: 20960.00 - Avg: 2138.06\n",
      "Generation 365/1000 - Best fitness: 20960.00 - Avg: 2060.21\n",
      "Generation 366/1000 - Best fitness: 20960.00 - Avg: 2095.82\n",
      "Generation 367/1000 - Best fitness: 20960.00 - Avg: 2127.76\n",
      "Generation 368/1000 - Best fitness: 20960.00 - Avg: 1921.19\n",
      "Generation 369/1000 - Best fitness: 20960.00 - Avg: 2461.79\n",
      "Generation 370/1000 - Best fitness: 20960.00 - Avg: 2313.81\n",
      "Generation 371/1000 - Best fitness: 20960.00 - Avg: 1987.74\n",
      "Generation 372/1000 - Best fitness: 20960.00 - Avg: 2358.08\n",
      "Generation 373/1000 - Best fitness: 20960.00 - Avg: 1896.96\n",
      "Generation 374/1000 - Best fitness: 20960.00 - Avg: 1782.29\n",
      "Generation 375/1000 - Best fitness: 20960.00 - Avg: 2250.41\n",
      "Generation 376/1000 - Best fitness: 20960.00 - Avg: 2015.45\n",
      "Injecting diversity at generation 376\n",
      "Generation 377/1000 - Best fitness: 20960.00 - Avg: 2230.95\n",
      "Generation 378/1000 - Best fitness: 20960.00 - Avg: 2260.98\n",
      "Generation 379/1000 - Best fitness: 20960.00 - Avg: 2203.60\n",
      "Generation 380/1000 - Best fitness: 20960.00 - Avg: 2000.13\n",
      "Generation 381/1000 - Best fitness: 20960.00 - Avg: 2244.91\n",
      "Generation 382/1000 - Best fitness: 20960.00 - Avg: 2265.08\n",
      "Generation 383/1000 - Best fitness: 20960.00 - Avg: 1762.68\n",
      "Generation 384/1000 - Best fitness: 20960.00 - Avg: 1923.62\n",
      "Generation 385/1000 - Best fitness: 20960.00 - Avg: 2110.23\n",
      "Generation 386/1000 - Best fitness: 20960.00 - Avg: 2086.48\n",
      "Generation 387/1000 - Best fitness: 20960.00 - Avg: 2393.41\n",
      "Generation 388/1000 - Best fitness: 20960.00 - Avg: 2033.71\n",
      "Generation 389/1000 - Best fitness: 20960.00 - Avg: 1863.32\n",
      "Generation 390/1000 - Best fitness: 20960.00 - Avg: 1789.90\n",
      "Generation 391/1000 - Best fitness: 20960.00 - Avg: 2215.25\n",
      "Generation 392/1000 - Best fitness: 20960.00 - Avg: 1905.35\n",
      "Generation 393/1000 - Best fitness: 20960.00 - Avg: 2185.40\n",
      "Generation 394/1000 - Best fitness: 20960.00 - Avg: 2203.00\n",
      "Generation 395/1000 - Best fitness: 20960.00 - Avg: 2248.60\n",
      "Generation 396/1000 - Best fitness: 20960.00 - Avg: 2236.16\n",
      "Generation 397/1000 - Best fitness: 20960.00 - Avg: 1908.57\n",
      "Generation 398/1000 - Best fitness: 20960.00 - Avg: 1969.44\n",
      "Generation 399/1000 - Best fitness: 20960.00 - Avg: 2037.84\n",
      "Generation 400/1000 - Best fitness: 20960.00 - Avg: 2178.56\n",
      "Generation 401/1000 - Best fitness: 20960.00 - Avg: 2185.45\n",
      "Generation 402/1000 - Best fitness: 20960.00 - Avg: 1964.42\n",
      "Generation 403/1000 - Best fitness: 20960.00 - Avg: 1809.71\n",
      "Generation 404/1000 - Best fitness: 20960.00 - Avg: 2186.86\n",
      "Generation 405/1000 - Best fitness: 20960.00 - Avg: 2224.14\n",
      "Generation 406/1000 - Best fitness: 20960.00 - Avg: 2864.28\n",
      "Generation 407/1000 - Best fitness: 20960.00 - Avg: 2273.98\n",
      "Generation 408/1000 - Best fitness: 20960.00 - Avg: 2127.67\n",
      "Generation 409/1000 - Best fitness: 20960.00 - Avg: 1963.18\n",
      "Generation 410/1000 - Best fitness: 20960.00 - Avg: 1845.03\n",
      "Generation 411/1000 - Best fitness: 20960.00 - Avg: 1765.09\n",
      "Generation 412/1000 - Best fitness: 20960.00 - Avg: 1884.17\n",
      "Generation 413/1000 - Best fitness: 20960.00 - Avg: 1720.84\n",
      "Generation 414/1000 - Best fitness: 20960.00 - Avg: 1959.90\n",
      "Generation 415/1000 - Best fitness: 20960.00 - Avg: 2037.41\n",
      "Generation 416/1000 - Best fitness: 20960.00 - Avg: 2138.81\n",
      "Injecting diversity at generation 416\n",
      "Generation 417/1000 - Best fitness: 20960.00 - Avg: 1999.72\n",
      "Generation 418/1000 - Best fitness: 20960.00 - Avg: 2162.60\n",
      "Generation 419/1000 - Best fitness: 20960.00 - Avg: 2257.73\n",
      "Generation 420/1000 - Best fitness: 20960.00 - Avg: 1905.52\n",
      "Generation 421/1000 - Best fitness: 20960.00 - Avg: 2096.51\n",
      "Generation 422/1000 - Best fitness: 20960.00 - Avg: 2375.27\n",
      "Generation 423/1000 - Best fitness: 20960.00 - Avg: 1905.04\n",
      "Generation 424/1000 - Best fitness: 20960.00 - Avg: 1935.63\n",
      "Generation 425/1000 - Best fitness: 20960.00 - Avg: 1977.84\n",
      "Generation 426/1000 - Best fitness: 20960.00 - Avg: 2078.16\n",
      "Generation 427/1000 - Best fitness: 20960.00 - Avg: 2139.81\n",
      "Generation 428/1000 - Best fitness: 20960.00 - Avg: 2025.98\n",
      "Generation 429/1000 - Best fitness: 20960.00 - Avg: 2185.00\n",
      "Generation 430/1000 - Best fitness: 20960.00 - Avg: 2231.71\n",
      "Generation 431/1000 - Best fitness: 20960.00 - Avg: 1982.35\n",
      "Generation 432/1000 - Best fitness: 20960.00 - Avg: 1863.34\n",
      "Generation 433/1000 - Best fitness: 20960.00 - Avg: 2082.73\n",
      "Generation 434/1000 - Best fitness: 20960.00 - Avg: 2094.79\n",
      "Generation 435/1000 - Best fitness: 20960.00 - Avg: 1939.98\n",
      "Generation 436/1000 - Best fitness: 20960.00 - Avg: 1776.33\n",
      "Generation 437/1000 - Best fitness: 20960.00 - Avg: 1783.02\n",
      "Generation 438/1000 - Best fitness: 20960.00 - Avg: 1999.24\n",
      "Generation 439/1000 - Best fitness: 20960.00 - Avg: 2073.31\n",
      "Generation 440/1000 - Best fitness: 20960.00 - Avg: 2228.60\n",
      "Generation 441/1000 - Best fitness: 20960.00 - Avg: 1672.35\n",
      "Generation 442/1000 - Best fitness: 20960.00 - Avg: 1888.76\n",
      "Generation 443/1000 - Best fitness: 20960.00 - Avg: 2161.74\n",
      "Generation 444/1000 - Best fitness: 20960.00 - Avg: 1763.95\n",
      "Generation 445/1000 - Best fitness: 20960.00 - Avg: 2103.97\n",
      "Generation 446/1000 - Best fitness: 20960.00 - Avg: 1929.38\n",
      "Generation 447/1000 - Best fitness: 20960.00 - Avg: 2179.61\n",
      "Generation 448/1000 - Best fitness: 20960.00 - Avg: 2261.37\n",
      "Generation 449/1000 - Best fitness: 20960.00 - Avg: 2135.53\n",
      "Generation 450/1000 - Best fitness: 20960.00 - Avg: 2552.28\n",
      "Generation 451/1000 - Best fitness: 20960.00 - Avg: 2011.65\n",
      "Generation 452/1000 - Best fitness: 20960.00 - Avg: 1750.82\n",
      "Generation 453/1000 - Best fitness: 20960.00 - Avg: 1791.37\n",
      "Generation 454/1000 - Best fitness: 20960.00 - Avg: 1799.31\n",
      "Generation 455/1000 - Best fitness: 20960.00 - Avg: 1957.06\n",
      "Generation 456/1000 - Best fitness: 20960.00 - Avg: 2005.50\n",
      "Injecting diversity at generation 456\n",
      "Generation 457/1000 - Best fitness: 20960.00 - Avg: 1887.04\n",
      "Generation 458/1000 - Best fitness: 20960.00 - Avg: 1945.34\n",
      "Generation 459/1000 - Best fitness: 20960.00 - Avg: 1950.68\n",
      "Generation 460/1000 - Best fitness: 20960.00 - Avg: 2391.34\n",
      "Generation 461/1000 - Best fitness: 20960.00 - Avg: 2029.49\n",
      "Generation 462/1000 - Best fitness: 20960.00 - Avg: 1983.55\n",
      "Generation 463/1000 - Best fitness: 20960.00 - Avg: 2273.05\n",
      "Generation 464/1000 - Best fitness: 20960.00 - Avg: 2103.07\n",
      "Generation 465/1000 - Best fitness: 20960.00 - Avg: 2226.52\n",
      "Generation 466/1000 - Best fitness: 20960.00 - Avg: 2028.36\n",
      "Generation 467/1000 - Best fitness: 20960.00 - Avg: 1904.18\n",
      "Generation 468/1000 - Best fitness: 20960.00 - Avg: 2147.84\n",
      "Generation 469/1000 - Best fitness: 20960.00 - Avg: 1977.22\n",
      "Generation 470/1000 - Best fitness: 20960.00 - Avg: 2073.55\n",
      "Generation 471/1000 - Best fitness: 20960.00 - Avg: 2258.72\n",
      "Generation 472/1000 - Best fitness: 20960.00 - Avg: 1850.77\n",
      "Generation 473/1000 - Best fitness: 20960.00 - Avg: 2450.54\n",
      "Generation 474/1000 - Best fitness: 20960.00 - Avg: 2039.89\n",
      "Generation 475/1000 - Best fitness: 20960.00 - Avg: 2183.92\n",
      "Generation 476/1000 - Best fitness: 20960.00 - Avg: 1891.95\n",
      "Generation 477/1000 - Best fitness: 20960.00 - Avg: 2096.30\n",
      "Generation 478/1000 - Best fitness: 20960.00 - Avg: 1796.50\n",
      "Generation 479/1000 - Best fitness: 20960.00 - Avg: 2353.50\n",
      "Generation 480/1000 - Best fitness: 20960.00 - Avg: 2286.74\n",
      "Generation 481/1000 - Best fitness: 20960.00 - Avg: 1744.32\n",
      "Generation 482/1000 - Best fitness: 20960.00 - Avg: 2102.10\n",
      "Generation 483/1000 - Best fitness: 20960.00 - Avg: 2240.27\n",
      "Generation 484/1000 - Best fitness: 20960.00 - Avg: 2288.11\n",
      "Generation 485/1000 - Best fitness: 20960.00 - Avg: 2136.78\n",
      "Generation 486/1000 - Best fitness: 20960.00 - Avg: 2164.69\n",
      "Generation 487/1000 - Best fitness: 20960.00 - Avg: 2245.35\n",
      "Generation 488/1000 - Best fitness: 20960.00 - Avg: 2138.97\n",
      "Generation 489/1000 - Best fitness: 20960.00 - Avg: 2082.74\n",
      "Generation 490/1000 - Best fitness: 20960.00 - Avg: 1931.08\n",
      "Generation 491/1000 - Best fitness: 20960.00 - Avg: 2076.74\n",
      "Generation 492/1000 - Best fitness: 20960.00 - Avg: 2165.02\n",
      "Generation 493/1000 - Best fitness: 20960.00 - Avg: 1879.60\n",
      "Generation 494/1000 - Best fitness: 20960.00 - Avg: 2024.83\n",
      "Generation 495/1000 - Best fitness: 20960.00 - Avg: 2168.40\n",
      "Generation 496/1000 - Best fitness: 20960.00 - Avg: 1941.17\n",
      "Injecting diversity at generation 496\n",
      "Generation 497/1000 - Best fitness: 20960.00 - Avg: 2121.26\n",
      "Generation 498/1000 - Best fitness: 20960.00 - Avg: 1813.07\n",
      "Generation 499/1000 - Best fitness: 20960.00 - Avg: 1740.02\n",
      "Generation 500/1000 - Best fitness: 20960.00 - Avg: 2011.55\n",
      "Generation 501/1000 - Best fitness: 20960.00 - Avg: 1784.51\n",
      "Generation 502/1000 - Best fitness: 20960.00 - Avg: 1840.74\n",
      "Generation 503/1000 - Best fitness: 20960.00 - Avg: 1980.48\n",
      "Generation 504/1000 - Best fitness: 20960.00 - Avg: 2089.98\n",
      "Generation 505/1000 - Best fitness: 20960.00 - Avg: 2131.81\n",
      "Generation 506/1000 - Best fitness: 20960.00 - Avg: 1905.63\n",
      "Generation 507/1000 - Best fitness: 20960.00 - Avg: 1900.77\n",
      "Generation 508/1000 - Best fitness: 20960.00 - Avg: 2088.11\n",
      "Generation 509/1000 - Best fitness: 20960.00 - Avg: 1800.94\n",
      "Generation 510/1000 - Best fitness: 20960.00 - Avg: 2160.68\n",
      "Generation 511/1000 - Best fitness: 20960.00 - Avg: 2076.04\n",
      "Generation 512/1000 - Best fitness: 20960.00 - Avg: 2313.71\n",
      "Generation 513/1000 - Best fitness: 20960.00 - Avg: 2126.47\n",
      "Generation 514/1000 - Best fitness: 20960.00 - Avg: 2072.78\n",
      "Generation 515/1000 - Best fitness: 20960.00 - Avg: 2171.88\n",
      "Generation 516/1000 - Best fitness: 20960.00 - Avg: 1914.08\n",
      "Generation 517/1000 - Best fitness: 20960.00 - Avg: 1785.25\n",
      "Generation 518/1000 - Best fitness: 20960.00 - Avg: 1917.14\n",
      "Generation 519/1000 - Best fitness: 20960.00 - Avg: 1861.49\n",
      "Generation 520/1000 - Best fitness: 20960.00 - Avg: 1891.54\n",
      "Generation 521/1000 - Best fitness: 20960.00 - Avg: 2189.25\n",
      "Generation 522/1000 - Best fitness: 20960.00 - Avg: 2181.66\n",
      "Generation 523/1000 - Best fitness: 20960.00 - Avg: 2087.94\n",
      "Generation 524/1000 - Best fitness: 20960.00 - Avg: 2334.67\n",
      "Generation 525/1000 - Best fitness: 20960.00 - Avg: 1997.40\n",
      "Generation 526/1000 - Best fitness: 20960.00 - Avg: 2303.76\n",
      "Generation 527/1000 - Best fitness: 20960.00 - Avg: 2252.41\n",
      "Generation 528/1000 - Best fitness: 20960.00 - Avg: 1896.14\n",
      "Generation 529/1000 - Best fitness: 20960.00 - Avg: 2381.94\n",
      "Generation 530/1000 - Best fitness: 20960.00 - Avg: 1744.21\n",
      "Generation 531/1000 - Best fitness: 20960.00 - Avg: 2182.27\n",
      "Generation 532/1000 - Best fitness: 20960.00 - Avg: 1991.03\n",
      "Generation 533/1000 - Best fitness: 20960.00 - Avg: 1867.37\n",
      "Generation 534/1000 - Best fitness: 20960.00 - Avg: 2274.82\n",
      "Generation 535/1000 - Best fitness: 20960.00 - Avg: 2530.80\n",
      "Generation 536/1000 - Best fitness: 20960.00 - Avg: 2017.50\n",
      "Injecting diversity at generation 536\n",
      "Generation 537/1000 - Best fitness: 20960.00 - Avg: 1821.72\n",
      "Generation 538/1000 - Best fitness: 20960.00 - Avg: 2031.00\n",
      "Generation 539/1000 - Best fitness: 20960.00 - Avg: 1988.71\n",
      "Generation 540/1000 - Best fitness: 20960.00 - Avg: 2250.22\n",
      "Generation 541/1000 - Best fitness: 20960.00 - Avg: 2645.24\n",
      "Generation 542/1000 - Best fitness: 20960.00 - Avg: 1701.40\n",
      "Generation 543/1000 - Best fitness: 20960.00 - Avg: 1999.19\n",
      "Generation 544/1000 - Best fitness: 20960.00 - Avg: 2303.51\n",
      "Generation 545/1000 - Best fitness: 20960.00 - Avg: 2315.42\n",
      "Generation 546/1000 - Best fitness: 20960.00 - Avg: 1953.51\n",
      "Generation 547/1000 - Best fitness: 20960.00 - Avg: 1865.86\n",
      "Generation 548/1000 - Best fitness: 20960.00 - Avg: 1951.00\n",
      "Generation 549/1000 - Best fitness: 20960.00 - Avg: 2107.17\n",
      "Generation 550/1000 - Best fitness: 20960.00 - Avg: 1764.29\n",
      "Generation 551/1000 - Best fitness: 20960.00 - Avg: 1797.56\n",
      "Generation 552/1000 - Best fitness: 20960.00 - Avg: 1907.79\n",
      "Generation 553/1000 - Best fitness: 20960.00 - Avg: 2523.47\n",
      "Generation 554/1000 - Best fitness: 20960.00 - Avg: 2152.70\n",
      "Generation 555/1000 - Best fitness: 20960.00 - Avg: 1841.85\n",
      "Generation 556/1000 - Best fitness: 20960.00 - Avg: 1857.57\n",
      "Generation 557/1000 - Best fitness: 20960.00 - Avg: 1728.66\n",
      "Generation 558/1000 - Best fitness: 20960.00 - Avg: 2134.58\n",
      "Generation 559/1000 - Best fitness: 20960.00 - Avg: 1982.37\n",
      "Generation 560/1000 - Best fitness: 20960.00 - Avg: 1887.28\n",
      "Generation 561/1000 - Best fitness: 20960.00 - Avg: 2036.69\n",
      "Generation 562/1000 - Best fitness: 20960.00 - Avg: 2115.66\n",
      "Generation 563/1000 - Best fitness: 20960.00 - Avg: 1842.02\n",
      "Generation 564/1000 - Best fitness: 20960.00 - Avg: 2054.11\n",
      "Generation 565/1000 - Best fitness: 20960.00 - Avg: 1870.17\n",
      "Generation 566/1000 - Best fitness: 20960.00 - Avg: 2059.12\n",
      "Generation 567/1000 - Best fitness: 20960.00 - Avg: 1883.14\n",
      "Generation 568/1000 - Best fitness: 20960.00 - Avg: 2097.84\n",
      "Generation 569/1000 - Best fitness: 20960.00 - Avg: 1930.37\n",
      "Generation 570/1000 - Best fitness: 20960.00 - Avg: 1730.07\n",
      "Generation 571/1000 - Best fitness: 20960.00 - Avg: 2235.01\n",
      "Generation 572/1000 - Best fitness: 20960.00 - Avg: 1843.33\n",
      "Generation 573/1000 - Best fitness: 20960.00 - Avg: 1928.71\n",
      "Generation 574/1000 - Best fitness: 20960.00 - Avg: 2169.63\n",
      "Generation 575/1000 - Best fitness: 20960.00 - Avg: 2405.50\n",
      "Generation 576/1000 - Best fitness: 20960.00 - Avg: 1804.17\n",
      "Injecting diversity at generation 576\n",
      "Generation 577/1000 - Best fitness: 20960.00 - Avg: 2153.93\n",
      "Generation 578/1000 - Best fitness: 20960.00 - Avg: 2025.80\n",
      "Generation 579/1000 - Best fitness: 20960.00 - Avg: 1848.52\n",
      "Generation 580/1000 - Best fitness: 20960.00 - Avg: 1901.37\n",
      "Generation 581/1000 - Best fitness: 20960.00 - Avg: 2117.18\n",
      "Generation 582/1000 - Best fitness: 20960.00 - Avg: 2227.59\n",
      "Generation 583/1000 - Best fitness: 20960.00 - Avg: 1921.79\n",
      "Generation 584/1000 - Best fitness: 20960.00 - Avg: 1735.12\n",
      "Generation 585/1000 - Best fitness: 20960.00 - Avg: 2029.40\n",
      "Generation 586/1000 - Best fitness: 20960.00 - Avg: 2055.90\n",
      "Generation 587/1000 - Best fitness: 20960.00 - Avg: 1890.57\n",
      "Generation 588/1000 - Best fitness: 20960.00 - Avg: 1898.09\n",
      "Generation 589/1000 - Best fitness: 20960.00 - Avg: 2060.24\n",
      "Generation 590/1000 - Best fitness: 20960.00 - Avg: 2227.75\n",
      "Generation 591/1000 - Best fitness: 20960.00 - Avg: 2243.13\n",
      "Generation 592/1000 - Best fitness: 20960.00 - Avg: 2034.79\n",
      "Generation 593/1000 - Best fitness: 20960.00 - Avg: 1979.07\n",
      "Generation 594/1000 - Best fitness: 20960.00 - Avg: 1841.81\n",
      "Generation 595/1000 - Best fitness: 20960.00 - Avg: 1925.93\n",
      "Generation 596/1000 - Best fitness: 20960.00 - Avg: 2164.64\n",
      "Generation 597/1000 - Best fitness: 20960.00 - Avg: 2023.67\n",
      "Generation 598/1000 - Best fitness: 20960.00 - Avg: 2357.75\n",
      "Generation 599/1000 - Best fitness: 21800.00 - Avg: 2243.40\n",
      "Generation 600/1000 - Best fitness: 21800.00 - Avg: 2314.00\n",
      "Generation 601/1000 - Best fitness: 21800.00 - Avg: 2136.05\n",
      "Generation 602/1000 - Best fitness: 21800.00 - Avg: 2202.36\n",
      "Generation 603/1000 - Best fitness: 21800.00 - Avg: 1848.03\n",
      "Generation 604/1000 - Best fitness: 21800.00 - Avg: 2110.17\n",
      "Generation 605/1000 - Best fitness: 21800.00 - Avg: 2165.09\n",
      "Generation 606/1000 - Best fitness: 21800.00 - Avg: 2254.35\n",
      "Generation 607/1000 - Best fitness: 21800.00 - Avg: 2045.60\n",
      "Generation 608/1000 - Best fitness: 21800.00 - Avg: 1912.69\n",
      "Generation 609/1000 - Best fitness: 21800.00 - Avg: 2035.48\n",
      "Generation 610/1000 - Best fitness: 21800.00 - Avg: 2351.80\n",
      "Generation 611/1000 - Best fitness: 21800.00 - Avg: 2127.92\n",
      "Generation 612/1000 - Best fitness: 21800.00 - Avg: 1835.73\n",
      "Generation 613/1000 - Best fitness: 21800.00 - Avg: 2183.50\n",
      "Generation 614/1000 - Best fitness: 21800.00 - Avg: 2521.52\n",
      "Generation 615/1000 - Best fitness: 21800.00 - Avg: 1994.59\n",
      "Generation 616/1000 - Best fitness: 21800.00 - Avg: 2029.01\n",
      "Generation 617/1000 - Best fitness: 21800.00 - Avg: 2164.56\n",
      "Generation 618/1000 - Best fitness: 21800.00 - Avg: 1839.60\n",
      "Generation 619/1000 - Best fitness: 21800.00 - Avg: 2117.14\n",
      "Generation 620/1000 - Best fitness: 21800.00 - Avg: 1985.59\n",
      "Generation 621/1000 - Best fitness: 21800.00 - Avg: 2265.43\n",
      "Generation 622/1000 - Best fitness: 21800.00 - Avg: 2079.26\n",
      "Generation 623/1000 - Best fitness: 21800.00 - Avg: 2305.31\n",
      "Generation 624/1000 - Best fitness: 21800.00 - Avg: 1943.71\n",
      "Generation 625/1000 - Best fitness: 21800.00 - Avg: 2112.84\n",
      "Generation 626/1000 - Best fitness: 21800.00 - Avg: 2153.64\n",
      "Generation 627/1000 - Best fitness: 21800.00 - Avg: 1827.82\n",
      "Generation 628/1000 - Best fitness: 21800.00 - Avg: 1918.38\n",
      "Generation 629/1000 - Best fitness: 21800.00 - Avg: 2186.54\n",
      "Generation 630/1000 - Best fitness: 21800.00 - Avg: 2050.19\n",
      "Generation 631/1000 - Best fitness: 21800.00 - Avg: 2537.98\n",
      "Generation 632/1000 - Best fitness: 21800.00 - Avg: 2030.75\n",
      "Generation 633/1000 - Best fitness: 21800.00 - Avg: 2416.36\n",
      "Generation 634/1000 - Best fitness: 21800.00 - Avg: 1903.33\n",
      "Generation 635/1000 - Best fitness: 21800.00 - Avg: 2185.66\n",
      "Generation 636/1000 - Best fitness: 21800.00 - Avg: 2095.22\n",
      "Generation 637/1000 - Best fitness: 21800.00 - Avg: 2355.12\n",
      "Generation 638/1000 - Best fitness: 21800.00 - Avg: 2440.99\n",
      "Generation 639/1000 - Best fitness: 21800.00 - Avg: 1717.97\n",
      "Injecting diversity at generation 639\n",
      "Generation 640/1000 - Best fitness: 21800.00 - Avg: 2190.15\n",
      "Generation 641/1000 - Best fitness: 21800.00 - Avg: 1794.52\n",
      "Generation 642/1000 - Best fitness: 21800.00 - Avg: 1911.15\n",
      "Generation 643/1000 - Best fitness: 21800.00 - Avg: 2184.30\n",
      "Generation 644/1000 - Best fitness: 21800.00 - Avg: 2233.17\n",
      "Generation 645/1000 - Best fitness: 21800.00 - Avg: 1889.52\n",
      "Generation 646/1000 - Best fitness: 21800.00 - Avg: 2075.12\n",
      "Generation 647/1000 - Best fitness: 21800.00 - Avg: 1952.74\n",
      "Generation 648/1000 - Best fitness: 21800.00 - Avg: 2061.69\n",
      "Generation 649/1000 - Best fitness: 21800.00 - Avg: 1908.36\n",
      "Generation 650/1000 - Best fitness: 21800.00 - Avg: 1794.85\n",
      "Generation 651/1000 - Best fitness: 21800.00 - Avg: 2389.64\n",
      "Generation 652/1000 - Best fitness: 21800.00 - Avg: 2255.41\n",
      "Generation 653/1000 - Best fitness: 21800.00 - Avg: 2298.89\n",
      "Generation 654/1000 - Best fitness: 21800.00 - Avg: 2179.49\n",
      "Generation 655/1000 - Best fitness: 21800.00 - Avg: 1974.85\n",
      "Generation 656/1000 - Best fitness: 21800.00 - Avg: 2343.48\n",
      "Generation 657/1000 - Best fitness: 21800.00 - Avg: 1687.58\n",
      "Generation 658/1000 - Best fitness: 21800.00 - Avg: 1938.50\n",
      "Generation 659/1000 - Best fitness: 21800.00 - Avg: 2095.87\n",
      "Generation 660/1000 - Best fitness: 21800.00 - Avg: 1995.83\n",
      "Generation 661/1000 - Best fitness: 21800.00 - Avg: 1920.92\n",
      "Generation 662/1000 - Best fitness: 21800.00 - Avg: 1854.21\n",
      "Generation 663/1000 - Best fitness: 21800.00 - Avg: 2295.67\n",
      "Generation 664/1000 - Best fitness: 21800.00 - Avg: 2043.15\n",
      "Generation 665/1000 - Best fitness: 21800.00 - Avg: 2266.94\n",
      "Generation 666/1000 - Best fitness: 21800.00 - Avg: 2344.15\n",
      "Generation 667/1000 - Best fitness: 21800.00 - Avg: 2120.63\n",
      "Generation 668/1000 - Best fitness: 21800.00 - Avg: 2299.00\n",
      "Generation 669/1000 - Best fitness: 23655.20 - Avg: 2267.87\n",
      "Generation 670/1000 - Best fitness: 23655.20 - Avg: 2172.46\n",
      "Generation 671/1000 - Best fitness: 24284.80 - Avg: 2246.35\n",
      "Generation 672/1000 - Best fitness: 24284.80 - Avg: 2227.08\n",
      "Generation 673/1000 - Best fitness: 24284.80 - Avg: 2068.88\n",
      "Generation 674/1000 - Best fitness: 24284.80 - Avg: 2095.39\n",
      "Generation 675/1000 - Best fitness: 24284.80 - Avg: 2005.38\n",
      "Generation 676/1000 - Best fitness: 24284.80 - Avg: 2060.76\n",
      "Generation 677/1000 - Best fitness: 24284.80 - Avg: 1917.68\n",
      "Generation 678/1000 - Best fitness: 24499.20 - Avg: 1824.35\n",
      "Generation 679/1000 - Best fitness: 24499.20 - Avg: 2208.66\n",
      "Generation 680/1000 - Best fitness: 24499.20 - Avg: 1946.29\n",
      "Generation 681/1000 - Best fitness: 24499.20 - Avg: 1987.76\n",
      "Generation 682/1000 - Best fitness: 24499.20 - Avg: 2356.52\n",
      "Generation 683/1000 - Best fitness: 24499.20 - Avg: 1932.78\n",
      "Generation 684/1000 - Best fitness: 24726.80 - Avg: 2140.91\n",
      "Generation 685/1000 - Best fitness: 24726.80 - Avg: 2219.25\n",
      "Generation 686/1000 - Best fitness: 24726.80 - Avg: 2365.87\n",
      "Generation 687/1000 - Best fitness: 24726.80 - Avg: 1925.88\n",
      "Generation 688/1000 - Best fitness: 24726.80 - Avg: 2299.73\n",
      "Generation 689/1000 - Best fitness: 24726.80 - Avg: 2018.06\n",
      "Generation 690/1000 - Best fitness: 24726.80 - Avg: 2165.55\n",
      "Generation 691/1000 - Best fitness: 24726.80 - Avg: 1915.81\n",
      "Generation 692/1000 - Best fitness: 24726.80 - Avg: 2289.89\n",
      "Generation 693/1000 - Best fitness: 24726.80 - Avg: 1878.83\n",
      "Generation 694/1000 - Best fitness: 24726.80 - Avg: 2513.79\n",
      "Generation 695/1000 - Best fitness: 24726.80 - Avg: 2287.55\n",
      "Generation 696/1000 - Best fitness: 25575.20 - Avg: 1974.81\n",
      "Generation 697/1000 - Best fitness: 25575.20 - Avg: 2182.22\n",
      "Generation 698/1000 - Best fitness: 25575.20 - Avg: 2187.76\n",
      "Generation 699/1000 - Best fitness: 25575.20 - Avg: 2005.81\n",
      "Generation 700/1000 - Best fitness: 25575.20 - Avg: 2176.53\n",
      "Generation 701/1000 - Best fitness: 25575.20 - Avg: 1971.30\n",
      "Generation 702/1000 - Best fitness: 25575.20 - Avg: 2267.40\n",
      "Generation 703/1000 - Best fitness: 25575.20 - Avg: 2295.51\n",
      "Generation 704/1000 - Best fitness: 25575.20 - Avg: 2372.63\n",
      "Generation 705/1000 - Best fitness: 25575.20 - Avg: 2024.59\n",
      "Generation 706/1000 - Best fitness: 25575.20 - Avg: 2402.04\n",
      "Generation 707/1000 - Best fitness: 25575.20 - Avg: 2046.02\n",
      "Generation 708/1000 - Best fitness: 25575.20 - Avg: 2475.96\n",
      "Generation 709/1000 - Best fitness: 25750.80 - Avg: 2108.05\n",
      "Generation 710/1000 - Best fitness: 25750.80 - Avg: 2188.68\n",
      "Generation 711/1000 - Best fitness: 25750.80 - Avg: 2287.25\n",
      "Generation 712/1000 - Best fitness: 25750.80 - Avg: 2171.95\n",
      "Generation 713/1000 - Best fitness: 25750.80 - Avg: 2451.21\n",
      "Generation 714/1000 - Best fitness: 25750.80 - Avg: 1801.74\n",
      "Generation 715/1000 - Best fitness: 25750.80 - Avg: 1895.04\n",
      "Generation 716/1000 - Best fitness: 25750.80 - Avg: 2217.27\n",
      "Generation 717/1000 - Best fitness: 25750.80 - Avg: 2741.02\n",
      "Generation 718/1000 - Best fitness: 25750.80 - Avg: 2379.94\n",
      "Generation 719/1000 - Best fitness: 25750.80 - Avg: 2348.84\n",
      "Generation 720/1000 - Best fitness: 25750.80 - Avg: 2326.13\n",
      "Generation 721/1000 - Best fitness: 25750.80 - Avg: 2351.37\n",
      "Generation 722/1000 - Best fitness: 25750.80 - Avg: 2236.25\n",
      "Generation 723/1000 - Best fitness: 25750.80 - Avg: 2133.32\n",
      "Generation 724/1000 - Best fitness: 25750.80 - Avg: 2403.39\n",
      "Generation 725/1000 - Best fitness: 25750.80 - Avg: 2240.38\n",
      "Generation 726/1000 - Best fitness: 25750.80 - Avg: 1863.76\n",
      "Generation 727/1000 - Best fitness: 25750.80 - Avg: 2096.59\n",
      "Generation 728/1000 - Best fitness: 25750.80 - Avg: 2095.72\n",
      "Generation 729/1000 - Best fitness: 25750.80 - Avg: 2018.82\n",
      "Generation 730/1000 - Best fitness: 25750.80 - Avg: 2254.79\n",
      "Generation 731/1000 - Best fitness: 25750.80 - Avg: 2046.13\n",
      "Generation 732/1000 - Best fitness: 25750.80 - Avg: 1994.32\n",
      "Generation 733/1000 - Best fitness: 25750.80 - Avg: 2050.03\n",
      "Generation 734/1000 - Best fitness: 25750.80 - Avg: 2216.62\n",
      "Generation 735/1000 - Best fitness: 25750.80 - Avg: 2223.76\n",
      "Generation 736/1000 - Best fitness: 25750.80 - Avg: 2218.87\n",
      "Generation 737/1000 - Best fitness: 25750.80 - Avg: 2025.57\n",
      "Generation 738/1000 - Best fitness: 25750.80 - Avg: 2085.05\n",
      "Generation 739/1000 - Best fitness: 25750.80 - Avg: 2169.61\n",
      "Generation 740/1000 - Best fitness: 25750.80 - Avg: 1868.58\n",
      "Generation 741/1000 - Best fitness: 25750.80 - Avg: 1826.11\n",
      "Generation 742/1000 - Best fitness: 25750.80 - Avg: 1872.92\n",
      "Generation 743/1000 - Best fitness: 25750.80 - Avg: 2013.78\n",
      "Generation 744/1000 - Best fitness: 25750.80 - Avg: 1959.78\n",
      "Generation 745/1000 - Best fitness: 25750.80 - Avg: 2178.51\n",
      "Generation 746/1000 - Best fitness: 25750.80 - Avg: 2057.86\n",
      "Generation 747/1000 - Best fitness: 25750.80 - Avg: 2009.17\n",
      "Generation 748/1000 - Best fitness: 25755.60 - Avg: 2080.89\n",
      "Generation 749/1000 - Best fitness: 25755.60 - Avg: 2036.67\n",
      "Generation 750/1000 - Best fitness: 25755.60 - Avg: 1751.18\n",
      "Generation 751/1000 - Best fitness: 25755.60 - Avg: 2168.39\n",
      "Generation 752/1000 - Best fitness: 25755.60 - Avg: 2163.12\n",
      "Generation 753/1000 - Best fitness: 25755.60 - Avg: 1795.35\n",
      "Generation 754/1000 - Best fitness: 25755.60 - Avg: 1887.45\n",
      "Generation 755/1000 - Best fitness: 25755.60 - Avg: 2242.26\n",
      "Generation 756/1000 - Best fitness: 25755.60 - Avg: 2549.91\n",
      "Generation 757/1000 - Best fitness: 25755.60 - Avg: 1920.95\n",
      "Generation 758/1000 - Best fitness: 25755.60 - Avg: 2077.14\n",
      "Generation 759/1000 - Best fitness: 25755.60 - Avg: 1916.96\n",
      "Generation 760/1000 - Best fitness: 25755.60 - Avg: 2163.52\n",
      "Generation 761/1000 - Best fitness: 25755.60 - Avg: 2044.12\n",
      "Generation 762/1000 - Best fitness: 25755.60 - Avg: 2494.72\n",
      "Generation 763/1000 - Best fitness: 25755.60 - Avg: 2104.74\n",
      "Generation 764/1000 - Best fitness: 25755.60 - Avg: 2147.91\n",
      "Generation 765/1000 - Best fitness: 25755.60 - Avg: 2083.67\n",
      "Generation 766/1000 - Best fitness: 25755.60 - Avg: 1929.71\n",
      "Generation 767/1000 - Best fitness: 25755.60 - Avg: 2109.62\n",
      "Generation 768/1000 - Best fitness: 25755.60 - Avg: 1851.11\n",
      "Generation 769/1000 - Best fitness: 25755.60 - Avg: 2157.00\n",
      "Generation 770/1000 - Best fitness: 25755.60 - Avg: 2297.12\n",
      "Generation 771/1000 - Best fitness: 25755.60 - Avg: 2171.53\n",
      "Generation 772/1000 - Best fitness: 25755.60 - Avg: 2105.39\n",
      "Generation 773/1000 - Best fitness: 25755.60 - Avg: 1975.99\n",
      "Generation 774/1000 - Best fitness: 25755.60 - Avg: 1986.61\n",
      "Generation 775/1000 - Best fitness: 25755.60 - Avg: 2388.85\n",
      "Generation 776/1000 - Best fitness: 25755.60 - Avg: 2076.84\n",
      "Generation 777/1000 - Best fitness: 25755.60 - Avg: 2210.75\n",
      "Generation 778/1000 - Best fitness: 25755.60 - Avg: 2770.44\n",
      "Generation 779/1000 - Best fitness: 25755.60 - Avg: 2332.15\n",
      "Generation 780/1000 - Best fitness: 25755.60 - Avg: 2621.36\n",
      "Generation 781/1000 - Best fitness: 25755.60 - Avg: 2071.20\n",
      "Generation 782/1000 - Best fitness: 25755.60 - Avg: 2059.55\n",
      "Generation 783/1000 - Best fitness: 25755.60 - Avg: 2195.48\n",
      "Generation 784/1000 - Best fitness: 25755.60 - Avg: 2119.05\n",
      "Generation 785/1000 - Best fitness: 25755.60 - Avg: 2125.47\n",
      "Generation 786/1000 - Best fitness: 25755.60 - Avg: 1889.69\n",
      "Generation 787/1000 - Best fitness: 25755.60 - Avg: 2146.27\n",
      "Generation 788/1000 - Best fitness: 25755.60 - Avg: 2371.32\n",
      "Injecting diversity at generation 788\n",
      "Generation 789/1000 - Best fitness: 25755.60 - Avg: 1819.74\n",
      "Generation 790/1000 - Best fitness: 25755.60 - Avg: 1979.68\n",
      "Generation 791/1000 - Best fitness: 25755.60 - Avg: 2123.63\n",
      "Generation 792/1000 - Best fitness: 25755.60 - Avg: 1842.13\n",
      "Generation 793/1000 - Best fitness: 25755.60 - Avg: 1876.51\n",
      "Generation 794/1000 - Best fitness: 25755.60 - Avg: 1952.25\n",
      "Generation 795/1000 - Best fitness: 25755.60 - Avg: 2104.49\n",
      "Generation 796/1000 - Best fitness: 25755.60 - Avg: 2180.55\n",
      "Generation 797/1000 - Best fitness: 25755.60 - Avg: 2016.46\n",
      "Generation 798/1000 - Best fitness: 25755.60 - Avg: 2387.67\n",
      "Generation 799/1000 - Best fitness: 25755.60 - Avg: 2147.88\n",
      "Generation 800/1000 - Best fitness: 25755.60 - Avg: 2132.61\n",
      "Generation 801/1000 - Best fitness: 25755.60 - Avg: 2214.44\n",
      "Generation 802/1000 - Best fitness: 25755.60 - Avg: 2287.92\n",
      "Generation 803/1000 - Best fitness: 25755.60 - Avg: 2647.27\n",
      "Generation 804/1000 - Best fitness: 25755.60 - Avg: 2313.34\n",
      "Generation 805/1000 - Best fitness: 25755.60 - Avg: 2533.63\n",
      "Generation 806/1000 - Best fitness: 25755.60 - Avg: 2472.24\n",
      "Generation 807/1000 - Best fitness: 25755.60 - Avg: 1928.56\n",
      "Generation 808/1000 - Best fitness: 25755.60 - Avg: 2089.56\n",
      "Generation 809/1000 - Best fitness: 25755.60 - Avg: 1965.63\n",
      "Generation 810/1000 - Best fitness: 25755.60 - Avg: 2305.39\n",
      "Generation 811/1000 - Best fitness: 25755.60 - Avg: 2248.34\n",
      "Generation 812/1000 - Best fitness: 25755.60 - Avg: 2260.46\n",
      "Generation 813/1000 - Best fitness: 25755.60 - Avg: 2143.44\n",
      "Generation 814/1000 - Best fitness: 25755.60 - Avg: 2117.82\n",
      "Generation 815/1000 - Best fitness: 25755.60 - Avg: 2451.21\n",
      "Generation 816/1000 - Best fitness: 25755.60 - Avg: 1956.77\n",
      "Generation 817/1000 - Best fitness: 25755.60 - Avg: 2408.44\n",
      "Generation 818/1000 - Best fitness: 25984.40 - Avg: 2122.89\n",
      "Generation 819/1000 - Best fitness: 25984.40 - Avg: 1968.42\n",
      "Generation 820/1000 - Best fitness: 25984.40 - Avg: 1973.13\n",
      "Generation 821/1000 - Best fitness: 25984.40 - Avg: 2222.60\n",
      "Generation 822/1000 - Best fitness: 25984.40 - Avg: 2180.40\n",
      "Generation 823/1000 - Best fitness: 25984.40 - Avg: 2620.00\n",
      "Generation 824/1000 - Best fitness: 25984.40 - Avg: 2403.55\n",
      "Generation 825/1000 - Best fitness: 25984.40 - Avg: 2397.13\n",
      "Generation 826/1000 - Best fitness: 25984.40 - Avg: 2289.08\n",
      "Generation 827/1000 - Best fitness: 25984.40 - Avg: 2339.61\n",
      "Generation 828/1000 - Best fitness: 25984.40 - Avg: 2204.63\n",
      "Generation 829/1000 - Best fitness: 25984.40 - Avg: 2200.53\n",
      "Generation 830/1000 - Best fitness: 25984.40 - Avg: 1980.92\n",
      "Generation 831/1000 - Best fitness: 25984.40 - Avg: 2281.38\n",
      "Generation 832/1000 - Best fitness: 25984.40 - Avg: 2673.80\n",
      "Generation 833/1000 - Best fitness: 25984.40 - Avg: 2485.34\n",
      "Generation 834/1000 - Best fitness: 25984.40 - Avg: 2296.33\n",
      "Generation 835/1000 - Best fitness: 25984.40 - Avg: 2302.49\n",
      "Generation 836/1000 - Best fitness: 25984.40 - Avg: 2415.98\n",
      "Generation 837/1000 - Best fitness: 25984.40 - Avg: 2513.84\n",
      "Generation 838/1000 - Best fitness: 25984.40 - Avg: 2125.13\n",
      "Generation 839/1000 - Best fitness: 25984.40 - Avg: 2298.94\n",
      "Generation 840/1000 - Best fitness: 25984.40 - Avg: 2310.84\n",
      "Generation 841/1000 - Best fitness: 25984.40 - Avg: 2187.07\n",
      "Generation 842/1000 - Best fitness: 25984.40 - Avg: 1980.50\n",
      "Generation 843/1000 - Best fitness: 25984.40 - Avg: 2284.70\n",
      "Generation 844/1000 - Best fitness: 25984.40 - Avg: 2514.69\n",
      "Generation 845/1000 - Best fitness: 25984.40 - Avg: 2289.62\n",
      "Generation 846/1000 - Best fitness: 25984.40 - Avg: 2417.35\n",
      "Generation 847/1000 - Best fitness: 25984.40 - Avg: 2247.72\n",
      "Generation 848/1000 - Best fitness: 25984.40 - Avg: 2090.17\n",
      "Generation 849/1000 - Best fitness: 25984.40 - Avg: 2074.96\n",
      "Generation 850/1000 - Best fitness: 25984.40 - Avg: 2461.21\n",
      "Generation 851/1000 - Best fitness: 25984.40 - Avg: 2409.43\n",
      "Generation 852/1000 - Best fitness: 25984.40 - Avg: 2391.51\n",
      "Generation 853/1000 - Best fitness: 25984.40 - Avg: 2169.28\n",
      "Generation 854/1000 - Best fitness: 26184.40 - Avg: 2246.43\n",
      "Generation 855/1000 - Best fitness: 26184.40 - Avg: 2397.60\n",
      "Generation 856/1000 - Best fitness: 27050.00 - Avg: 2765.90\n",
      "Generation 857/1000 - Best fitness: 27050.00 - Avg: 2250.67\n",
      "Generation 858/1000 - Best fitness: 27050.00 - Avg: 2784.98\n",
      "Generation 859/1000 - Best fitness: 27050.00 - Avg: 2483.70\n",
      "Generation 860/1000 - Best fitness: 27050.00 - Avg: 2507.26\n",
      "Generation 861/1000 - Best fitness: 27050.00 - Avg: 2408.14\n",
      "Generation 862/1000 - Best fitness: 27050.00 - Avg: 2785.75\n",
      "Generation 863/1000 - Best fitness: 27050.00 - Avg: 2495.38\n",
      "Generation 864/1000 - Best fitness: 27050.00 - Avg: 2311.60\n",
      "Generation 865/1000 - Best fitness: 27050.00 - Avg: 2680.23\n",
      "Generation 866/1000 - Best fitness: 27050.00 - Avg: 2771.43\n",
      "Generation 867/1000 - Best fitness: 27050.00 - Avg: 2338.66\n",
      "Generation 868/1000 - Best fitness: 27050.00 - Avg: 2572.62\n",
      "Generation 869/1000 - Best fitness: 27050.00 - Avg: 2403.74\n",
      "Generation 870/1000 - Best fitness: 27050.00 - Avg: 2527.84\n",
      "Generation 871/1000 - Best fitness: 27050.00 - Avg: 2273.20\n",
      "Generation 872/1000 - Best fitness: 27050.00 - Avg: 2146.00\n",
      "Generation 873/1000 - Best fitness: 27050.00 - Avg: 2277.49\n",
      "Generation 874/1000 - Best fitness: 27050.00 - Avg: 2493.52\n",
      "Generation 875/1000 - Best fitness: 27050.00 - Avg: 2645.69\n",
      "Generation 876/1000 - Best fitness: 27050.00 - Avg: 2385.43\n",
      "Generation 877/1000 - Best fitness: 27050.00 - Avg: 2554.18\n",
      "Generation 878/1000 - Best fitness: 27050.00 - Avg: 2446.90\n",
      "Generation 879/1000 - Best fitness: 27050.00 - Avg: 2378.98\n",
      "Generation 880/1000 - Best fitness: 27050.00 - Avg: 2214.58\n",
      "Generation 881/1000 - Best fitness: 27050.00 - Avg: 2547.96\n",
      "Generation 882/1000 - Best fitness: 27050.00 - Avg: 2145.00\n",
      "Generation 883/1000 - Best fitness: 27050.00 - Avg: 2514.31\n",
      "Generation 884/1000 - Best fitness: 27050.00 - Avg: 2229.27\n",
      "Generation 885/1000 - Best fitness: 27050.00 - Avg: 2457.78\n",
      "Generation 886/1000 - Best fitness: 27050.00 - Avg: 2683.24\n",
      "Generation 887/1000 - Best fitness: 27050.00 - Avg: 2502.20\n",
      "Generation 888/1000 - Best fitness: 27050.00 - Avg: 2345.71\n",
      "Generation 889/1000 - Best fitness: 27050.00 - Avg: 2206.85\n",
      "Generation 890/1000 - Best fitness: 27050.00 - Avg: 2364.34\n",
      "Generation 891/1000 - Best fitness: 27050.00 - Avg: 2273.29\n",
      "Generation 892/1000 - Best fitness: 27050.00 - Avg: 2391.12\n",
      "Generation 893/1000 - Best fitness: 27050.00 - Avg: 2242.84\n",
      "Generation 894/1000 - Best fitness: 27050.00 - Avg: 2447.72\n",
      "Generation 895/1000 - Best fitness: 27050.00 - Avg: 2427.04\n",
      "Generation 896/1000 - Best fitness: 27050.00 - Avg: 2250.07\n",
      "Injecting diversity at generation 896\n",
      "Generation 897/1000 - Best fitness: 27249.20 - Avg: 2479.17\n",
      "Generation 898/1000 - Best fitness: 27249.20 - Avg: 2610.20\n",
      "Generation 899/1000 - Best fitness: 27249.20 - Avg: 2338.52\n",
      "Generation 900/1000 - Best fitness: 27249.20 - Avg: 2207.76\n",
      "Generation 901/1000 - Best fitness: 27249.20 - Avg: 2189.44\n",
      "Generation 902/1000 - Best fitness: 27249.20 - Avg: 2353.56\n",
      "Generation 903/1000 - Best fitness: 27249.20 - Avg: 2191.34\n",
      "Generation 904/1000 - Best fitness: 27249.20 - Avg: 2305.36\n",
      "Generation 905/1000 - Best fitness: 27249.20 - Avg: 2671.70\n",
      "Generation 906/1000 - Best fitness: 27249.20 - Avg: 2279.80\n",
      "Generation 907/1000 - Best fitness: 27249.20 - Avg: 2285.92\n",
      "Generation 908/1000 - Best fitness: 27249.20 - Avg: 2481.48\n",
      "Generation 909/1000 - Best fitness: 27249.20 - Avg: 2195.79\n",
      "Generation 910/1000 - Best fitness: 27249.20 - Avg: 2301.22\n",
      "Generation 911/1000 - Best fitness: 27249.20 - Avg: 2316.13\n",
      "Generation 912/1000 - Best fitness: 27249.20 - Avg: 2622.32\n",
      "Generation 913/1000 - Best fitness: 27249.20 - Avg: 2370.31\n",
      "Generation 914/1000 - Best fitness: 27249.20 - Avg: 2464.09\n",
      "Generation 915/1000 - Best fitness: 27249.20 - Avg: 2427.75\n",
      "Generation 916/1000 - Best fitness: 27249.20 - Avg: 2376.57\n",
      "Generation 917/1000 - Best fitness: 27249.20 - Avg: 2627.66\n",
      "Generation 918/1000 - Best fitness: 27249.20 - Avg: 2447.77\n",
      "Generation 919/1000 - Best fitness: 27249.20 - Avg: 2401.61\n",
      "Generation 920/1000 - Best fitness: 27249.20 - Avg: 2247.84\n",
      "Generation 921/1000 - Best fitness: 27249.20 - Avg: 2500.61\n",
      "Generation 922/1000 - Best fitness: 27249.20 - Avg: 2422.71\n",
      "Generation 923/1000 - Best fitness: 27249.20 - Avg: 2382.90\n",
      "Generation 924/1000 - Best fitness: 27249.20 - Avg: 2790.21\n",
      "Generation 925/1000 - Best fitness: 27249.20 - Avg: 2382.47\n",
      "Generation 926/1000 - Best fitness: 27249.20 - Avg: 2647.62\n",
      "Generation 927/1000 - Best fitness: 27249.20 - Avg: 2272.48\n",
      "Generation 928/1000 - Best fitness: 27249.20 - Avg: 2484.24\n",
      "Generation 929/1000 - Best fitness: 27249.20 - Avg: 2364.12\n",
      "Generation 930/1000 - Best fitness: 27249.20 - Avg: 2532.73\n",
      "Generation 931/1000 - Best fitness: 27249.20 - Avg: 2388.44\n",
      "Generation 932/1000 - Best fitness: 27249.20 - Avg: 2526.44\n",
      "Generation 933/1000 - Best fitness: 27249.20 - Avg: 2275.09\n",
      "Generation 934/1000 - Best fitness: 27249.20 - Avg: 2174.45\n",
      "Generation 935/1000 - Best fitness: 27249.20 - Avg: 2549.32\n",
      "Generation 936/1000 - Best fitness: 27249.20 - Avg: 2271.52\n",
      "Generation 937/1000 - Best fitness: 27249.20 - Avg: 2221.33\n",
      "Injecting diversity at generation 937\n",
      "Generation 938/1000 - Best fitness: 27249.20 - Avg: 2353.49\n",
      "Generation 939/1000 - Best fitness: 27249.20 - Avg: 2199.82\n",
      "Generation 940/1000 - Best fitness: 27249.20 - Avg: 2142.04\n",
      "Generation 941/1000 - Best fitness: 27249.20 - Avg: 2287.35\n",
      "Generation 942/1000 - Best fitness: 27249.20 - Avg: 2373.38\n",
      "Generation 943/1000 - Best fitness: 27249.20 - Avg: 2280.30\n",
      "Generation 944/1000 - Best fitness: 27249.20 - Avg: 2614.92\n",
      "Generation 945/1000 - Best fitness: 27249.20 - Avg: 2458.41\n",
      "Generation 946/1000 - Best fitness: 27249.20 - Avg: 2434.50\n",
      "Generation 947/1000 - Best fitness: 27249.20 - Avg: 2597.31\n",
      "Generation 948/1000 - Best fitness: 27249.20 - Avg: 2410.32\n",
      "Generation 949/1000 - Best fitness: 27249.20 - Avg: 2216.11\n",
      "Generation 950/1000 - Best fitness: 27249.20 - Avg: 2407.59\n",
      "Generation 951/1000 - Best fitness: 27249.20 - Avg: 2167.68\n",
      "Generation 952/1000 - Best fitness: 27249.20 - Avg: 2105.23\n",
      "Generation 953/1000 - Best fitness: 27249.20 - Avg: 2579.26\n",
      "Generation 954/1000 - Best fitness: 27249.20 - Avg: 2283.58\n",
      "Generation 955/1000 - Best fitness: 27249.20 - Avg: 2270.52\n",
      "Generation 956/1000 - Best fitness: 27249.20 - Avg: 2196.68\n",
      "Generation 957/1000 - Best fitness: 27249.20 - Avg: 2259.69\n",
      "Generation 958/1000 - Best fitness: 27249.20 - Avg: 2451.36\n",
      "Generation 959/1000 - Best fitness: 27249.20 - Avg: 2259.15\n",
      "Generation 960/1000 - Best fitness: 27249.20 - Avg: 2359.95\n",
      "Generation 961/1000 - Best fitness: 27249.20 - Avg: 2230.83\n",
      "Generation 962/1000 - Best fitness: 27249.20 - Avg: 2402.56\n",
      "Generation 963/1000 - Best fitness: 27249.20 - Avg: 2603.91\n",
      "Generation 964/1000 - Best fitness: 27249.20 - Avg: 2311.77\n",
      "Generation 965/1000 - Best fitness: 27249.20 - Avg: 2332.86\n",
      "Generation 966/1000 - Best fitness: 27249.20 - Avg: 2489.08\n",
      "Generation 967/1000 - Best fitness: 27249.20 - Avg: 2248.84\n",
      "Generation 968/1000 - Best fitness: 27249.20 - Avg: 2266.20\n",
      "Generation 969/1000 - Best fitness: 27249.20 - Avg: 2274.82\n",
      "Generation 970/1000 - Best fitness: 27249.20 - Avg: 2244.16\n",
      "Generation 971/1000 - Best fitness: 27249.20 - Avg: 2163.29\n",
      "Generation 972/1000 - Best fitness: 27249.20 - Avg: 2377.81\n",
      "Generation 973/1000 - Best fitness: 27249.20 - Avg: 2505.89\n",
      "Generation 974/1000 - Best fitness: 27249.20 - Avg: 2414.75\n",
      "Generation 975/1000 - Best fitness: 27249.20 - Avg: 2256.17\n",
      "Generation 976/1000 - Best fitness: 27249.20 - Avg: 2293.36\n",
      "Generation 977/1000 - Best fitness: 27249.20 - Avg: 2490.71\n",
      "Injecting diversity at generation 977\n",
      "Generation 978/1000 - Best fitness: 27249.20 - Avg: 2246.32\n",
      "Generation 979/1000 - Best fitness: 27249.20 - Avg: 2437.51\n",
      "Generation 980/1000 - Best fitness: 27249.20 - Avg: 2435.71\n",
      "Generation 981/1000 - Best fitness: 27249.20 - Avg: 2423.66\n",
      "Generation 982/1000 - Best fitness: 27249.20 - Avg: 2197.30\n",
      "Generation 983/1000 - Best fitness: 27249.20 - Avg: 2531.37\n",
      "Generation 984/1000 - Best fitness: 27249.20 - Avg: 2384.38\n",
      "Generation 985/1000 - Best fitness: 27249.20 - Avg: 2353.02\n",
      "Generation 986/1000 - Best fitness: 27249.20 - Avg: 2874.50\n",
      "Generation 987/1000 - Best fitness: 27249.20 - Avg: 2645.64\n",
      "Generation 988/1000 - Best fitness: 27249.20 - Avg: 2348.22\n",
      "Generation 989/1000 - Best fitness: 27249.20 - Avg: 2378.47\n",
      "Generation 990/1000 - Best fitness: 27249.20 - Avg: 2249.20\n",
      "Generation 991/1000 - Best fitness: 27249.20 - Avg: 2220.78\n",
      "Generation 992/1000 - Best fitness: 27249.20 - Avg: 2238.65\n",
      "Generation 993/1000 - Best fitness: 27249.20 - Avg: 2396.35\n",
      "Generation 994/1000 - Best fitness: 27249.20 - Avg: 2480.66\n",
      "Generation 995/1000 - Best fitness: 27249.20 - Avg: 2414.45\n",
      "Generation 996/1000 - Best fitness: 27249.20 - Avg: 2329.45\n",
      "Generation 997/1000 - Best fitness: 27249.20 - Avg: 2626.15\n",
      "Generation 998/1000 - Best fitness: 27249.20 - Avg: 2434.07\n",
      "Generation 999/1000 - Best fitness: 27249.20 - Avg: 2300.88\n",
      "Generation 1000/1000 - Best fitness: 27249.20 - Avg: 2776.06\n",
      "GP agent saved to evaluation_results\\gp_trained_agent_10x10.json\n",
      "‚úÖ GP training completed in 585.94 seconds\n",
      "üíæ Model saved to: evaluation_results\\gp_trained_agent_10x10.json\n",
      "\n",
      "ü§ñ TRAINING DEEP Q-NETWORK AGENT - 10x10 Training Grid\n",
      "============================================================\n",
      "Training DQN: 5000 episodes\n",
      "Training grid: 10x10\n",
      "Training DQN Agent for 5000 episodes...\n",
      "Game size: 10x10\n",
      "Episode 100/5000 | Avg Score: 0.53 | Best: 3 | Epsilon: 0.282\n",
      "  Memory: 2531 | Loss: 3.9167\n",
      "Episode 200/5000 | Avg Score: 2.73 | Best: 14 | Epsilon: 0.050\n",
      "  Memory: 8191 | Loss: 2.5907\n",
      "Episode 300/5000 | Avg Score: 7.20 | Best: 19 | Epsilon: 0.050\n",
      "  Memory: 17156 | Loss: 3.4597\n",
      "Episode 400/5000 | Avg Score: 8.38 | Best: 28 | Epsilon: 0.050\n",
      "  Memory: 25389 | Loss: 4.4385\n",
      "Episode 500/5000 | Avg Score: 10.78 | Best: 29 | Epsilon: 0.050\n",
      "  Memory: 35142 | Loss: 5.8883\n",
      "Episode 600/5000 | Avg Score: 11.24 | Best: 29 | Epsilon: 0.050\n",
      "  Memory: 45240 | Loss: 8.4996\n",
      "Episode 700/5000 | Avg Score: 11.20 | Best: 32 | Epsilon: 0.050\n",
      "  Memory: 54856 | Loss: 12.3815\n",
      "Episode 800/5000 | Avg Score: 10.77 | Best: 32 | Epsilon: 0.050\n",
      "  Memory: 63800 | Loss: 15.4395\n",
      "Episode 900/5000 | Avg Score: 11.20 | Best: 32 | Epsilon: 0.050\n",
      "  Memory: 73273 | Loss: 17.9956\n",
      "Episode 1000/5000 | Avg Score: 11.19 | Best: 32 | Epsilon: 0.050\n",
      "  Memory: 82596 | Loss: 20.2092\n",
      "Episode 1100/5000 | Avg Score: 11.57 | Best: 32 | Epsilon: 0.050\n",
      "  Memory: 92343 | Loss: 21.7140\n",
      "Episode 1200/5000 | Avg Score: 10.43 | Best: 32 | Epsilon: 0.050\n",
      "  Memory: 100000 | Loss: 23.1799\n",
      "Episode 1300/5000 | Avg Score: 11.40 | Best: 32 | Epsilon: 0.050\n",
      "  Memory: 100000 | Loss: 24.3521\n",
      "Episode 1400/5000 | Avg Score: 11.53 | Best: 32 | Epsilon: 0.050\n",
      "  Memory: 100000 | Loss: 24.6440\n",
      "Episode 1500/5000 | Avg Score: 11.78 | Best: 32 | Epsilon: 0.050\n",
      "  Memory: 100000 | Loss: 24.7491\n",
      "Episode 1600/5000 | Avg Score: 9.85 | Best: 32 | Epsilon: 0.050\n",
      "  Memory: 100000 | Loss: 25.4019\n",
      "Episode 1700/5000 | Avg Score: 11.55 | Best: 32 | Epsilon: 0.050\n",
      "  Memory: 100000 | Loss: 25.6677\n",
      "Episode 1800/5000 | Avg Score: 10.13 | Best: 32 | Epsilon: 0.050\n",
      "  Memory: 100000 | Loss: 25.9941\n",
      "Episode 1900/5000 | Avg Score: 10.79 | Best: 32 | Epsilon: 0.050\n",
      "  Memory: 100000 | Loss: 24.7340\n",
      "Episode 2000/5000 | Avg Score: 11.19 | Best: 32 | Epsilon: 0.050\n",
      "  Memory: 100000 | Loss: 24.8035\n",
      "Episode 2100/5000 | Avg Score: 11.32 | Best: 32 | Epsilon: 0.050\n",
      "  Memory: 100000 | Loss: 24.6731\n",
      "Episode 2200/5000 | Avg Score: 10.70 | Best: 32 | Epsilon: 0.050\n",
      "  Memory: 100000 | Loss: 25.0269\n",
      "Episode 2300/5000 | Avg Score: 10.21 | Best: 32 | Epsilon: 0.050\n",
      "  Memory: 100000 | Loss: 24.4694\n",
      "Episode 2400/5000 | Avg Score: 10.96 | Best: 32 | Epsilon: 0.050\n",
      "  Memory: 100000 | Loss: 24.4420\n",
      "Episode 2500/5000 | Avg Score: 9.95 | Best: 32 | Epsilon: 0.050\n",
      "  Memory: 100000 | Loss: 24.0302\n",
      "Episode 2600/5000 | Avg Score: 10.59 | Best: 32 | Epsilon: 0.050\n",
      "  Memory: 100000 | Loss: 23.3443\n"
     ]
    }
   ],
   "source": [
    "# üöÄ RUN COMPLETE MULTI-GRID GENERALIZATION EVALUATION WITH RESEARCH PAPER STATISTICS\n",
    "print(\"üöÄ STARTING COMPREHENSIVE MULTI-GRID EVALUATION WITH STATISTICAL ANALYSIS\")\n",
    "print(\"=\" * 90)\n",
    "print(f\"Training Grid: {evaluator.training_grid[0]}x{evaluator.training_grid[1]}\")\n",
    "print(f\"Test Grid Sizes: {[f'{w}x{h}' for w, h in evaluator.test_grids]}\")\n",
    "print(f\"Test Episodes per Grid: {evaluator.test_episodes}\")\n",
    "print(f\"Total Test Episodes: {len(evaluator.test_grids) * 3 * evaluator.test_episodes}\")\n",
    "print(f\"Statistical Analysis: PSO-NN (GP) vs Simple Agents (A*, DQN)\")\n",
    "print(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "# Initialize storage for multi-grid results\n",
    "MULTI_GRID_RESULTS = {}\n",
    "MULTI_GRID_EPISODE_DATA = {}\n",
    "\n",
    "# Phase 1: Train all agents once on the training grid\n",
    "print(f\"\\n\" + \"üèãÔ∏è\" * 20)\n",
    "print(f\"üèãÔ∏è PHASE 1: TRAINING ALL AGENTS ON {evaluator.training_grid[0]}x{evaluator.training_grid[1]} GRID\")\n",
    "print(\"üèãÔ∏è\" * 20)\n",
    "\n",
    "trained_agents = train_or_load_agents()\n",
    "\n",
    "if not trained_agents:\n",
    "    print(\"‚ùå No agents were successfully trained. Stopping evaluation.\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Training phase completed! {len(trained_agents)} agents trained:\")\n",
    "    for agent_name in trained_agents.keys():\n",
    "        training_time = TRAINING_LOGS.get(agent_name, {}).get('training_time', 0)\n",
    "        agent_category = 'PSO-NN' if agent_name == 'GP' else 'Simple Agent'\n",
    "        print(f\"   ‚Ä¢ {agent_name} ({agent_category}): {training_time:.1f}s training time\")\n",
    "\n",
    "    # Phase 2: Test all trained agents on all grid sizes\n",
    "    print(f\"\\n\" + \"üéØ\" * 20)\n",
    "    print(f\"üéØ PHASE 2: TESTING AGENTS ON ALL GRID SIZES\")\n",
    "    print(\"üéØ\" * 20)\n",
    "    \n",
    "    all_grid_test_results = test_all_agents_on_all_grids(trained_agents)\n",
    "    \n",
    "    # Phase 3: Calculate metrics for each grid\n",
    "    print(f\"\\n\" + \"üìä\" * 20)\n",
    "    print(f\"üìä PHASE 3: CALCULATING METRICS AND STATISTICAL ANALYSIS\")\n",
    "    print(\"üìä\" * 20)\n",
    "    \n",
    "    for grid_key, grid_test_results in all_grid_test_results.items():\n",
    "        width, height = map(int, grid_key.split('x'))\n",
    "        \n",
    "        # Convert episode results to DataFrame for analysis\n",
    "        grid_episodes = []\n",
    "        for agent_name, episodes in grid_test_results.items():\n",
    "            for episode in episodes:\n",
    "                episode_copy = episode.copy()\n",
    "                episode_copy['agent'] = agent_name\n",
    "                grid_episodes.append(episode_copy)\n",
    "        \n",
    "        if grid_episodes:\n",
    "            grid_df = pd.DataFrame(grid_episodes)\n",
    "            grid_metrics = evaluator.calculate_research_paper_metrics(grid_df, width, height)\n",
    "            MULTI_GRID_RESULTS[grid_key] = grid_metrics\n",
    "            \n",
    "            print(f\"‚úÖ {grid_key} grid metrics calculated\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è No valid episodes for {grid_key} grid\")\n",
    "    \n",
    "    # Store episode data for detailed statistical analysis\n",
    "    MULTI_GRID_EPISODE_DATA = all_grid_test_results\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 90)\n",
    "print(\"üéä MULTI-GRID EVALUATION WITH STATISTICAL ANALYSIS COMPLETED!\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "# Phase 4: Generate comprehensive statistical analysis matching research paper format\n",
    "if MULTI_GRID_RESULTS:\n",
    "    print(f\"\\nüìä GENERATING RESEARCH PAPER FORMAT STATISTICAL ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Save all results with timestamp\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    # Save detailed episode statistics (all raw data)\n",
    "    episodes_df, summary_stats, agent_comparison = save_detailed_episode_statistics(MULTI_GRID_EPISODE_DATA, timestamp)\n",
    "    \n",
    "    # Generate research paper format statistical tables with p-values\n",
    "    statistical_results = generate_research_paper_statistical_tables(MULTI_GRID_RESULTS, MULTI_GRID_EPISODE_DATA)\n",
    "    \n",
    "    # Save comprehensive results\n",
    "    combined_df = save_multi_grid_results(MULTI_GRID_EPISODE_DATA, timestamp)\n",
    "    \n",
    "    if not combined_df.empty:\n",
    "        # Generate additional analysis (existing functions)\n",
    "        multi_grid_tables_df = generate_multi_grid_research_tables(MULTI_GRID_RESULTS)\n",
    "        generalization_df = evaluator.analyze_generalization_performance(MULTI_GRID_RESULTS)\n",
    "        generalization_summary_df = generate_generalization_analysis(generalization_df)\n",
    "        overall_summary, grid_summary = generate_multi_grid_summary_statistics(combined_df)\n",
    "        generate_multi_grid_comparison_plots(combined_df)\n",
    "        ranking_df = generate_agent_ranking_analysis(combined_df)\n",
    "        \n",
    "        print(f\"\\n\" + \"=\" * 90)\n",
    "        print(\"‚úÖ RESEARCH PAPER STATISTICAL ANALYSIS SUCCESSFULLY COMPLETED!\")\n",
    "        print(\"=\" * 90)\n",
    "        print(f\"üìÅ Results saved to: {evaluator.results_dir}\")\n",
    "        print(f\"üèãÔ∏è Training Grid: {evaluator.training_grid[0]}x{evaluator.training_grid[1]}\")\n",
    "        print(f\"üìä Test Grids: {len(evaluator.test_grids)}\")\n",
    "        print(f\"ü§ñ Agents tested: {len(trained_agents)} (1 PSO-NN, 2 Simple Agents)\")\n",
    "        print(f\"üéØ Total episodes analyzed: {len(episodes_df)}\")\n",
    "        \n",
    "        # Training time summary\n",
    "        total_training_time = sum(log.get('training_time', 0) for log in TRAINING_LOGS.values())\n",
    "        print(f\"‚è±Ô∏è Total training time: {total_training_time:.2f}s\")\n",
    "        \n",
    "        # Statistical significance summary\n",
    "        print(f\"\\nüìà STATISTICAL SIGNIFICANCE SUMMARY:\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        significant_results = {}\n",
    "        for grid_key, grid_stats in statistical_results.items():\n",
    "            significant_results[grid_key] = {}\n",
    "            for agent, test_results in grid_stats['statistical_tests'].items():\n",
    "                significant_count = sum([\n",
    "                    test_results['points_significant'],\n",
    "                    test_results['games_won_significant'], \n",
    "                    test_results['moves_significant']\n",
    "                ])\n",
    "                significant_results[grid_key][agent] = significant_count\n",
    "                \n",
    "                print(f\"{grid_key} - PSO-NN vs {agent}: {significant_count}/3 metrics significantly different\")\n",
    "                \n",
    "                # Show which metrics are significant\n",
    "                sig_metrics = []\n",
    "                if test_results['points_significant']:\n",
    "                    sig_metrics.append(f\"Points (p={test_results['points_pvalue']:.3e})\")\n",
    "                if test_results['games_won_significant']:\n",
    "                    sig_metrics.append(f\"Games Won (p={test_results['games_won_pvalue']:.3e})\")\n",
    "                if test_results['moves_significant']:\n",
    "                    sig_metrics.append(f\"Moves (p={test_results['moves_pvalue']:.3e})\")\n",
    "                \n",
    "                if sig_metrics:\n",
    "                    print(f\"   Significant: {', '.join(sig_metrics)}\")\n",
    "                else:\n",
    "                    print(f\"   No significant differences found\")\n",
    "        \n",
    "        # Display PSO-NN vs Simple Agents performance summary\n",
    "        print(f\"\\nÔøΩ PSO-NN (GP) vs SIMPLE AGENTS PERFORMANCE:\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for grid_key in sorted(statistical_results.keys()):\n",
    "            grid_stats = statistical_results[grid_key]\n",
    "            pso_stats = grid_stats['pso_nn_stats']\n",
    "            \n",
    "            print(f\"\\n{grid_key} Grid:\")\n",
    "            print(f\"  PSO-NN (GP): Points {pso_stats['points_mean']:.2f}¬±{pso_stats['points_std']:.2f}, \"\n",
    "                  f\"Games Won {pso_stats['games_won_mean']:.1f}%, \"\n",
    "                  f\"Moves {pso_stats['moves_mean']:.1f}¬±{pso_stats['moves_std']:.1f}\")\n",
    "            \n",
    "            for agent, agent_stats in grid_stats['simple_agents_stats'].items():\n",
    "                print(f\"  {agent} (Simple): Points {agent_stats['points_mean']:.2f}¬±{agent_stats['points_std']:.2f}, \"\n",
    "                      f\"Games Won {agent_stats['games_won_mean']:.1f}%, \"\n",
    "                      f\"Moves {agent_stats['moves_mean']:.1f}¬±{agent_stats['moves_std']:.1f}\")\n",
    "        \n",
    "        # Files generated summary\n",
    "        print(f\"\\nÔøΩ FILES GENERATED:\")\n",
    "        print(\"=\" * 40)\n",
    "        print(f\"‚úÖ Statistical Analysis:\")\n",
    "        print(f\"   - statistical_analysis_{timestamp}.json (Detailed results)\")\n",
    "        print(f\"   - statistical_comparison_{timestamp}.csv (Comparison data)\")\n",
    "        print(f\"   - statistical_tables_{timestamp}.tex (LaTeX format)\")\n",
    "        print(f\"‚úÖ Episode Data:\")\n",
    "        print(f\"   - detailed_episodes_{timestamp}.csv (All episode data)\")\n",
    "        print(f\"   - summary_statistics_{timestamp}.csv (Aggregated stats)\")\n",
    "        print(f\"   - agent_comparison_{timestamp}.csv (Agent comparison)\")\n",
    "        print(f\"‚úÖ Generalization Analysis:\")\n",
    "        print(f\"   - multi_grid_results_{timestamp}.json (Comprehensive results)\")\n",
    "        print(f\"   - multi_grid_generalization_{timestamp}.png (Visualization)\")\n",
    "        \n",
    "        # Research paper format summary\n",
    "        print(f\"\\nüìÑ RESEARCH PAPER READY OUTPUTS:\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"‚úÖ TABLE II: Mean Points Scored (with p-values)\")\n",
    "        print(f\"‚úÖ TABLE III: Games Won Percentage (with p-values)\")  \n",
    "        print(f\"‚úÖ TABLE IV: Mean Moves Made (with p-values)\")\n",
    "        print(f\"‚úÖ Statistical significance testing (Mann-Whitney U)\")\n",
    "        print(f\"‚úÖ PSO-NN (GP) vs Simple Agents (A*, DQN) comparison\")\n",
    "        print(f\"‚úÖ LaTeX format tables ready for publication\")\n",
    "        \n",
    "        # Key findings for conclusion\n",
    "        print(f\"\\nüî¨ KEY FINDINGS FOR RESEARCH CONCLUSIONS:\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Count overall significant differences\n",
    "        total_comparisons = len(statistical_results) * 2 * 3  # grids * agents * metrics\n",
    "        total_significant = sum(\n",
    "            sum(test_results[f'{metric}_significant'] for metric in ['points', 'games_won', 'moves'])\n",
    "            for grid_stats in statistical_results.values()\n",
    "            for test_results in grid_stats['statistical_tests'].values()\n",
    "        )\n",
    "        \n",
    "        print(f\"üìä Total statistical comparisons: {total_comparisons}\")\n",
    "        print(f\"üìä Statistically significant differences: {total_significant} ({total_significant/total_comparisons*100:.1f}%)\")\n",
    "        \n",
    "        # Performance advantages\n",
    "        pso_better_points = 0\n",
    "        pso_better_games = 0\n",
    "        simple_better_moves = 0\n",
    "        \n",
    "        for grid_stats in statistical_results.values():\n",
    "            pso_stats = grid_stats['pso_nn_stats']\n",
    "            for agent_stats in grid_stats['simple_agents_stats'].values():\n",
    "                if pso_stats['points_mean'] > agent_stats['points_mean']:\n",
    "                    pso_better_points += 1\n",
    "                if pso_stats['games_won_mean'] > agent_stats['games_won_mean']:\n",
    "                    pso_better_games += 1\n",
    "                if pso_stats['moves_mean'] > agent_stats['moves_mean']:\n",
    "                    simple_better_moves += 1\n",
    "        \n",
    "        total_grid_agent_pairs = sum(len(grid_stats['simple_agents_stats']) for grid_stats in statistical_results.values())\n",
    "        \n",
    "        print(f\"üèÜ PSO-NN better points scored: {pso_better_points}/{total_grid_agent_pairs} comparisons\")\n",
    "        print(f\"üèÜ PSO-NN better games won: {pso_better_games}/{total_grid_agent_pairs} comparisons\")\n",
    "        print(f\"ÔøΩ Simple agents made fewer moves: {simple_better_moves}/{total_grid_agent_pairs} comparisons\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No valid results to analyze\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå No grids were successfully evaluated\")\n",
    "\n",
    "print(f\"\\nüéâ Research paper statistical analysis complete!\")\n",
    "print(f\"üìä All data saved for statistical analysis and publication\")\n",
    "print(f\"üìÅ Check the {evaluator.results_dir} directory for all results files.\")\n",
    "print(f\"üìÑ LaTeX tables are ready for direct inclusion in your research paper!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4584014-9186-4969-9ee4-339b097845e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_statistical_summary(statistical_results: Dict, episodes_df: pd.DataFrame = None):\n",
    "    \"\"\"Generate a quick statistical summary for research paper conclusions\"\"\"\n",
    "    print(\"\\nüìã QUICK STATISTICAL SUMMARY FOR RESEARCH PAPER\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    if not statistical_results:\n",
    "        print(\"‚ùå No statistical results available\")\n",
    "        return\n",
    "    \n",
    "    # Overall summary\n",
    "    print(f\"\\nüéØ METHODOLOGY:\")\n",
    "    print(f\"   ‚Ä¢ PSO-NN Agent: Genetic Programming (GP)\")\n",
    "    print(f\"   ‚Ä¢ Simple Agents: A* Algorithm, Deep Q-Network (DQN)\")\n",
    "    print(f\"   ‚Ä¢ Statistical Test: Mann-Whitney U test\")\n",
    "    print(f\"   ‚Ä¢ Significance Level: Œ± = 0.05\")\n",
    "    print(f\"   ‚Ä¢ Grid Sizes Tested: {len(statistical_results)}\")\n",
    "    print(f\"   ‚Ä¢ Episodes per Agent per Grid: {evaluator.test_episodes}\")\n",
    "    \n",
    "    # Count significant results by metric\n",
    "    metrics_summary = {\n",
    "        'points': {'pso_better': 0, 'simple_better': 0, 'significant': 0, 'total': 0},\n",
    "        'games_won': {'pso_better': 0, 'simple_better': 0, 'significant': 0, 'total': 0},\n",
    "        'moves': {'pso_better': 0, 'simple_better': 0, 'significant': 0, 'total': 0}\n",
    "    }\n",
    "    \n",
    "    detailed_results = []\n",
    "    \n",
    "    for grid_key, grid_stats in statistical_results.items():\n",
    "        pso_stats = grid_stats['pso_nn_stats']\n",
    "        \n",
    "        for agent, agent_stats in grid_stats['simple_agents_stats'].items():\n",
    "            test_results = grid_stats['statistical_tests'][agent]\n",
    "            \n",
    "            # Points analysis\n",
    "            metrics_summary['points']['total'] += 1\n",
    "            if pso_stats['points_mean'] > agent_stats['points_mean']:\n",
    "                metrics_summary['points']['pso_better'] += 1\n",
    "            else:\n",
    "                metrics_summary['points']['simple_better'] += 1\n",
    "            if test_results['points_significant']:\n",
    "                metrics_summary['points']['significant'] += 1\n",
    "            \n",
    "            # Games won analysis\n",
    "            metrics_summary['games_won']['total'] += 1\n",
    "            if pso_stats['games_won_mean'] > agent_stats['games_won_mean']:\n",
    "                metrics_summary['games_won']['pso_better'] += 1\n",
    "            else:\n",
    "                metrics_summary['games_won']['simple_better'] += 1\n",
    "            if test_results['games_won_significant']:\n",
    "                metrics_summary['games_won']['significant'] += 1\n",
    "            \n",
    "            # Moves analysis\n",
    "            metrics_summary['moves']['total'] += 1\n",
    "            if pso_stats['moves_mean'] > agent_stats['moves_mean']:\n",
    "                metrics_summary['moves']['pso_better'] += 1\n",
    "            else:\n",
    "                metrics_summary['moves']['simple_better'] += 1\n",
    "            if test_results['moves_significant']:\n",
    "                metrics_summary['moves']['significant'] += 1\n",
    "            \n",
    "            # Store detailed result\n",
    "            detailed_results.append({\n",
    "                'Grid': grid_key,\n",
    "                'PSO_vs': agent,\n",
    "                'PSO_Points_Better': pso_stats['points_mean'] > agent_stats['points_mean'],\n",
    "                'PSO_Games_Better': pso_stats['games_won_mean'] > agent_stats['games_won_mean'],\n",
    "                'PSO_Moves_More': pso_stats['moves_mean'] > agent_stats['moves_mean'],\n",
    "                'Points_Significant': test_results['points_significant'],\n",
    "                'Games_Significant': test_results['games_won_significant'],\n",
    "                'Moves_Significant': test_results['moves_significant'],\n",
    "                'Points_P_Value': test_results['points_pvalue'],\n",
    "                'Games_P_Value': test_results['games_won_pvalue'],\n",
    "                'Moves_P_Value': test_results['moves_pvalue']\n",
    "            })\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(f\"\\nüìä PERFORMANCE COMPARISON RESULTS:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for metric, data in metrics_summary.items():\n",
    "        metric_name = metric.replace('_', ' ').title()\n",
    "        pso_win_rate = (data['pso_better'] / data['total'] * 100) if data['total'] > 0 else 0\n",
    "        sig_rate = (data['significant'] / data['total'] * 100) if data['total'] > 0 else 0\n",
    "        \n",
    "        print(f\"\\n{metric_name}:\")\n",
    "        print(f\"   PSO-NN performed better: {data['pso_better']}/{data['total']} ({pso_win_rate:.1f}%)\")\n",
    "        print(f\"   Statistically significant: {data['significant']}/{data['total']} ({sig_rate:.1f}%)\")\n",
    "    \n",
    "    # Conclusion statements for research paper\n",
    "    print(f\"\\nüìÑ CONCLUSION STATEMENTS FOR RESEARCH PAPER:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    points_dominance = (metrics_summary['points']['pso_better'] / metrics_summary['points']['total'] * 100)\n",
    "    games_dominance = (metrics_summary['games_won']['pso_better'] / metrics_summary['games_won']['total'] * 100)\n",
    "    moves_more = (metrics_summary['moves']['pso_better'] / metrics_summary['moves']['total'] * 100)\n",
    "    \n",
    "    print(f\"\\n1. POINTS SCORED:\")\n",
    "    print(f\"   \\\"The PSO-NN method achieved better point scores than the simple agents\")\n",
    "    print(f\"   in {metrics_summary['points']['pso_better']}/{metrics_summary['points']['total']} ({points_dominance:.1f}%) of comparisons,\")\n",
    "    print(f\"   with {metrics_summary['points']['significant']} statistically significant differences (p < 0.05).\\\"\")\n",
    "    \n",
    "    print(f\"\\n2. GAMES WON:\")  \n",
    "    print(f\"   \\\"The PSO-NN approach won more games than simple agents\")\n",
    "    print(f\"   in {metrics_summary['games_won']['pso_better']}/{metrics_summary['games_won']['total']} ({games_dominance:.1f}%) of test scenarios,\")\n",
    "    print(f\"   with {metrics_summary['games_won']['significant']} statistically significant differences.\\\"\")\n",
    "    \n",
    "    print(f\"\\n3. MOVES MADE:\")\n",
    "    print(f\"   \\\"The PSO-NN agent made more moves than simple agents\")\n",
    "    print(f\"   in {metrics_summary['moves']['pso_better']}/{metrics_summary['moves']['total']} ({moves_more:.1f}%) of comparisons,\")\n",
    "    print(f\"   with {metrics_summary['moves']['significant']} statistically significant differences.\\\"\")\n",
    "    \n",
    "    # Grid-specific insights\n",
    "    print(f\"\\nüéØ GRID-SPECIFIC PERFORMANCE:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    for grid_key in sorted(statistical_results.keys()):\n",
    "        grid_stats = statistical_results[grid_key]\n",
    "        width, height = map(int, grid_key.split('x'))\n",
    "        complexity = width * height\n",
    "        \n",
    "        pso_avg_points = grid_stats['pso_nn_stats']['points_mean']\n",
    "        simple_avg_points = np.mean([\n",
    "            stats['points_mean'] for stats in grid_stats['simple_agents_stats'].values()\n",
    "        ])\n",
    "        \n",
    "        advantage = ((pso_avg_points - simple_avg_points) / simple_avg_points * 100) if simple_avg_points > 0 else 0\n",
    "        \n",
    "        print(f\"{grid_key} (complexity {complexity}): PSO-NN {advantage:+.1f}% vs simple agents avg\")\n",
    "    \n",
    "    # Statistical test summary\n",
    "    print(f\"\\nüß™ STATISTICAL TEST SUMMARY:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    total_tests = sum(len(grid_stats['statistical_tests']) * 3 for grid_stats in statistical_results.values())\n",
    "    total_significant = sum(\n",
    "        sum(test_results[f'{metric}_significant'] for metric in ['points', 'games_won', 'moves'])\n",
    "        for grid_stats in statistical_results.values()\n",
    "        for test_results in grid_stats['statistical_tests'].values()\n",
    "    )\n",
    "    \n",
    "    print(f\"Total statistical tests performed: {total_tests}\")\n",
    "    print(f\"Significant results (p < 0.05): {total_significant} ({total_significant/total_tests*100:.1f}%)\")\n",
    "    \n",
    "    # Best and worst performance grids\n",
    "    if episodes_df is not None and len(episodes_df) > 0:\n",
    "        print(f\"\\nüèÜ PERFORMANCE BY GRID SIZE:\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        pso_performance = episodes_df[episodes_df['agent'] == 'GP'].groupby('grid_size')['points_scored'].mean().sort_values(ascending=False)\n",
    "        \n",
    "        print(f\"Best PSO-NN Performance: {pso_performance.index[0]} (avg {pso_performance.iloc[0]:.2f} points)\")\n",
    "        print(f\"Worst PSO-NN Performance: {pso_performance.index[-1]} (avg {pso_performance.iloc[-1]:.2f} points)\")\n",
    "        \n",
    "        # Success rates\n",
    "        success_rates = episodes_df[episodes_df['agent'] == 'GP'].groupby('grid_size')['successful_episode'].mean() * 100\n",
    "        print(f\"Highest Success Rate: {success_rates.idxmax()} ({success_rates.max():.1f}%)\")\n",
    "        print(f\"Lowest Success Rate: {success_rates.idxmin()} ({success_rates.min():.1f}%)\")\n",
    "    \n",
    "    return detailed_results, metrics_summary\n",
    "\n",
    "def export_research_ready_data(statistical_results: Dict, episodes_df: pd.DataFrame, timestamp: str):\n",
    "    \"\"\"Export data in formats ready for research paper figures and tables\"\"\"\n",
    "    print(f\"\\nüì§ EXPORTING RESEARCH-READY DATA FORMATS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Export for statistical software (R, SPSS, etc.)\n",
    "    research_data = []\n",
    "    \n",
    "    for grid_key, grid_stats in statistical_results.items():\n",
    "        width, height = map(int, grid_key.split('x'))\n",
    "        \n",
    "        # PSO-NN data\n",
    "        pso_data = {\n",
    "            'Grid_Size': grid_key,\n",
    "            'Grid_Width': width,\n",
    "            'Grid_Height': height,\n",
    "            'Grid_Complexity': width * height,\n",
    "            'Agent_Type': 'PSO-NN',\n",
    "            'Agent_Name': 'GP',\n",
    "            'Points_Mean': grid_stats['pso_nn_stats']['points_mean'],\n",
    "            'Points_Std': grid_stats['pso_nn_stats']['points_std'],\n",
    "            'Games_Won_Mean': grid_stats['pso_nn_stats']['games_won_mean'],\n",
    "            'Games_Won_Std': grid_stats['pso_nn_stats']['games_won_std'],\n",
    "            'Moves_Mean': grid_stats['pso_nn_stats']['moves_mean'],\n",
    "            'Moves_Std': grid_stats['pso_nn_stats']['moves_std']\n",
    "        }\n",
    "        research_data.append(pso_data)\n",
    "        \n",
    "        # Simple agents data\n",
    "        for agent, agent_stats in grid_stats['simple_agents_stats'].items():\n",
    "            agent_data = {\n",
    "                'Grid_Size': grid_key,\n",
    "                'Grid_Width': width,\n",
    "                'Grid_Height': height,\n",
    "                'Grid_Complexity': width * height,\n",
    "                'Agent_Type': 'Simple_Agent',\n",
    "                'Agent_Name': agent,\n",
    "                'Points_Mean': agent_stats['points_mean'],\n",
    "                'Points_Std': agent_stats['points_std'],\n",
    "                'Games_Won_Mean': agent_stats['games_won_mean'],\n",
    "                'Games_Won_Std': agent_stats['games_won_std'],\n",
    "                'Moves_Mean': agent_stats['moves_mean'],\n",
    "                'Moves_Std': agent_stats['moves_std']\n",
    "            }\n",
    "            research_data.append(agent_data)\n",
    "    \n",
    "    # Save research data\n",
    "    research_df = pd.DataFrame(research_data)\n",
    "    research_file = evaluator.results_dir / f\"research_ready_data_{timestamp}.csv\"\n",
    "    research_df.to_csv(research_file, index=False)\n",
    "    \n",
    "    # Export p-values matrix for significance testing\n",
    "    pvalue_data = []\n",
    "    for grid_key, grid_stats in statistical_results.items():\n",
    "        for agent, test_results in grid_stats['statistical_tests'].items():\n",
    "            pvalue_data.append({\n",
    "                'Grid_Size': grid_key,\n",
    "                'Comparison': f'PSO-NN_vs_{agent}',\n",
    "                'Points_P_Value': test_results['points_pvalue'],\n",
    "                'Games_Won_P_Value': test_results['games_won_pvalue'],\n",
    "                'Moves_P_Value': test_results['moves_pvalue'],\n",
    "                'Points_Significant': test_results['points_significant'],\n",
    "                'Games_Won_Significant': test_results['games_won_significant'],\n",
    "                'Moves_Significant': test_results['moves_significant']\n",
    "            })\n",
    "    \n",
    "    pvalue_df = pd.DataFrame(pvalue_data)\n",
    "    pvalue_file = evaluator.results_dir / f\"p_values_matrix_{timestamp}.csv\"\n",
    "    pvalue_df.to_csv(pvalue_file, index=False)\n",
    "    \n",
    "    print(f\"‚úÖ Research-ready exports completed:\")\n",
    "    print(f\"   Research data: {research_file}\")\n",
    "    print(f\"   P-values matrix: {pvalue_file}\")\n",
    "    \n",
    "    return research_df, pvalue_df\n",
    "\n",
    "print(\"‚úÖ Research paper statistical summary and export functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971bae9b-89f2-4a40-a034-48c448a7102e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä GENERATE FINAL RESEARCH PAPER ANALYSIS AND EXPORTS\n",
    "# Run this after the main evaluation is complete\n",
    "\n",
    "if 'statistical_results' in locals() and 'episodes_df' in locals():\n",
    "    print(\"\\n\" + \"üìä\" * 30)\n",
    "    print(\"üìä FINAL RESEARCH PAPER STATISTICAL ANALYSIS\")  \n",
    "    print(\"üìä\" * 30)\n",
    "    \n",
    "    # Generate quick statistical summary for conclusions\n",
    "    detailed_results, metrics_summary = quick_statistical_summary(statistical_results, episodes_df)\n",
    "    \n",
    "    # Export research-ready data formats\n",
    "    research_df, pvalue_df = export_research_ready_data(statistical_results, episodes_df, timestamp)\n",
    "    \n",
    "    print(f\"\\n\" + \"=\" * 80)\n",
    "    print(\"üéâ RESEARCH PAPER ANALYSIS COMPLETE!\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"\\nüìÅ KEY FILES FOR YOUR RESEARCH PAPER:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"‚úÖ LaTeX Tables: statistical_tables_{timestamp}.tex\")\n",
    "    print(f\"‚úÖ Statistical Analysis: statistical_analysis_{timestamp}.json\")\n",
    "    print(f\"‚úÖ Episode Data: detailed_episodes_{timestamp}.csv\")\n",
    "    print(f\"‚úÖ P-values Matrix: p_values_matrix_{timestamp}.csv\")\n",
    "    print(f\"‚úÖ Research Data: research_ready_data_{timestamp}.csv\")\n",
    "    print(f\"‚úÖ Visualization: multi_grid_generalization_{timestamp}.png\")\n",
    "    \n",
    "    print(f\"\\nüìÑ READY FOR RESEARCH PAPER:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(\"‚úÖ TABLE II: Mean Points Scored (with p-values)\")\n",
    "    print(\"‚úÖ TABLE III: Games Won Percentage (with p-values)\")\n",
    "    print(\"‚úÖ TABLE IV: Mean Moves Made (with p-values)\")\n",
    "    print(\"‚úÖ Statistical significance analysis (Mann-Whitney U tests)\")\n",
    "    print(\"‚úÖ PSO-NN vs Simple Agents comparison complete\")\n",
    "    print(\"‚úÖ All data formatted for statistical software (R, SPSS, etc.)\")\n",
    "    \n",
    "    # Show final performance summary\n",
    "    print(f\"\\nüèÜ FINAL PERFORMANCE SUMMARY:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    pso_wins = metrics_summary['points']['pso_better']\n",
    "    total_comparisons = metrics_summary['points']['total']\n",
    "    pso_win_percentage = (pso_wins / total_comparisons * 100) if total_comparisons > 0 else 0\n",
    "    \n",
    "    significant_points = metrics_summary['points']['significant']\n",
    "    significant_games = metrics_summary['games_won']['significant']\n",
    "    significant_moves = metrics_summary['moves']['significant']\n",
    "    total_significance_tests = significant_points + significant_games + significant_moves\n",
    "    \n",
    "    print(f\"üéØ PSO-NN (GP) outperformed Simple Agents in {pso_win_percentage:.1f}% of point comparisons\")\n",
    "    print(f\"üéØ {total_significance_tests} statistically significant differences found\")\n",
    "    print(f\"üéØ Data from {len(episodes_df)} total episodes across {len(TEST_GRID_SIZES)} grid sizes\")\n",
    "    print(f\"üéØ {len(trained_agents)} agents tested: 1 PSO-NN, {len(trained_agents)-1} Simple Agents\")\n",
    "    \n",
    "    # Instructions for using the results\n",
    "    print(f\"\\nüìã INSTRUCTIONS FOR USING RESULTS:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"1. Use statistical_tables_*.tex for LaTeX table inclusion\")\n",
    "    print(\"2. Reference p_values_matrix_*.csv for significance testing details\")\n",
    "    print(\"3. Use research_ready_data_*.csv for further statistical analysis\")\n",
    "    print(\"4. Include multi_grid_generalization_*.png for visual results\")\n",
    "    print(\"5. Reference detailed_episodes_*.csv for raw episode data\")\n",
    "    \n",
    "    print(f\"\\n‚ú® Your research paper statistical analysis is complete!\")\n",
    "    print(f\"üìä All results match the format from your LaTeX reference tables.\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Run the main evaluation first to generate statistical results\")\n",
    "    print(\"üí° Execute the cell above that contains 'RUN COMPLETE MULTI-GRID EVALUATION'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
